
# Interpretation von Korrelationen

<div class="vspace-large"></div>

![Bildnachweis^[https://www.patheos.com/blogs/tippling/2017/10/31/spooky-punkins-and-statistical-correlation/]](images/Inferring-Causation-from-Correlation.jpg){height=300px}



<!----------------->
<!--- New slide --->
<!----------------->
## Korrelation und Kausalität

- Eine positive oder negative Korrelation zeigt an, dass zwei Variablen zusammenhängen &mdash; und auch, dass man *eine Variable aus der anderen (zu einem gewissen Grad) vorhersagen kann*.
- Dies **bedeutet jedoch nicht, dass sich die Variablen auch kausal bedingen**
- Einerseits **können Korrelationen zufällig zustande kommen** &mdash; die Wahrscheinlichkeit von solchen irrtümlichen Befunden untersuchen wir noch genauer beim Thema Signifikanztestung.
- .. andererseits können Korrelationen durch dritte Variablen (**Störvariablen**) verursacht sein.
- Umgekehrt können Störvariablen auch tatsächlich vorhandene Zusammenhänge unterdrücken &mdash; man spricht dann von **Suppression**; der Korrelationskoeffizient unterschätzt in diesem Fall die tatsächliche Stärke des Zusammenhangs.
- Trotz aller Fallstricke bei der Interpretation gilt: eine Korrelation KANN ein **Indiz für Kausalität** sein.
    - Wo Kausalität da auch Korrelation, sofern diese nicht durch Störvariablen unterdrückt ist.
<!-- <div class="vspace-medium"></div> -->

:::{.fragment}
![](images/correlation_confounder.png){height=210px}
:::





<!----------------->
<!--- New slide --->
<!----------------->
## Korrelation und Kausalität

<div class="vspace-xlarge">&nbsp;</div>

![](images/correlation_nicolascage.png)

![](images/tylergiven.png){.absolute bottom=0 left=0 height=150px}



<!----------------->
<!--- New slide --->
<!----------------->
## Korrelation und Kausalität

<div class="vspace-xlarge"></div>

![](images/correlation_confounder_sharks.png)

<!----------------->
<!--- New slide --->
<!----------------->
## Wann ist ein Korrelationskoeffizient groß oder klein?
- Pauschal schwer zu beantworten
- In der psychologischen Literatur hat sich folgende Konvention/Nomenklatur nach Jacob Cohen^[Cohen J. (1988). Statistical Power Analysis for the Behavioral Sciences. New York, NY: Routledge Academic] eingebürgert:

:::{.fragment}
<!---  Table --->
| Korrelation (r) | Konvention |
|-|-|
| 0.1 bis 0.3  | "kleiner" Effekt |
| 0.3 bis 0.5 | "mittlerer" Effekt |
| > 0.5 | "großer" Effekt |

: {tbl-colwidths="[20, 20]"}
:::

- Allerdings fügt Cohen im gleichen Artikel hinzu:

:::{.fragment}
> These proposed conventions were set forth throughout with much diffidence [Zurückhaltung], qualifications [Bedingungen], and invitations **not to employ** them if possible.
:::

- Bei der Beurteilung sollte der Korrelationskoeffizient, wie jede Effektgröße, immer in Relation zu typischen Werten im jeweiligen Forschungsfeld gesetzt werden.


<!----------------->
<!--- New slide --->
<!----------------->
##
:::: {.columns}
::: {.column width="9%"}
::: {style="margin-top:-15px"}
![](images/summary.png){width=60px}
:::
:::
::: {.column width="91%"}
::: {.summary}
- Zusammenhänge werden mit **Kovarianz** und **Korrelation** untersucht.
- Im Gegensatz zur Kovarianz sind **Korrelationen unabhängig von den gewählten Einheiten**.
- Die **Pearson-Korrelation** misst die Linearität eines Zusammenhangs und gilt für intervallskalierte Daten.
- Für ordinalskalierte Variablen eignen sich **Rangkorrelationen** wie **Spearmans Rho** oder **Kendalls Tau**: sie messen die Monotonie eines Zusammenhangs.
- Sind beide Variablen binär, greift der **Phi-Koeffizient**.
- Correlation does not imply causation, Correlation does not imply causation, Correlation does not imply causation, Correlation does not...
:::
:::
::::

<!----------------->
<!--- New slide --->
<!----------------->
<!-- ## Korrelation und Kausalität {.blackslide}

:::: {.columns}
::: {.column width="59%"}
Die Task Force ist immer noch einigermaßen perblex, ob des Zusammenhangs von TikTok-Onlinezeit und Entzündungswerten.

- Als erfahrenen Statistiker:innen kennen Sie die **erste Regel der Korrelation**:

::: {style="color:lightblue; margin: -20px 0 5px 5px; font-family: monospace; padding-left: 14px"}
**Korrelation ist nicht gleich Kausalität**
:::
::: {style="text-align: left"}
(Oder falls Sie den Lateiner heraushängen lassen wollen: *Cum hoc ergo propter hoc*)
:::
:::
::: {.column width="41%"}
![](images/streudiagramm.png)
:::
::::

- Es scheint unmöglich, dass virtuelle TikTok-Zeit einen [**kausalen Einfluss**]{color="lightblue"} auf biologische Entzündungswerte hat.
- Sie wissen, dass ein häufiger alternativer Grund für eine Korrelation eine dritte Variable ist, die wiederum Einfluss auf beide Variablen der Korrelation hat&mdash; eine [**Störvariable**]{color="lightblue"}.
- In diesem Fall vermuten Sie, dass die Störvariable eine vorhandene Paradoxie-Erkrankung selbst ist: die Erkrankung führt einerseits zu höheren Entzündungswerten und andererseits zu vermehrter TikTok-Zeit (um Trost bei Leidensgenossen zu erfahren?) -->




 <!-- ```{python}

```   -->

 <!-- ```{python}
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from scipy.stats import linregress, pearsonr

np.random.seed(0)
root = '/home/matteo/OneDrive/lehre/Statistik/stats1_lecture/book/'
df = pd.read_csv(os.path.join(root, 'data', 'paradoxia.csv'))
data_tiktok_paradoxia = df[df.group == 2]['hours_tiktok_per_day'].values
data_inflam_paradoxia = df[df.group == 2]['inflammation'].values

linrg = linregress(data_tiktok_paradoxia, data_inflam_paradoxia)
r, p = pearsonr(data_tiktok_paradoxia, data_inflam_paradoxia)
print(linrg)

fontsize = 15

plt.style.use('dark_background')
plt.figure(figsize=(3, 2.5))
plt.xticks(fontsize=fontsize-2)
plt.yticks(fontsize=fontsize-2)
plt.xlabel('Stunden TikTok / 24h', fontsize=fontsize)
plt.ylabel('Entzündungswerte', fontsize=fontsize)
plt.scatter(data_tiktok_paradoxia, data_inflam_paradoxia)
plt.plot([0.1, 3.1], linrg.intercept + linrg.slope * np.array([0.1, 3.1]), color='#ff00ff', lw=2)
plt.text(0.2, 0.3, r'$\bf{r=' + f'{r:.3f}' + r'}$', color='#ff00ff', fontsize=fontsize-2)
plt.xlim(0, 3.2)
plt.ylim(0, 0.34)
# plt.legend()
plt.savefig('images/paradoxia_histogram_correlation_paradoxiker.png', bbox_inches='tight')
```  -->

## {.blackslide .center}

<div class="vspace-medium"></div>

:::: {.columns}
::: {.column width="65%"}
Zurück zum Zusammenhang zwischen TikTok-Online-Zeit und Entzündungswerten. Beides sind kontinuierliche intervallskalierte Variablen, Sie können also den Pearson-Korrelationskoeffizienten anwenden. Sie stellen den Zusammenhang in Form eines [**Streudiagramms**]{.navy-paradoxia} dar:
:::
::: {.column width="35%"}
::: {.content-hidden when-format="pdf"}
![](images/paradoxia_group_of_scientists.png){.hcenter-image height=200px style="margin-top:-100px !important"}
<!-- Source: Midjourney -->
:::
:::
::::

<div class="vspace-large"></div>
![](images/paradoxia_histogram_correlation_paradoxiker.png){height=400px}

Faszinierend. Es gibt tatsächlich einen Zusammenhang beider Variablen. Kann das Ergebnis so interpretiert werden, dass TikTok sich auf physiologische Entzündungswerte auswirkt?




<!----------------->
<!--- New slide --->
<!----------------->
## [Warum ist die Korrelation auf &minus;1 bis 1 beschränkt?]{color="darkred"}

![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=110px}

Darstellung der Korrelation nur mit (Ko)Varianzen:

$$
\hat{\rho}_{\mkern-2mu\scriptscriptstyle{XY}} = \frac{Cov(X,Y)}{\sigma_{\mkern-2mu\scriptscriptstyle{X}} \sigma_{\mkern-2mu\scriptscriptstyle{Y}}} = \frac{Cov(X,Y)}{\sqrt{Var(X)} \sqrt{Var(Y)}}
$$

Die Korrelation sollte maximal ($\hat{\rho}=1$) sein, wenn $X$ mit sich selbst korreliert wird ($Y=X$). Zu berücksichtigen ist, dass die Kovarianz *von X mit sich selbst* gleich der Varianz ist:

$$
\hat{\rho}_{\mkern-2mu\scriptscriptstyle{XX}} = \frac{Cov(X,X)}{\sqrt{Var(X)} \sqrt{Var(X)}} = \frac{Var(X)}{\sqrt{Var(X)} \sqrt{Var(X)}} = \frac{Var(X)}{Var(X)} = 1
$$


Umgekehrt sollte die Korrelation maximal negativ sein ($\hat{\rho}=-1$), wenn $Y$ genau das Inverse von $X$ ist, also $Y=-X$. Unter Berücksichtigung von $Var(X) = Var(-X)$ gilt:
$$
\hat{\rho}_{\mkern-2mu\scriptscriptstyle{X(-X)}} = \frac{Cov(X,-X)}{\sqrt{Var(X)} \sqrt{Var(-X)}} = \frac{-Cov(X,X)}{\sqrt{Var(X)} \sqrt{Var(X)}} = \frac{-Var(X)}{Var(X)} = -1
$$






<!----------------->
<!--- New slide --->
<!----------------->
## Punktbiseriale und biseriale Korrelation {visibility="hidden"}

![](images/kein_klausurstoff.png){.absolute top=40 right=30 height=110px}

- Korrelationskoeffizienten können auch berechnet werden, wenn eine<br>der beiden Variablen binär ist. Zwei Fälle werden unterschieden.


:::{.fragment}
**Fall 1: die binäre Variable liegt natürlicherweise in dichotomer Form vor (z.B. männl./weibl.)**
:::

:::{.fragment}
In diesem Fall haben die beiden Werte der binären Variable *keine natürliche Ordnung* und es wird der [**punktbiseriale Korrelationskoeffizient**]{color="navy"} verwendet.
:::

:::{.fragment}
Sei $X$ die binäre Variable und $Y$ die kontinuierliche Variable. Wir teilen die Stichprobe in Gruppe $A$ (für die $X$ den einen Wert einnimmt) und Gruppe $B$ (für die $X$ den anderen Wert einnimmt). Es gilt:

:::{style="margin-top: 0px"}
$$
r_\text{population} = \frac{\left(\bar{y}_A - \bar{y}_B\right)}{\sigma_Y}\sqrt{p_A p_B} \qquad\qquad r_\text{sample} = \frac{\left(\bar{y}_A - \bar{y}_B\right)}{s_Y}\sqrt{\frac{n p_A p_B}{n-1}}
$$
:::

wobei $\bar{y}_{A/B}$ der Mittelwert von $Y$ und $p_{A/B}$ der Anteil (proportion) der Versuchspersonen in Gruppe $A$/$B$ ist. $\sigma_Y$/$s_Y$ ist die Standardabweichung von $Y$ in der Population/Stichprobe.
:::

<div class="vspace-medium"></div>

::: {.merke .fragment}
:::: {.columns}
::: {.column width="5%"}
::: {style="margin-top: 18px"}
![](images/merke.png){height="55px"}
:::
:::
::: {.column width="95%"}
**Beachte:** der punktbiserielle Korrelationskoeffizient leitet sich direkt aus dem Pearson-Korrelationskoeffizienten ab (ist äquivalent), d.h. die Pearsonkorrelation einschlägiger Statistiksoftware kann verwendet werden!
:::
::::
:::

<!----------------->
<!--- New slide --->
<!----------------->
## Punktbiseriale und biseriale Korrelation {visibility="hidden"}

![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=110px}

**Fall 2: die binäre Variable resultiert aus der Dichotomisierung einer kontinuierlichen Variable**

:::{.fragment}
In diesem Fall unterschätzt die punktbiseriale Korrelation den wahren Wert und es sollte der [**biseriale Korrelationskoeffizient**]{color="navy"} verwendet:

:::{style="margin-left: -30px"}
$$
r_\text{population} = \frac{\left(\bar{y}_A - \bar{y}_B\right)}{f(z_p)\sigma_Y}p_A p_B \qquad\qquad r_\text{sample} = \frac{\left(\bar{y}_A - \bar{y}_B\right)}{f(z_p)s_Y}\frac{n p_A p_B}{n-1}
$$
:::

wobei $f(z_p)$ der Wert der Standardnormalverteilung bei $z_p$ ist und $z_p$ der Wert, bei dem die Fläche rechts unter der Standardnormalverteilung gleich $p$ ist ($P(Z>z_p)=p$).

<!-- Antwort auf 
https://real-statistics.com/correlation/biserial-correlation/comment-page-1/?unapproved=1505005&moderation-hash=fba191d84ae6d8b2252c6b13efb49ba1#comment-1505005
checken! -->


Quellen: ^[https://real-statistics.com/correlation/biserial-correlation/] ^[https://www.ncss.com/wp-content/themes/ncss/pdf/Procedures/NCSS/Point-Biserial_and_Biserial_Correlations.pdf] ^[Jacobs P, Viechtbauer W (2017) Estimation of the biserial correlation and its sampling variance for use in meta-analysis: Biserial Correlation. Res Syn Meth 8:161–180.]
:::



::: {.merke .fragment}
:::: {.columns}
::: {.column width="5%"}
::: {style="margin-top: 18px"}
![](images/merke.png){height="55px"}
:::
:::
::: {.column width="95%"}
**Beachte:** der biserielle Korrelationskoeffizient ist [nicht]{.underline} äquivalent mit dem Pearson-Korrelationskoeffizienten und sollte manuell berechnet werden.
:::
::::
:::


<!----------------->
<!--- New slide --->
<!----------------->
## [Wann Spearman und wann Kendall?]{color="darkred"}

![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=130px}

- Beide Rangkorrelationskoeffizienten bestimmen die Monotonie eines Zusammenhangs.
- **Kendall ist robuster bei kleinen Stichproben** und ist in diesen Fällen bevorzugt.
- **Spearman ist etwas weniger sensitiv gegenüber Rangbindungen** (also wenn zwei Werte den gleichen Rang haben) und ist daher bevorzugt, wenn es viele Rangbindungen gibt^[Puth M-T, Neuhäuser M, Ruxton GD (2015) Effective use of Spearman’s and Kendall’s correlation coefficients for association between two measured traits. Animal Behaviour 102:77–84.].
    - Beachte: auch bei den Kendall'schen Paaren gibt es Rangbindungen, und zwar dann, wenn die verglichenen *Paare* zwischen $X$ und $Y$ genau identisch sind.
    - Diese Paare sind weder konkordant noch diskordant und es gibt verschiedene Algorithmen diese Fälle zu berücksichtigen (hier nicht behandelt).
- **In Abwesenheit von Rangbindungen liefert Kendall präzisere Schätzungen** und ist in diesem Fall zu bevorzugen.^[Puth M-T, Neuhäuser M, Ruxton GD (2015) Effective use of Spearman’s and Kendall’s correlation coefficients for association between two measured traits. Animal Behaviour 102:77–84.].
- In der Statistik wird Kendall häufig als "Default"-Rangkorrelation empfohlen^[DC Howell (2012). Statistical Methods for Psychology. Wadsworth.]:
    - idR präzisere Schätzung des Populationsparameters
    - Standardfehler ist bekannt (für Spearman gibt es lediglich Approximationen^[https://stats.stackexchange.com/questions/18887/how-to-calculate-a-confidence-interval-for-spearmans-rank-correlation])
- In der Praxis ist aber Spearman der weitaus verbreitetere Korrelationskoeffizient &mdash;<br> womöglich weil er idR größer als der Kendall-Koeffizient ist &#128521;.

<!-- https://www.researchgate.net/post/Does-Spearmans-rho-have-any-advantage-over-Kendalls-tau     -->


<!----------------->
<!--- New slide --->
<!----------------->
## [Wann ist ein Korrelationskoeffizient groß oder klein?]{color="darkred"}

![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=120px}

- In einer kürzlichen Metaanalyse von Lovakov Agadullina (2021)^[Lovakov A, Agadullina ER (2021) Empirically derived guidelines for effect size interpretation in social psychology. Eur J Soc Psychol 51:485–504.] wurden typische Effektstärken in der Sozialpsychologie untersucht:

:::{.fragment}
![](images/lovakov_2021.png){height=400px}
:::

- Erkenntnis: "mittlere" und "starke" Korrelationen (definiert als das 50%- und 75%- Quantil)<br> sind in der Realität kleiner als von Cohen angenommen
