{
  "hash": "d3342225fb6dd468ab3a9e9e369b5786",
  "result": {
    "markdown": "---\ntitle: \"Vorlesung 11: t-Test\"\n---\n\n## {.blackslide .center}\n\n<div class=\"vspace-small\"></div>\n\n:::: {.columns}\n::: {.column width=\"68%\"}\n\n**Erinnerung:** den z-Test haben Sie unter der Voraussetzung durchgeführt, dass die Merkmalsstreuungen $\\sigma$ bzw. der Standardfehler $se$ in der Population bekannt sind.\n\n![](images/paradoxia_histogram_inflammation_sem_sig.png){height=270px style=\"margin-top: 30px !important;margin-bottom: 50px !important;\"}\n\n:::\n::: {.column width=\"32%\"}\n::: {.content-hidden when-format=\"pdf\"}\n![](images/paradoxia_group_of_scientists.png){.hcenter-image height=200px style=\"margin-top:-20px !important\"}\n\n:::\n:::\n::::\n\n\n:::: {.columns}\n::: {.column width=\"60%\"}\n<div class=\"vspace-medium\"></div>\nWie schon angesprochen, kommt dieser Fall in der Praxis allerdings nahezu nie vor und gilt auch für den vorliegenden Fall nicht. What shall you do?\n\n:::\n\n::: {.column width=\"40%\"}\n![](images/paradoxia_nulldist2g.png){height=260px style=\"margin-top: -70px !important\"}\n\n:::\n::::\n\n<!-- ## Der Forschungsprozess {.hcenter-slide}\n\n```yaml { .animate src=\"images/scientific_process.svg\"}\nsetup:\n    - element: \"#inference\"\n      modifier: function() { this.node.style.fill = 'green'; }\n    - element: \"#inferencebg\"\n      modifier: function() { this.node.style.fill = '#d8ffe2';}\n```\n\n# Einschub: Anmerkungen zur Klausur -->\n\n```{tex}\n\n```\n<!----------------->\n<!--- New slide --->\n<!----------------->\n<!-- ## Infos zur Klausur: Allgemeines\n\n- **Struktur:** 50% Verständnisfragen (Großteil *multiple choice*), 50% Rechnen\n- **Hilfsmittel:** Formelsammlung, einfacher Taschenrechner ($+$/$-$/$\\cdot$/$:$), ein Lineal oder Geodreieck wird nicht benötigt (ist aber erlaubt)\n- **Wichtig:** die Formelsammlung druckt das Prüfungsbüro für Sie aus. Sie dürfen keinen eigenen Ausdruck in die Klausur mitnehmen.\n- **Klausurinhalt:** Stoff der Vorlesungsfolien (Ausnahme: rot markiert)\n- **Rechnen:** welche Formeln muss ich beherrschen? \n  - Die Formelsammlung bietet einen sehr guten Überblick über mögliche Formeln in der Klausur. \n  - Bis auf rot gefärbte Formeln sind alle Formeln klausurrelevant.\n  - Sie können und sollen die Formelsammlung in der Klausur anwenden.\n  - Das Ziel von Statistik 1 ist explizit nicht, dass Sie Formeln auswendig lernen; Ziel ist die Kompetenz, passende Formeln nachzuschlagen und konzeptuell zu verstehen.\n  - Achten Sie darauf, dass Sie die aktuelle Version der Formelsammlung von der Website [hmu-stats.github.io](https://hmu-stats.github.io) verwenden: \n    - Version vom 19.1.2024 &mdash; siehe Datum in der Formelsammlung\n    - Im Fall einer Aktualisierung der Formelsammlung vor der Klausur gebe ich Ihnen in jedem Fall Bescheid. -->\n\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n<!-- ## Infos zur Klausur: spezifische Bemerkungen\n\n- **z-Test:** es werden keine *Rechen*aufgaben zum z-Test in der Klausur gestellt, da dieser eine geringe Praxisrelevanz hat und hauptsächlich aus pädagogischen Gründen gelehrt wird.\n  - [Aber:]{.underline} Sie sollten konzeptuell verstehen, was der prinzipielle Einsatzzweck des z-Testes ist (verglichen mit dem t-Test).\n- **Bessel-Korrektur:**\n  - Es soll verstanden werden, warum es sie gibt und wann sie prinzipiell angewendet (Stichprobe -> Population) oder nicht angewendet (deskriptive Beschreibung der Stichprobe) wird.\n  - Bei Rechenaufgaben wird die Besselkorrektur keine Rolle spielen, d.h. es wird nicht als Fehler gewertet, wenn Sie die Besselkorrektur irrtümlich anwenden oder nicht anwenden.\n  - Das impliziert auch, dass Sie bei Rechenaufgaben wahlweise die Stichprobenvarianz $s^2$ oder die Populationsschätzung $\\hat{\\sigma}^2$ angeben bzw. verwenden können.\n  - Der Grund ist, dass die Anwendung der Besselkorrektur selbst in akademischen Veröffentlichungen und Lehrbüchern sehr inkonsistent ist. Auf den folgenden beiden Folien finden Sie zwei Beispiele. -->\n\n\n<!--- New slide --->\n<!----------------->\n<!-- ## Besselkorrektur meets practise: z-Transformation\n\n- Die **z-Standardisierung** oder **z-Transformation** ist eine häufig genutzte Methode, um Variablen zwischen verschiedenen Studien vergleichbar zu machen.\n- *Streng genommen* nimmt die z-Transformation an, dass Populationsmittelwert $\\mu$ und die Populationsstreuung $\\sigma$ bekannt sind. Die Formel lautet daher:\n\n:::{.fragment}\n$$\n\\text{z-Transformation:}\\qquad Z = \\frac{X-\\mu}{\\sigma}\n$$\n:::\n\n- In der Praxis sind $\\sigma$ und $\\mu$ aber nahezu nie bekannt und daher werden häufig der empirische Mittelwert $\\Delta\\bar{x}$ und die Populationsschätzung $\\hat{\\sigma}$ mit Besselkorrektur verwendet.\n- Seien Sie sich aber bewusst, dass dies aus theoretischer Sicht eine Ungenauigkeit darstellt, denn bei unbekannter Populationsstreuung handelt es sich bei $Z$ nicht um einen normalverteilten Wert, sondern um einen t-verteilten Wert (und damit eigentlich um eine *t-Transformation*).\n- Erst ab ca. $N\\ge 30$ sind die Stichprobenschätzungen so gut, dass die z-Transformation guten Gewissens auch bei unbekannten Populationsparametern angwendet werden sollte. -->\n\n<!--- New slide --->\n<!----------------->\n<!-- ## Besselkorrektur meets practise: Korrelation\n\nFür die Formel der Pearson-Korrelation hatten wir kennengelernt:\n\n$$\nr = \\frac{1}{s_X s_Y}\\frac{1}{n}\\sum_{i=1}^n(x_i-\\bar{x})(y_i-\\bar{y})\n$$\n\n- Dies ist **Stichprobenkorrelationskoeffizient**.\n- In der Regel sind wir aber an einer Schätzung der Korrelation in der Population interessiert &xrarr; dies führt zum **empirischen Korrelationskoeffizienten**:\n\n:::{.fragment}\n$$\n\\hat{\\rho} = \\frac{1}{\\hat{\\sigma}_X \\hat{\\sigma}_Y}\\frac{1}{n-1}\\sum_{i=1}^n(x_i-\\bar{x})(y_i-\\bar{y})\n$$\n(beachten Sie den Übergang $s\\rightarrow\\hat{\\sigma}$ und $n\\rightarrow n-1$, d.h. die Besselkorrektur)\n:::\n\n- In der Praxis herrscht hier leider keine Einheitlichkeit. De facto wird in der Literatur standardmäßig die Bezeichnung $r$ für den Korrelationskoeffizienten verwendet, aber mit der Formel des empirischen Korrelationskoeffizienten. -->\n\n# Der t-Test\n\n## Problemstellung\n\n:::{style=\"margin-top: 75px\"}\nZur Erinnerung: beim **z-Test** haben wir für die Verteilung der Prüfgröße $z=\\frac{\\hat{\\theta}}{se}$ eine Normalverteilung annehmen können. Grund:\n\n- Aufgrund des zentralen Grenzwertsatzes können statistische Kennwerte $\\hat{\\theta}$ bei ausreichender Stichprobengröße als normalverteilt angenommen werden.\n- Beim z-Test werden die Standardabweichung $\\sigma$ der Population(en), und damit auch der Standardfehler $se$ (z.B. $se=\\frac{\\sigma}{\\sqrt{n}}$ bei der Einzelmessung), als bekannt angenommen.\n- De facto wird also bei der Berechnung der Prüfgröße $z=\\frac{\\hat{\\theta}}{se}$ eine normalverteilte Variable ($\\hat{\\theta}$) durch eine bekannte Konstante ($se$) geteilt, so dass auch die Prüfgröße $z$ normalverteilt ist. \n\n<div class=\"vspace-large\"></div>\n\n[Frage:]{.underline} wie verhält es sich, wenn $se$ *nicht bekannt* ist?\n:::\n\n## Problemstellung\n\n<!-- <div class=\"vspace-xlarge\"></div> -->\n\n- Ist der Populationsstandardfehler $se$ *nicht bekannt* &mdash; und das ist der Regelfall &mdash; **muss der Standardfehler auf Basis der Stichprobe als $\\hat{se}$ geschätzt werden**. \n- Die Schätzung von $\\hat{se}$ ist mit Unsicherheit behaftet und daher selbst eine **Zufallsvariable**. \n- Wir teilen also eine normalverteilte Zufallsvariable $\\hat{\\theta}$ durch eine wie-auch-immer-verteilte (*) zweite Zufallsvariable $\\hat{se}$.<br>[(* die wie-auch-immer-Verteilung ist bekannt: $\\hat{se}$ folgt der Chi-Verteilung bzw. χ-Verteilung)]{style=\"font-size: 22px !important\"}\n- **In diesem Fall können wir nicht mehr davon ausgehen, dass die Prüfgröße normalverteilt ist!**\n\n\n::: {.colorbox .fragment style=\"margin-top:13px\"}\nDie Gretchen-Frage ist daher:&numsp;welcher Verteilung folgt die Prüfstatistik\n$$\n\\frac{\\hat{\\theta}}{\\hat{se}}\\qquad\\text{?}\\qquad\\text{(mit Betonung auf dem ^ über dem Standardfehler $se$)}\n$$\n:::\n\n::: {.notabene .fragment style=\"margin-top: 25px\"}\n:::: {.columns}\n::: {.column width=\"7%\"}\n::: {style=\"margin-top: 10px\"}\n![](images/notabene2.png){height=\"65px\"}\n:::\n:::\n::: {.column width=\"93%\"}\nStreng genommen lautet die fragliche Prüfgröße $\\frac{\\hat{\\theta}-\\theta_0}{\\hat{se}}$. Von einigen Ausnahmen abgesehen gilt jedoch zumeist $\\theta_0=0$ und wir lassen $\\theta_0$ aus diesem Grund auch im Folgenden weg.\n\nEin Bespiel für eine Ausnahme ist, wenn $\\hat{\\theta}$ eine Einzelmessung ist und gegen einen Referenzwert wie den Durchschnitts-IQ $\\theta_0=100$ getestetet wird; in diesem Fall muss also $\\theta_0=100$ zunächst vom Mittelwert $\\hat{\\theta}$ abgezogen werden.\n:::\n::::\n:::\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## Die t-Verteilung\n\n:::: {.columns}\n::: {.column width=\"80%\"}\n:::{.nonincremental style=\"font-size: 26px\"}\n- An dieser Stelle kommt der englische Statistiker **William Sealy Gosset** ins Spiel.\n:::\n\n:::{style=\"margin-top: -20px; font-size: 26px\"}\n- Er postulierte 1908, dass das Verhältnis eines normalverteilten Kennwertes $\\hat{\\theta}$ und einer Chi-verteilten Variable einer Wahrscheinlichkeitsverteilung folgt, die seither als [**t-Verteilung**]{color=\"navy\"} (oder auch [**Studentsche t-Verteilung**]{color=\"navy\"}) bezeichnet wird.\n- Die Formel der Verteilung ist vergleichsweise kompliziert &mdash; für die Praxis entscheidend ist, dass sie **durch einen einzigen Parameter ($\\text{df}\\,$) definiert wird**:\n:::\n\n:::{.fragment style=\"margin-top:-10px; margin-bottom: 15px\"}\n$$\nt\\text{-Verteilung:}\\qquad f_t(x|\\scriptsize\\text{df}\\normalsize)\n$$\n:::\n\n:::\n::: {.column width=\"20%\"}\n![William Sealy Gosset (1876-1937)](images/portrait_gosset.png)\n:::\n::::\n\n::: {style=\"margin-top: -10px; font-size: 26px\"}\n:::: {.columns}\n::: {.column width=\"45%\"}\n- Der Parameter $\\text{df}$ steht für die [**Zahl der Freiheitsgrade**]{color=\"navy\"} (*degrees of freedom*) und hängt eng mit der Stichprobengröße $n$ zusammen.\n- Im Bild rechts ist eine t-Verteilung mit 4 Freiheitsgraden im Vergleich zur Standardnormalverteilung aufgetragen.\n- Erste Erkenntnis: die t-Verteilung hat etwas dickere Flanken (*fat tails*)!\n:::\n::: {.column width=\"55%\"}\n\n<div class=\"vspace-small\"></div>\n:::{.fragment}\n![](images/tdist.png){height=300px}\n:::\n:::\n::::\n:::\n\n\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## t-Wert\n\n:::: {.columns}\n::: {.column width=\"60%\"}\n\n:::{.nonincremental}\n- Wir kennen nun also die Form der Nullverteilung, wenn der Standardfehler als $\\hat{se}$ auf Basis der Stichprobe geschätzt werden muss: **t-Verteilung**\n- In Korrespondenz mit dem Namen der Verteilung wird die Prüfgröße auf Basis von $\\hat{se}$ als [**t-Wert**]{color=\"navy\"} bezeichnet:\n:::\n\n$$\nt = \\frac{\\hat{\\theta}}{\\hat{se}}\n$$\n\n:::\n::: {.column width=\"40%\"}\n\n![](images/ttest1.png){style=\"margin-top: -40px !important\"}\n\n:::\n::::\n\n- Das Prinzip der p-Wert-Bestimmung ist exakt wie beim z-Test: es wird die Fläche unter der t-Verteilung relativ zum Prüfgrößenwert $t$ bestimmt:\n    - Gerichtete Hypothese $\\hat{\\theta} > 0$: Fläche rechts von $t$\n    - Gerichtete Hypothese $\\hat{\\theta} < 0$: Fläche links von $t$\n    - Ungerichtete Hypothese $\\hat{\\theta} \\neq 0$: Fläche links von $−|t|$&numsp;**PLUS**&numsp;Fläche rechts von $|t|$\n- Merke: der *t-Wert* ist zur *t-Verteilung* wie der *z-Wert* zur *Standardnormalverteilung*!\n\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n<!-- ## [Herleitung der t-Verteilung]{style=\"font-size: 36px !important; color: darkred\"}\n\n![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=110px}\n\n:::: {.columns}\n::: {.column width=\"60%\"}\n:::{.nonincremental}\n- Um ein Gefühl dafür zu bekommen, wie die t-Verteilung hergeleitet werden kann, ist es sinnvoll nochmals das Testen des **unstandardisierten Mittelwertunterschiedes** $\\Delta\\bar{x}$ zu betrachten.\n- Da die Streubreite $\\hat{\\sigma}/\\sqrt{n}$ der Stichprobenverteilung nicht genau bekannt ist, sondern mit Unsicherheit behaftet ist (siehe gestrichelte Linien im unteren Bild), ist der p-Wert nicht eindeutig bestimmt.\n- Es ist dennoch möglich, den (erwarteten) p-Wert zu berechnen, in dem man nicht nur die Fläche auf Basis der eigentlichen Schätzung $\\hat{\\sigma}$ berechnet, sondern *für alle möglichen* Werte von $\\sigma$.\n- Die so erhalteten Flächen mittelt man gewichtet an der Wahrscheinlichkeit jedes möglichen Wertes von $\\sigma$ &mdash; dadurch wird die Unsicherheit von $\\hat{\\sigma}$ \"marginalisiert\".\n:::\n:::\n::: {.column width=\"40%\"}\n:::{style=\"margin-top: -30px !important\"}\n![](images/nulldist2d2.png)\n:::\n\n![](images/nulldist2d3.png)\n:::\n::::\n\n:::{.nonincremental style=\"margin-top: -15px\"}\n- Betrachtet man diese Art der Integration mit Marginalisierung nicht für einen<br>konkreten Fall, sondern für die theoretische Verteilung, ergibt sich die t-Verteilung.\n::: -->\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## t-Verteilung versus Standardormalverteilung\n\n:::{.nonincremental}\n- Der einzige Parameter der t-Verteilung, die Zahl der Freiheitsgrade $\\text{df}$, bestimmt die Form der Verteilung.\n- Die Zahl der Freiheitsgrade $\\text{df}$ hängt eng mit der Stichprobengröße $n$ zusammen<br>(z.B. $\\text{df}=n-1$ bei einer Mittelwertdifferenz abhängiger Messungen).\n- Je größer $\\text{df}$ bzw. $n$, desto ähnlicher wird die t-Verteilung der Standardnormalverteilung!\n:::\n\n<div class=\"vspace-small\"></div>\n\n![](images/tdist2.png)\n\n<div class=\"vspace-small\"></div>\n\nDie Standardabweichung der t-Verteilung ist im Gegensatz zur Standardnormalverteilung nicht exakt 1 sondern $\\sqrt{\\frac{\\text{df}}{\\text{df}-2}}$. Für $n\\rightarrow\\infty$ und damit $\\text{df}\\rightarrow\\infty$ nähert sich die Standardabweichung aber 1 an.\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## Funktionen der t-Verteilung\n\n:::: {.columns}\n::: {.column width=\"65%\"}\nWie die Normalverteilung wird auch die t-Verteilung durch eine **Wahrscheinlichkeitsdichte** definiert:\n\n![](images/tdist_notation.png){height=200px style=\"margin-top:15px !important\"}\n\n:::\n::: {.column width=\"35%\"}\n![](images/ttest1_f.png)\n:::\n::::\n\n<div class=\"vspace-small\"></div>\n\n:::{.fragment}\n:::: {.columns}\n::: {.column width=\"65%\"}\n\nDie zugehörige **kumulative Verteilungsfunktion** wird der Konvention entsprechend mit einem großen $F$ denotiert:\n\n<div class=\"vspace-small\"></div>\n\n$$\n\\text{Kumulative Verteilungsfunktion:}\\\\ \nF_t(x|\\scriptsize\\text{df}\\normalsize) = \\int_{-\\infty}^{x}f_t(x'|\\scriptsize\\text{df}\\normalsize)dx'\n$$\n\nDie kumulative Verteilungsfunktion ordnet jedem t-Wert den Flächeinhalt unter der t-Verteilung im Bereich $[-\\infty; t]$ zu.\n\n<div class=\"vspace-small\"></div>\n\n\n:::\n::: {.column width=\"35%\"}\n![](images/ttest1_f_cdf.png)\n:::\n::::\n:::\n\n\n## Funktionen der t-Verteilung\n\n<div class=\"vspace-small\"></div>\n\n:::: {.columns}\n::: {.column width=\"45%\"}\n\nZuweilen stellt sich die umgekehrte Frage:<br> *Wie lautet der t-Wert für einen bestimmten Flächeninhalt (z.B. einen bestimmten p-Wert) unter der t-Verteilung?*\n\nDiesen Zusammenhang stellt die [**inverse kumulative Verteilungsfunktion**]{color=\"navy\"} her:\n\n<div class=\"vspace-small\"></div>\n\n$$\nt = F^{-1}_t(a|\\scriptsize\\text{df}\\normalsize)\n$$\n\n:::\n::: {.column width=\"55%\"}\n\n![](images/tdist_cdfinv0_simple.png){style=\"margin-top:-50px !important\"}\n\n:::\n::::\n\nwobei $a$ die Fläche ([a]{.underline}rea) bezeichnet. Da die t-Verteilung eine Wahrscheinlichkeitsverteilung ist, kann die Fläche $a$ nur Werte zwischen 0 und 1 annehmen.\n\n:::{.fragment}\nDie Funktion wird auch **Quantilfunktion** genannt, da sie z.B. für $a=0.8$ den Wert $t$ zurück gibt, der 80% der t-Verteilung umfasst (von $-\\infty$ gerechnet; im Beispiel $t=0.85$).\n:::\n\n::: {.notabene .fragment}\n:::: {.columns}\n::: {.column width=\"7%\"}\n::: {style=\"margin-top: 10px\"}\n![](images/notabene2.png){height=\"65px\"}\n:::\n:::\n::: {.column width=\"93%\"}\nSämtliche Funktionen (Wahrscheinlichkeitsdichte, kumulative Verteilungsfunktion, inverse kumulative Verteilungsfunktion) sind zu kompliziert zur manuellen Berechnung und werden mit dem Computer ausgewertet. Zusätzlich bietet die t-Tabelle die Möglichkeit, kritische t-Werte für ausgewählte Signifikanzniveaus nachzuschlagen.\n:::\n::::\n:::\n\n\n## Funktionen der t-Verteilung\n\nMit der inversen kumulativen Verteilungsfunktion können [**kritische t-Werte**]{color=\"navy\"} für gegebene Signifikanzniveaus $\\alpha$ berechnet werden, wie sie von der **t-Tabelle** bereitgestellt werden. \n\nBei gerichteter Hypothese ist der kritische t-Wert bei einem Signifikanzniveau von $\\alpha$ gleich $F^{-1}_t(1-\\alpha|\\scriptsize\\text{df}\\normalsize)$, bei ungerichteter Hypothese gleich $F^{-1}_t(1-\\frac{\\alpha}{2}|\\scriptsize\\text{df}\\normalsize)$. Für die Angabe eines kritischen t-Wertes wird als Subscript die kritische Fläche und die Zahl der Freiheitsgrade $\\text{df}$ angegeben:\n\n$$\n\\text{Gerichtet:}\\quad t_\\text{crit} = t_{(1-\\alpha,\\,\\text{df})}\\qquad\\text{Ungerichtet:}\\quad t_\\text{crit} = t_{(1-\\frac{\\alpha}{2},\\,\\text{df})}\n$$\n\n\n<!-- <div class=\"vspace-medium\"></div> -->\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n\n![](images/ttest1_alpha.png){height=330px}\n\n:::\n::: {.column width=\"50%\"}\n\n![](images/ttest1_alpha_ungerichtet.png){height=330px}\n\n:::\n::::\n\n**$t_\\text{crit}$ gibt den Wert an, den die Prüfgröße $t$ mindestens erreichen muss, damit der zugehörige p-Wert kleiner als das Signifikanzniveau $\\alpha$ ist.**\n\n\n# Durchführung eines t-Testes\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## t-Test\n\nZur Durchführung des t-Tests müssen wir uns über folgende Punkte Gedanken machen:\n\n:::{.fragment}\n**0. Sind die Voraussetzungen für einen t-Test gegeben?**\n\nJeder statistische Test basiert auf bestimmten Annahmen. Der Test sollte daher nur dann angewendet werden, wenn diese Annahmen erfüllt sind (oder sich eine Verletzung der Annahme in der Praxis als wenig problematisch herausgestellt hat).\n:::\n\n:::{.fragment}\n**1. Welche Art von t-Test benötige ich?**\n\nFür verschiedene Szenarien gibt es unterschiedliche t-Tests, die sich unterscheiden in a) dem verwendeten Standardfehler und b) der Zahl der Freiheitsgrade $\\text{df}$.\n:::\n\n:::{.fragment}\n**2. Zahl der Freiheitsgrade**\n\nDie Zahl der Freiheitsgrade $\\text{df}$ ist als Parameter für die t-Verteilung notwendig, und damit auch notwendig um Flächen (wie p-Werte) unter der Verteilung zu berechnen. De facto übernehmen das heute Computerprogramme, jedoch ist es nach wie vor Usus die Zahl der Freiheitsgrade eines statistischen Testes in wissenschaftlichen Veröffentlichungen anzugeben.\n:::\n\n:::{.fragment}\n**3. Signifikanzniveau & ein/zweiseitige Testung**\n\nWelchen Wert bestimme ich als Signifikanzniveau $\\alpha$? Ist mein Test einseitig (gerichtete Hypothese) oder zweiseitig (ungerichtete Hypothese)? &xrarr; siehe auch Vorlesung 10\n:::\n\n\n\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## 0. Sind die Voraussetzungen für einen t-Test gegeben?\n\n:::: {.columns}\n::: {.column width=\"70%\"}\n\n:::{.nonincremental}\n- Mindestens **intervallskalierte Daten**.\n- **Hinreichende Normalverteilung** des gemessenen Merkmals $X$ in der Population (Zweistichproben-t-Test: Normalverteilung von $X_A$ und $X_B$ in den beiden Gruppen A und B!)\n    - [Allerdings zeigen Simulationsstudien, dass der t-Test sehr „robust“ gegen Verletzungen der Normalverteilungsannahme ist.]{color=\"darkgreen\"}\n    - Problematisch sind stark schiefe Verteilungen (rechts- oder linksschief) bei kleinen Stichprobengrößen.\n    - Kann von keiner Normalverteilung ausgegangen werden: nicht-parametrische Testverfahren (z.B. Mann-Whitney-U-Test).\n- Siehe Bonuscontent für eine [Begründung der Normalverteilungsvoraussetzung beim t-Test](#tnormal){style=\"color: darkred\"}.\n:::\n:::\n::: {.column width=\"30%\"}\n![Mr. T](images/mrT.png)\n\n:::\n::::\n\n\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## 1. Welche Art von t-Test benötige ich?\n\n:::{.vcenter}\n![](images/ttest_decisiontree_v2.png){height=640px}\n:::\n\n\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## 2. Zahl der Freiheitsgrade\n\n::: {.nonincremental style=\"font-size: 26px\"}\n- Die [**Zahl der Freiheitsgrade**]{color=\"navy\"} gibt die **Zahl der frei variierbaren Werte** bei der Berechnung eines statistischen Kennwertes an.\n- Häufig kann die Zahl der Freiheitsgrade recht einfach berechnet werden als Stichprobengröße $n$ *minus* die Anzahl der Zwischenparameter, die für die Berechnung des statistischen Kennwertes geschätzt werden müssen.\n:::\n\n\n<!---  Example --->\n::: {.example .fragment style=\"font-size:23px !important; margin-top:-12px\"}\n:::: {.columns}\n::: {.column width=\"7%\"}\n::: {style=\"margin-top: 10px\"}\n![](images/example.png){height=50px}\n:::\n:::\n::: {.column width=\"93%\"}\n**Beispiel Varianz:** Angenommen, wir wollen für einer Stichprobe aus vier Werten die Varianz bestimmen:\n\n::: {style=\"margin-top:-15px !important; margin-bottom:-5px !important\"}\n$$\n\\hat{\\sigma}^2 = \\frac{1}{4-1}\\sum_{i=1}^4 (x_i-\\bar{x})^2\n$$\n:::\n\nAus der Formel der Varianz erkennen wir, dass wir zur Berechnung der Varianz **einen Parameter** aus den Daten bestimmen müssen, nämlich der Mittelwert $\\bar{x}$. Die Zahl der Freiheitsgrade ergibt sich damit plain & simple nach obiger Definition als **Stichprobengröße n minus 1**, also in diesem Beispiel $\\text{df}=3$. \n\nDadurch, dass die Formel der Varianz den Mittelwert aller Datenpunkte als Parameter enthält, können wir nicht mehr alle 4 Datenpunkte beliebig frei variieren. Wir könnten drei beliebige Datenwerte frei bestimmen, der vierte Wert aber wäre durch den Mittelwertparameter automatisch festgelegt. Sagen wir der Mittelwert sei $\\bar{x}=2$ und wir würden frei drei Werte als (2, 4, 1) frei wählen. Der vierte Wert ist nun nicht mehr frei, denn um die Randbedingung $\\bar{x}=2$ zu garantieren, muss der vierte Wert gleich 1 sein. Diese Logik gilt nicht nur für den Mittelwertsparameter, sondern für jeden Parameter der \"auf dem Weg\" zur Berechnung einer statistischen Größe geschätzt werden muss (bei der Varianz ist der Mittelwert aber der einzige Zwischenparameter).\n:::\n::::\n:::\n\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## 2. Zahl der Freiheitsgrade: t-Test\n\n\n:::: {.columns}\n::: {.column width=\"70%\"}\n\n:::{.nonincremental}\n- Für die Zahl der Freiheitsgrade beim t-Test gilt, dass die Zahl der Freiheitsgrade ausschließlich auf Basis der Streuung $\\hat{se}$ im Nenner bestimmt wird.\n:::\n\n$$\nt=\\frac{\\hat{\\theta}}{\\hat{se}}\n$$\n:::\n::: {.column width=\"30%\"}\n:::{style=\"margin-top: -70px\"}\n![](images/df_cartoon.jpg)\n:::\n:::\n::::\n\n\n- Häufig reicht es, zu zählen, wie viele Mittelwerte für die Berechnung von $\\hat{se}$ im Nenner des t-Wertes für die verschiedenen Tests verwendet werden:\n    - Einstichproben-t-Test: 1 Mittelwert für 1 Stichprobe &xrarr; $\\text{df}=n-1$\n    - Differenzen-t-Test: 1 Mittelwert für 1 Stichprobe (hier: Mittelwert $\\Delta\\bar{x}$ der Differenzen $\\Delta\\bar{x}_i$) &xrarr; $\\text{df}=n-1$\n    - Zweistichproben-t-Test (ähnliche Varianzen): 2 Mittelwerte für 2 Stichproben &xrarr; $\\text{df}=n_A+n_B-2$\n    - (Ausnahme: Zweistichprobentest mit unterschiedlichen Varianzen &xrarr; Welch–Satterthwaite-Gleichung)\n    - Korrelation und Regression: 2 Mittelwerte für die zwei Zusammenhangsvariablen $X$ und $Y$ &xrarr; $\\text{df}=n-2$\n\n\n<!-- - Eine berechtigte Frage ist, warum beim t-Test die Streuung $\\hat{\\sigma}$ nicht auch als Freiheitsgrad abgezogen werden muss (schließlich wird dieser Parameter bei der Berechnung des t-Wertes verwendet).\n- Der Grund ist subtil und hängt damit zusammen, dass wir die t-Verteilung *unter der Voraussetzung verwenden, dass der Standardfehler geschätzt werden musste*. Der Verlust dieses Freiheitsgrades ist also in der Verteilung selbst bereits berücksichtigt und muss post-hoc nicht mehr als zusätzlicher Freiheitsgrad abgezogen werden.^[https://stats.stackexchange.com/questions/226483/does-the-determination-of-the-mean-and-sd-imply-the-loss-of-one-or-two-degrees-o] -->\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n<!-- ## [3. Zahl der Freiheitsgrade]{color=\"darkred\"}\n\n![](images/kein_klausurstoff.png){.absolute top=15 right=20 height=100px}\n\n:::: {.columns}\n::: {.column width=\"65%\"}\n\n:::{.nonincremental}\n- Generell gilt: **wir wollen (idealerweise) eine möglichst große Zahl von Freiheitsgraden** für die Bestimmung unseres statistischen Kennwertes, denn alle Freiheitsgerade die nicht \"unterwegs verloren gehen\" (bei der Berechnung von Zwischenparametern), fließen in die Schätzung des Kennwertes ein und präzisieren damit dessen Schätzung.\n- Das Konzept der Freiheitsgrade wird **besonders wichtig bei komplexeren Modellen**, wie sie in Statistik 2 behandelt werden (multiple Regression). Dort gehen schnell eine große Zahl von Freiheitsgraden \"flöten\" und die Zahl der Freiheitsgrade muss daher bereits bei der Wahl eines Modells berücksichtig werden.\n:::\n:::\n::: {.column width=\"35%\"}\n\n![Bildnachweis^[https://www.facebook.com/SaraswathiAnalytics/photos/a.101349091331739/428667868599858]](images/df_cartoon.jpg){style=\"margin-top: 60px !important\"}\n\n:::\n::::\n\n:::{style=\"margin-top: -15px\"}\n:::{.nonincremental}\n- Der **Begriff \"Freiheitsgrad\" ist wenig intuitiv**, weil die Datenpunkte nur im Gedankenexperiment \"frei\" gewählt werden können &mdash; in Realität sind sie natürlich gegeben.\n- Ein intuitiverer Ausdruck wäre **effektive Stichprobengröße**: wie viele Datenpunkte aus meiner Stichprobe kann ich effektiv zur Schätzung meines statistischen Zielkennwerts nutzbar machen?\n:::\n::: -->\n\n\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## 3. Signifikanzniveau & ein/zweiseitige Testung\n\n**Erinnerung:**\n\n::: {.colorbox}\nDas **Signifikanzniveau** $\\alpha$ gibt legt ein Kriterium für die Ablehnung der Nullhypothese fest.<br><br>[Es gilt:]{.underline} ist $p<\\alpha$ lehnen wir die Nullhypothese ab und werten unseren Effekt als statistisch signifikant.\n:::\n\n:::: {.columns .fragment}\n::: {.column width=\"50%\"}\n\n:::{.nonincremental}\n- Der Wert $\\alpha$ wird auch Irrtumswahrscheinlichkeit genannt &mdash; sie gibt das Risiko an, mit dem wir bereit sind, die Nullhypothese fälschlicherweise abzulehnen.\n    - Beispiel: ist $\\alpha=0.05$, so gibt es eine 5%-ige Wahrscheinlichkeit, die Nullhypothese abzulehnen, *obwohl sie in Wahrheit zutrifft*.\n    - Je kleiner $\\alpha$, desto \"konservativer\" der Test, d.h. desto eher will ich vermeiden, einen Effekt fälschlicherweise als signifikant zu werten (erhöhe aber dabei mein Risko, einen wahren Effekt zu \"verpassen\").\n:::\n\n:::\n::: {.column width=\"50%\"}\n![](images/significance_level.png){style=\"margin-top:0px !important\"}\n:::\n::::\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## 3. Signifikanzniveau & ein/zweiseitige Testung\n\n- Abhänging davon, ob die Hypothese gerichtet bzw. ungerichtet wird ein einseitiger bzw. zweiseitiger t-Test durchgeführt.\n\n<!-- <div class=\"vspace-medium\"></div> -->\n\n<!---  Table --->\n|| Einseitiger Test<br>(gerichtete Hypothese) | Zweiseitiger Test<br>(ungerichtete Hypothese) |\n|-|:-:|:-:|\n| **Berechnung des kritischen t-Wertes** | ![](images/ttest1_alpha2.png) | ![](images/ttest1_alpha_ungerichtet2.png) |\n| **Berechnung des p-Wertes** | ![](images/ttest1_pvalue.png){style=\"margin-top:15px !important\"} | ![](images/ttest1_pvalue_ungerichtet.png){style=\"margin-top:15px !important\"} |\n\n: {tbl-colwidths=\"[33, 33, 33]\"}\n\n# t-Test für Mittelwertdifferenzen\n\n\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## t-Test für Mittelwertdifferenzen\n\n- Zur Erinnerung, bei einem statistischen Test zu Mittelwertdifferenzen stellen wir folgende Fragen: \n    - Unterscheidet sich ein Mittelwert signifikant von einem Referenzwert? (Einstichprobentest mit Einzelmessung)    \n    - Unterscheiden sich die Mittelwerte von zwei abhängigen Bedingungen signifikant voneinander? (Einstichprobentest mit zwei abhängigen Messungen)\n    - Unterscheiden sich die Mittelwerte von zwei unabhängigen Stichproben signifikant voneinander? (Zweistichprobentest)\n- Beispiel Paradoxia (Zweistichprobentest):\n\n:::{.fragment style=\"margin-top: 15px\"}\n![](images/mittelwertdifferenz_paradoxia.png){height=300px}\n:::\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## t-Test für Mittelwertdifferenzen\n\n:::{.nonincremental}\n- Um den t-Wert für eine Mittelwertdifferenz $\\Delta\\bar{x}$ zu erhalten, ersetzen wir $\\hat{\\theta}$ durch $\\Delta\\bar{x}$:\n:::\n\n$$\n\\text{t-Wert für Mittelwertdifferenz:}\\qquad t = \\frac{\\hat{\\theta}}{\\hat{se}} = \\frac{\\Delta\\bar{x}}{\\hat{se}}\n$$\n\n- Die Mittelwertdifferenz $\\Delta\\bar{x}$ ist einfach zu bestimmen, die zentrale Frage lautet daher: **wie berechnet sich der Standardfehler $\\hat{se}$ einer Mittelwertdifferenz $\\Delta\\bar{x}$?**\n\n\n::: {.merke style=\"margin-top: 130px; font-size: 26px\"}\n:::: {.columns}\n::: {.column width=\"5%\"}\n::: {style=\"margin-top: 18px\"}\n![](images/merke.png){height=\"55px\"}\n:::\n:::\n::: {.column width=\"95%\"}\nDer Standardfehler im Nenner des t-Wertes bezieht sich immer auf die Prüfgröße $\\hat{\\theta}$. Die Frage lautet also bei jedem t-Test: was ist der Standardfehler von $\\hat{\\theta}$ bzw. was ist die Standardabweichung der Stichprobenverteilung von $\\hat{\\theta}$?\n:::\n::::\n:::\n\n\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## [t-Test: Veranschaulichung der Standardfehler von Mittelwertdifferenzen]{style=\"font-size:37px\"}\n\n<div class=\"vspace-small\"></div>\n![](images/stichprobenverteilung_diff_v2.png)\n\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## [Standardfehler bei Mittelwertdifferenzen ($\\sigma$ unbekannt): Cheat sheet]{style=\"font-size:38px\"}\n\nDas folgende Cheat sheet gibt Ihnen eine Übersicht über die Berechnung des Standardfehlers $\\hat{se}$ von Mittelwertdifferenzen im Nenner der Prüfgröße $t=\\frac{\\Delta\\bar{x}}{\\hat{se}}$:\n\n<!---  Table --->\n|Fall|Berechnung des Standardfehlers $\\hat{se}$|\n|-|-|\n| **Differenz des Mittelwertes [einer Stichprobe]{.underline} und einem Referenzwert** $\\mu_0$<br>(&rarr; Einstichproben-t-Test) | $\\hat{se}=\\frac{\\hat{\\sigma}}{\\sqrt{n}}$ |\n| **Mittelwertdifferenz abhängiger Messungen A und B in [einer Stichprobe]{.underline}**<br>(&rarr; Differenzen-t-Test) |$\\hat{se} = \\frac{\\hat{\\sigma}_\\Delta}{\\sqrt{n}}\\qquad\\text{mit}$ \\\n$\\hat{\\sigma}_\\Delta=\\sqrt{\\hat{\\sigma}_A^2+\\hat{\\sigma}_B^2-2\\,\\hat{\\rho}\\hat{\\sigma}_A\\hat{\\sigma}_B}$ \\\n$\\text{oder}\\qquad\\hat{\\sigma}_\\Delta=\\sqrt{\\frac{1}{n-1}\\left(\\Delta x_i-\\Delta\\bar{x}\\right)^2}$ |\n| **Mittelwertdifferenz unabhängiger Messungen in [zwei Stichproben A und B]{.underline} (ähnliche Varianzen)**<br>(&rarr; Klassischer Zweistichproben-t-Test) | $\\hat{se} = \\hat{\\sigma}_\\text{pooled}\\sqrt{\\frac{1}{n_A}+\\frac{1}{n_B}}\\quad$[(siehe Herleitung)](#pooledvariance){style=\"color: darkred\"} \\\n$\\text{mit}\\quad \\hat{\\sigma}_\\text{pooled}=\\sqrt{\\frac{(n_A-1)\\hat{\\sigma}^2_A + (n_B-1)\\hat{\\sigma}^2_B}{n_A+n_B-2}}$ |\n| **Mittelwertdifferenz unabhängiger Messungen in [zwei Stichproben A und B]{.underline} (unähnliche Varianzen)**<br>(&rarr; Welch's Zweistichproben-t-Test) | $\\hat{se}= \\sqrt{\\frac{\\hat{\\sigma}_A^2}{n_A} + \\frac{\\hat{\\sigma}_B^2}{n_B}}$ |c\n\n: {tbl-colwidths=\"[50, 40]\"}\n\n\n<div class=\"vspace-small\"></div>\n\n::: {.merke style=\"font-size: 23px !important\"}\n:::: {.columns}\n::: {.column width=\"5%\"}\n::: {style=\"margin-top: 10px\"}\n![](images/merke.png){height=\"55px\"}\n:::\n:::\n::: {.column width=\"95%\"}\nDieses Cheat Sheet gilt für den Fall, dass die Populationsvarianzen $\\sigma^2_A$ bzw. $\\sigma^2_B$ **nicht bekannt** sind. In diesem Sinne ist es das in der Praxis relevante Cheat Sheet, da die Populationsvarianzen nahezu nie bekannt sind.\n:::\n::::\n:::\n\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## Zahl der Freiheitsgrade für t-Tests von Mittelwertdifferenzen\n\n<!-- <div class=\"vspace-medium\"></div> -->\n\n<!---  Table --->\n|Test|Frage|Zahl der Freiheitsgrade|\n|-|-|-|\n| **Einstichprobentest mit Einzelmessung** | Ist $\\bar{x}$ größer als ein Referenzwert $\\mu_0$? | $\\text{df} = n - 1$, da für die Berechnung von $t$ genau ein Zwischenparameter bestimmt werden muss (der Mittelwert $\\bar{x}$) |\n| **Einstichprobentest mit zwei abhängigen Messungen** | Unterscheiden sich die Mittelwerte $\\bar{x}_A$ und $\\bar{x}_B$ zwischen zwei Bedingungen A und B? In diesem Fall kann man auch fragen: ist der Mittelwert der Differenzvariable ($\\Delta\\bar{x}=\\overline{X_A-X_B}$) verschieden von Null? | $\\text{df} = n - 1$, da für die Berechnung von $t$ genau ein Zwischenparameter bestimmt werden muss (der Mittelwert $\\overline{X_A-X_B}$)|\n| **Zweistichprobentest (ähnliche Varianzen)** | Unterscheiden sich die Mittelwerte $\\bar{x}_A$ und $\\bar{x}_B$ zwischen zwei Gruppen A und B? ($\\Delta\\bar{x}=\\bar{x}_A-\\bar{x}_B$) |$\\text{df} = n_A + n_B - 2$, da für die Berechnung von $t$ genau zwei Zwischenparameter bestimmt werden müssen (die Mittelwerte $\\bar{x}_A$ und $\\bar{x}_B$)|\n| **Zweistichprobentest (unähnliche Varianzen, aka Welch's t-Test)** | Unterscheiden sich die Mittelwerte $\\bar{x}_A$ und $\\bar{x}_B$ zwischen zwei Gruppen A und B? ($\\Delta\\bar{x}=\\bar{x}_A-\\bar{x}_B$) | **Welch–Satterthwaite-Gleichung:** \\\n$\\text{df} = \\frac{\\left(\\frac{\\hat{\\sigma}_A^2}{n_A}+\\frac{\\hat{\\sigma}_B^2}{n_B}\\right)^2}{\\frac{\\left(\\hat{\\sigma}_A^2/n_A\\right)^2}{n_A-1}+\\frac{\\left(\\hat{\\sigma}_B^2/n_B\\right)^2}{n_B-1}}$ \\\nFalls $n_A=n_B=n:\\quad$[(siehe Intuition)](#welchsatterthwaiteintuition){style=\"color: darkred\"} $\\text{df}=(n-1)\\Big(1+\\frac{2}{\\left(\\frac{\\hat{\\sigma}_A}{\\hat{\\sigma}_B}\\right)^2+\\left(\\frac{\\hat{\\sigma}_B}{\\hat{\\sigma}_A}\\right)^2}\\Big)$ |\n\n: {tbl-colwidths=\"[23, 35, 42]\"}\n\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## Beispiel: t-Test für unabhängige Gruppen\n\n:::: {.columns}\n::: {.column width=\"80%\"}\n\nBetrachten wir das Beispiel Med- versus Psych-Nasen für den Fall, dass wir die Standardabweichungen $\\sigma_\\text{med}$ und $\\sigma_\\text{psych}$ von Nasenlängen in der Med- und Psych-Population [nicht]{.underline} kennen.\n\nEs gilt immer noch:\n\n$$\n\\Delta \\bar{x} = \\bar{x}_\\text{med} - \\bar{x}_\\text{psych} = 0.2cm\n$$\n\n:::{.fragment}\n.. aber $\\sigma_\\text{med}$ und $\\sigma_\\text{psych}$ müssen jetzt aus unseren Messwerten geschätzt werden. Für das Beispiel nehmen wir an:\n\n$$\n\\hat{\\sigma}_\\text{med} = 0.5\\qquad\\qquad\\hat{\\sigma}_\\text{psych} = 0.2\n$$\n:::\n\n:::{.fragment}\nWir schlagen die Formel für den Standardfehler bei unabhängigen Messungen und unähnlichen Varianzen ($\\frac{\\hat{\\sigma}_\\text{med}}{\\hat{\\sigma}_\\text{psych}} > 2\\;$!) nach und setzen ein:\n\n$$\n\\hat{se}= \\sqrt{\\frac{\\hat{\\sigma}_\\text{med}^2}{n_\\text{med}} + \\frac{\\hat{\\sigma}_\\text{psych}^2}{n_\\text{psych}}} \\overset{(Computer)}{\\approx}  0.098\n$$\n\n[(Erinnerung: es galt $n_\\text{med}=n_\\text{psych}=30$)]{style=\"font-size:20px\"}\n:::\n\n:::\n::: {.column width=\"20%\"}\n![](images/psych_med.png)\n:::\n::::\n\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## Beispiel: t-Test für unabhängige Gruppen\n\n:::: {.columns}\n::: {.column width=\"60%\"}\n\nMit dem Standardfehler bewaffnet, können wir nun den t-Wert berechnen:\n\n:::{style=\"margin-top: -37px; margin-left: 30px\"}\n$$\nt = \\frac{\\Delta \\bar{x}}{\\hat{se}} = \\frac{0.2}{0.098} \\approx 2.03\n$$\n:::\n\n:::{.fragment}\nEs fehlen noch die Freiheitsgrade. Bei ungleichen Varianzen ist die Formel recht sperrig:\n\n:::{style=\"margin-top: -10px\"}\n$$\n\\begin{aligned}\n\\text{df}&=(n-1)\\Big(1+\\frac{2}{\\left(\\frac{\\hat{\\sigma}_\\text{med}}{\\hat{\\sigma}_\\text{psych}}\\right)^2+\\left(\\frac{\\hat{\\sigma}_\\text{psych}}{\\hat{\\sigma}_\\text{med}}\\right)^2}\\Big) = \\\\\n&=(30-1)\\Big(1+\\frac{2}{\\left(\\frac{0.5}{0.2}\\right)^2+\\left(\\frac{0.2}{0.5}\\right)^2}\\Big) \\approx 38.05\n\\end{aligned}\n$$\n:::\n\n:::\n\n:::\n::: {.column width=\"40%\"}\n![](images/ttest1_example_v2.png)\n:::\n::::\n\n:::{.fragment}\n:::{style=\"margin-top: -12px\"}\nAufgrund der gerichteten (positiven) Hypothese ist der p-Wert die Fläche *rechts des t-Wertes* unter der t-Verteilung:\n:::\n\n:::{style=\"margin-top: -35px; margin-left: 120px\"}\n$$\np=\\int_{t}^{\\infty}f_t(x|\\scriptsize\\text{df}\\normalsize)dx = \\int_{2.03}^{\\infty}f_t(x|38.05)dx = 1-F_t(2.03|38.05) \\overset{(Computer)}{\\approx} 0.025\n$$\n:::\n:::\n\n:::{.fragment}\nDer p-Wert ist dem p-Wert des z-Tests ($0.023$) sehr ähnlich. Dies ist wenig überraschend, da a) der Standardfehler einen ähnlichen Wert aufwies ($se=0.1$ beim z-Test) und b) die Zahl er Freiheitsgrade so hoch ist, dass der Unterschied Normalverteilung vs. t-Verteilung marginal ist.\n:::\n\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## t-Test für unabhängige Stichproben\n\n**Klassischer Zweistichproben-t-Test (ähnliche Varianzen) versus Welch's t-Test (unterschiedliche Varianzen) &mdash; welcher der beiden Tests sollte nun verwendet werden?**\n\n:::{.nonincremental}\n- In der Psychologie sind ungleiche Varianzen die realistischere Annahme. Selbst bei randomisiert-kontrollierten Studien, bei denen Versuchspersonen den Gruppen aus einer identischen Ursprungs-Population zugewiesen werden, kann das Treatment selbst einen Einfluss auf die Varianz haben.\n- Neben der Faustformel $0.5\\le\\frac{\\hat{\\sigma}_A}{\\hat{\\sigma}_B}\\le2$ gibt es auch Testverfahren zur Überprüfung der Varianzgleichheit zwischen Gruppen, allerdings sind diese nicht unproblematisch\n    - Ein Grund:auf Varianzgleichheit wird idR auf Basis eines nicht-signifikanten Ergebnis in einem solchen Test angenommen &mdash; \"absence of evidence is not evidence of absence\"^[Altman DG, Bland JM (1995) Absence of evidence is not evidence of absence. BMJ 311:485.]\n:::\n\n\n:::{style=\"margin-top: -15px\"}\n:::: {.columns}\n::: {.column width=\"66%\"}\n:::{.nonincremental}\n- Herrscht Varianzgleichheit vor und ist die Stichprobengröße nicht extrem klein in einer Gruppe, kommen der Student'sche t-Test und Welch's t-Test zu sehr ähnlichen Ergebnissen.\n- Vor diesem Hintergrund wird empfohlen^[Delacre M, Lakens D, Leys C (2017) Why Psychologists Should by Default Use Welch’s t-test Instead of Student’s t-test. International Review of Social Psychology 30:92.], bereits ab moderaten Gruppengrößen (ca. $n\\ge 8$ pro Gruppe) *immer* Welch's t-Test anzuwenden. In den meisten Statistikprogrammen ist dieser Test implementiert.\n:::\n:::\n::: {.column width=\"34%\"}\n\n\n![Option für Welch's t-test in JASP.](images/welch_jasp.png){height=270px style=\"margin-top:-20px\"}\n\n:::\n::::\n:::\n\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## Beispiel: t-Test für abhängige Messungen\n\n:::: {.columns}\n::: {.column width=\"80%\"}\nSie führen ein Experiment *innerhalb der Med-Gruppe* (n=32) durch. In einer experimentellen Intervention stellen Sie den Med-Studierenden die Frage \n\n> Studieren Sie Medizin, weil es der Wunsch Ihrer Eltern ist? \n\nSie messen die Nasenlängen dabei sowohl vor (\"pre\"), als auch nach (\"post\") der Intervention. Ihre [ungerichtete]{.underline} Hypothese ist, dass sich die Nasenlängen vor und nach der Intervention auf einem Signifikanzniveau $\\alpha=0.05$ unterscheiden.\n:::\n::: {.column width=\"20%\"}\n![](images/med.png)\n:::\n::::\n\n:::{.fragment}\nDie Mittelwertdifferenz betrage $\\Delta\\bar{x} = \\bar{x}_\\text{post} - \\bar{x}_\\text{pre} = 0.1cm$.\n:::\n\n<div class=\"vspace-small\"></div>\n\n\n:::{.fragment}\nWir nehmen der Einfachheit halber an, dass die beiden Messungen $X_\\text{pre}$ und $X_\\text{post}$ unkorreliert sind, d.h. $\\hat{\\rho}=0$. Die Standardabweichungen seien $\\hat{\\sigma}_\\text{pre}=\\hat{\\sigma}_\\text{post}=0.5$. Die Standardabweichung $\\hat{\\sigma}_\\Delta$ der Differenzvariable $\\Delta X$ ist damit:\n:::\n\n:::{.fragment}\n$$\n\\hat{\\sigma}_\\Delta=\\sqrt{\\hat{\\sigma}_\\text{pre}^2+\\hat{\\sigma}_\\text{post}^2-2\\,\\hat{\\rho}\\hat{\\sigma}_\\text{pre}\\hat{\\sigma}_\\text{post}} = \\sqrt{(0.5)^2+(0.5)^2-0} = \\frac{1}{\\sqrt{2}}\n$$\n:::\n\n:::{.fragment}\n$$\n\\text{Standardfehler:}\\qquad \\hat{se}=\\frac{\\hat{\\sigma}_\\Delta}{\\sqrt{n}} = \\frac{1}{\\sqrt{2}\\sqrt{32}}=\\frac{1}{8}\n$$\n\n:::\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## Beispiel: t-Test für abhängige Messungen\n\n:::: {.columns}\n::: {.column width=\"60%\"}\n\nNun können wir den t-Wert berechnen:\n\n$$\nt = \\frac{\\Delta\\bar{x}}{\\hat{se}} = \\frac{0.1}{1/8} = 0.8\n$$\n\n:::{.fragment}\nAufgrund der ungerichteten Hypothese ist der p-Wert die Summe der Flächen unter der t-Verteilung links von $-|t|=-0.8$ [und]{.underline} rechts von $+|t|=0.8$.\n\nBei $\\text{df}=n-1=31$ Freiheitsgraden gilt:\n:::\n:::\n::: {.column width=\"40%\"}\n![](images/ttest1_example2_v2.png)\n:::\n::::\n\n\n:::{.fragment}\n$$\n\\begin{aligned}\np&=\\int_{-\\infty}^{-t}f_t(x|\\scriptsize\\text{df}\\normalsize)dx + \\int_{t}^{\\infty}f_t(x|\\scriptsize\\text{df}\\normalsize)dx \\overset{(Symmetrie)}{=} 2\\cdot\\int_{-\\infty}^{-t}f_t(x|\\scriptsize\\text{df}\\normalsize)dx  = \\\\\n&= 2\\cdot F_t(-t|\\scriptsize\\text{df}\\normalsize) \\overset{(einsetzen)}{=} 2\\cdot F_t(-0.8|31) \\overset{(Computer)}{=} 0.43\n\\end{aligned}\n$$\n:::\n\n:::{.fragment style=\"margin-top:60px\"}\nDer p-Wert ist also deutlich größer als unser Signifikanzniveau $\\alpha=0.05$ und wir können die Nullhypothese $\\Delta\\bar{x}=0$ nicht ablehnen. More research is needed!\n:::\n\n\n\n\n# t-Test für die Korrelation\n\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## Stichprobenverteilung der Korrelation $\\hat{\\rho}$\n\n:::: {.columns}\n::: {.column width=\"60%\"}\n\n:::{.nonincremental}\n- Analog zu Mittelwertsunterschieden kann auch die **Stichprobenverteilung der Korrelation** aufgestellt werden: als **Normalverteilung** mit dem **Mittelwert unserer Kennwertschätzung (hier $\\hat{\\rho}$)** und einer Streuung, die dem **Standardfehler** ($\\hat{se}$) des Kennwertes entspricht.\n:::\n\n:::{style=\"margin-top: -15px\"}\n- Den Standardfehler der Korrelation haben wir bereits in Vorlesung 08 kennengelernt:\n:::\n\n:::{.fragment style=\"margin-top: -15px\"}\n$$\n\\hat{se}(\\hat{\\rho}) = \\sqrt{\\frac{1-\\hat{\\rho}^2}{n-2}}\n$$\n:::\n\n:::\n::: {.column width=\"40%\"}\n![](images/nulldist_rho.png)\n:::\n::::\n\n:::{.fragment}\n:::{.nonincremental}\n- Auch dieser Standardfehler ist eine Schätzung auf Basis der Stichprobe und entsprechend stellt die standardisierte Prüfgröße einen t-Wert dar:\n:::\n\n:::{style=\"margin-top: -15px\"}\n$$\nt = \\frac{\\hat{\\rho}}{\\hat{se}(\\hat{\\rho})} = \\hat{\\rho}\\sqrt{\\frac{n-2}{1-\\hat{\\rho}^2}}\n$$\n:::\n:::\n\n:::{.fragment}\n[(Präziser gesagt handelt es sich auch hier wieder um das Verhältnis einer normalverteilten Variable ($\\hat{\\rho}$) und einer chi-verteilten Variable ($\\hat{se}(\\hat{\\rho})$) &mdash; ein solches Verhältnis führt zu einer t-verteilten Prüfgröße)]{style=\"font-size: 23px\"}\n:::\n\n\n\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## Nullhypothese und Hypothesentestung bei Korrelationen\n\n:::: {.columns}\n::: {.column width=\"60%\"}\n\n:::{.nonincremental}\n- Die **Nullhypothesenverteilung** der Korrelation ist also eine **t-Verteilung**.\n- Die Nullhypothese entspricht der Annahme, dass der wahre Zusammenhang in der Population $\\rho = 0$ ist.\n:::\n\n:::{style=\"margin-top: -15px\"}\n- Auch hier können wir gerichtete und ungerichtete Hypothesen testen:\n    - Gerichtete Hypothesen: \n        - die Korrelation ist größer 0 ($\\rho>0$)\n        - die Korrelation ist kleiner 0 ($\\rho<0$)\n    - Ungerichtete Hypothese: die Korrelation ist ungleich 0 ($\\rho\\neq 0$)\n:::\n:::\n::: {.column width=\"40%\"}\n\n![](images/ttest1_rho.png)\n\n:::\n::::\n\n- Die Berechnung der p-Werte erfolgt analog wie bei Mittelwertunterschieden.\n\n::: {.merke .fragment}\n:::: {.columns}\n::: {.column width=\"5%\"}\n::: {style=\"margin-top: 18px\"}\n![](images/merke.png){height=\"55px\"}\n:::\n:::\n::: {.column width=\"95%\"}\nDie Zahl der Freiheitsgrade der Korrelation ist $\\text{df}=n-2$. Grund: die Streuung $\\hat{se}$ im Nenner des t-Wertes enthält den Korrelationskoeffizient $\\hat{\\rho}$ und dieser involviert die Berechnung von **zwei** Mittelwerten (Mittelwert $\\bar{x}$ der Variable $X$ und Mittelwert $\\bar{y}$ der Variable $Y$).\n:::\n::::\n:::\n\n\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## Beispiel: Bestimmung des p-Wertes bei der Korrelation\n\n:::{.nonincremental}\n- Nehmen wir an, die Korrelation von Größe und Gewicht in einer Stichprobe von $n=12$ betrage $\\hat{\\rho}=0.4$.\n:::\n:::{style=\"margin-top: -15px\"}\n- Wir wollen testen, ob die Korrelation auf einem Signifikanzniveau $\\alpha=0.05$ signifikant größer als 0 ist.\n:::\n\n:::: {.columns}\n::: {.column width=\"55%\"}\n\n- Berechnung von der Prüfgröße $t$:\n\n:::{.fragment}\n$$\nt = \\hat{\\rho}\\sqrt{\\frac{n-2}{1-\\hat{\\rho}^2}} = 0.4\\sqrt{\\frac{12-2}{1-0.4^2}} \\overset{(Computer)}{=} 1.38\n$$\n:::\n\n- Wir sehen in der Tabelle, dass der kritische t-Wert für $\\text{df}=n-2=10$ Freiheitsgrade bei einem (einseitigen!) Signifikanzniveau von $\\alpha=0.05$ gleich $1.813$ beträgt.\n- Die Nullhypothese wird also nicht abgelehnt, und der Effekt als nicht signifikant gewertet.\n\n:::\n::: {.column width=\"45%\"}\n:::{.fragment}\n![](images/ttable_r.png)\n:::\n:::\n::::\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## Beispiel: Bestimmung des p-Wertes bei der Korrelation\n\n:::: {.columns}\n::: {.column width=\"61%\"}\n:::{.nonincremental}\n- Statistische Programme geben den p-Wert in der Regel automatisch mit an und es ist somit ersichtlich,  ob es sich um eine statistisch signifikante Korrelation handelt.\n:::\n:::{style=\"margin-top: -15px\"}\n- **Standardmäßig** handelt es sich dabei immer um einen **Test für eine ungerichtete Hypothese**. \n- War die Hypothese dagegen gerichtet, gilt:\n    - Halbiere den p-Wert der ungerichteten Hypothese, falls das Vorzeichen von $\\hat{\\rho}$ in Richtung der Hypothese ist.\n    - Verdoppele den p-Wert der ungerichteten Hypothese, falls das Vorzeichen von $\\hat{\\rho}$ in gegensätzlicher Richtung der Hypothese ist.\n    - Im Beispiel wäre also der Korrelationskoeffizient $2\\times 0.198=0.396$, falls wir einen negativen Zusammenhang vorhergesagt hätten, und $0.198/2=0.099$, falls wir einen positiven Zusammenhang vorhergesagt hätten.\n:::\n:::\n::: {.column width=\"39%\"}\n\n<div class=\"vspace-medium\"></div>\n\n![Auswahl in JASP: Regression &rarr; Klassisch &rarr; Korrelation. Zusätzliche Selektion des Streudiagramms.](images/jasp_weight_height.png){width=375px}\n:::\n::::\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n##\n:::: {.columns}\n::: {.column width=\"9%\"}\n::: {style=\"margin-top:-15px\"}\n![](images/summary.png){width=60px}\n:::\n:::\n::: {.column width=\"91%\"}\n::: {.summary style=\"margin-top: 10px; margin-bottom: -15px; padding-top: 0px; padding-bottom: 0px;\"}\n::: {style=\"margin-bottom: -15px;\"}\n- Wird der Standardfehler auf Basis der Stichprobe als $\\hat{se}$ geschätzt, folgt die Prüfgröße $\\frac{\\hat{\\theta}}{\\hat{se}}(=t)$ einer **t-Verteilung**.\n- Die t-Verteilung **nähert sich für $n\\rightarrow\\infty$ der Standardnormalverteilung an**. Bei **kleineren Fallzahlen $n$** hat die t-Verteilung etwas **dickere Flanken**.\n- Der **prinzipielle Ansatz ist beim t-Test identisch zum z-Test**: Bestimmung der Fläche für Wertebereiche extremer als die Prüfgröße (hier $t$).\n- **t-Test von Mittelwertdifferenzen** ($t=\\frac{\\Delta\\bar{x}}{\\hat{se}}$): je nach Szenario werden unter- schiedliche t-Test-Varianten angwendet. Sie unterscheiden sich hinsichtlich:\n    - Zahl der Freiheitsgrade $\\text{df}$\n    - Standardfehler $\\hat{se}$\n- **Korrelation**: Berechnung des t-Wertes erfolgt analog mittels $t = \\frac{\\hat{\\rho}}{\\hat{se}(\\hat{\\rho})}$.\n    - Der Standardfehler der Korrelation hängt von der Korrelation $\\hat{\\rho}$ und der Stichprobengröße $n$ ab: $\\hat{se}(\\hat{\\rho}) = \\sqrt{\\frac{1-\\hat{\\rho}^2}{n-2}}$\n- Auch für Regressionskoeffizienten lassen sich t-Tests durchführen &rightarrow;&nbsp;[Bonuscontent](#treg){style=\"color: darkred;\"}\n:::\n:::\n:::\n::::\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## {.blackslide .center}\n\n<div class=\"vspace-small\"></div>\n\n:::: {.columns}\n::: {.column width=\"68%\"}\n\n![](images/paradoxia_histogram_correlation_paradoxiker.png){height=300px}\n\n:::\n::: {.column width=\"32%\"}\n::: {.content-hidden when-format=\"pdf\"}\n\n![](images/paradoxia_group_of_scientists.png){.hcenter-image height=250px style=\"margin-top:-20px !important; margin-left:-20px !important\"}\n\n:::\n:::\n::::\n\n\nStichwort Signifikanz von Zusammenhängen: die Signifikanz des unerwarteten Zusammenhangs von TikTok-Onlinezeit und Entzündungswerten haben Sie bislang nicht getestet.\n\nBasierend auf dem Korrelationskoeffizienten $\\hat{\\rho}=0.517$ und der Stichprobengröße $n=50$ ergibt sich die Prüfgröße $t$ direkt:\n\n<div class=\"vspace-small\"></div>\n\n$$\nt = \\frac{\\hat{\\rho}}{\\hat{se}(\\hat{\\rho})} = \\hat{\\rho}\\sqrt{\\frac{n-2}{1-\\hat{\\rho}^2}} = 0.517\\sqrt{\\frac{50-2}{1-0.517^2}} = 4.18\n$$\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## {.blackslide .center}\n\n<div class=\"vspace-small\"></div>\n\n:::: {.columns}\n::: {.column width=\"60%\"}\n\nDer Zusammenhang war unerwartet und es gab dementsprechend keine gerichtete Hypothese. Der p-Wert ist in diesem Fall also der doppelte Wert der Fläche rechts des (positiven) t-Werts von $4.18$, oder analog, der doppelte Wert links des negierten t-Werts $-4.18$.\n\n$$\np=2\\int_{-\\infty}^{-4.18}f_t(x|\\scriptsize\\text{df}\\normalsize)dx = 2F_t(-4.18|48)=0.0001\n$$\n\n[(Die Zahl der Freiheitsgrade beim t-Test der Korrelation ist $n-2$)]{style=\"font-size:24px\"}\n\n\n:::\n::: {.column width=\"40%\"}\n::: {.content-hidden when-format=\"pdf\"}\n\n![](images/paradoxia_nulldist_t_r.png)\n\n:::\n:::\n::::\n\n\nDer Zusammenhang von TikTok-Onlinezeit und Entzündungswerten ist also deutlich signifikant.\n\nTrotz des hochsignifikanten Effektes bleiben Sie skeptisch &mdash; Ihr größtes Fragezeichen: was ist Ursache, was ist Wirkung? Folgen erhöhte Entzündungswerte tatsächlich auf TikTok-Konsum (einschlägiger Kanäle)? Oder ist es einfach so, dass Erkrankte (mit erhöhten Entzündungswerten) Rat und Solidarität auf TikTok suchen?\n\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## {.blackslide .center}\n\n<div class=\"vspace-small\"></div>\n\n:::: {.columns}\n::: {.column width=\"68%\"}\nUm die Gruppen*unterschiede* nun ebenfalls mithilfe des t-Tests zu überprüfen, listen Sie nochmals alle relevanten  Werte auf, die Sie zum Teil bereits beim z-Test bestimmt hatten:\n\n<!---  Table --->\n||Fallzahl $n$|$\\Delta\\bar{x}$ |Standardfehler $\\hat{se}$|Freiheitsgrade $\\text{df}$|\n|-|-|-|-|-|\n| [TikTok]{.underline} | $2\\times 50$ | $0.577$ | ${0.123}$ | $93.7$ |\n| [Entzündung]{.underline} | $2\\times 50$ |$0.0243$ | ${0.0147}$ | $96.2$ |\n\n: {tbl-colwidths=\"[18, 18, 10, 27, 27]\"}\n\n\n:::\n::: {.column width=\"32%\"}\n::: {.content-hidden when-format=\"pdf\"}\n\n![](images/paradoxia_group_of_scientists.png){.hcenter-image height=200px style=\"margin-top:-20px !important\"}\n\n:::\n:::\n::::\n\n<div class=\"vspace-medium\"></div>\n\n:::{.nonincremental}\n- Neu hinzugekommen sind die Freiheitsgrade, die Sie in der Tabelle mit der Formel für ungleiche Varianzen bestimmt haben:\n:::\n\n$$\n\\text{df}=(n-1)\\Big(1+\\frac{2}{\\left(\\frac{\\hat{\\sigma}_\\text{control}}{\\hat{\\sigma}_\\text{paradoxia}}\\right)^2+\\left(\\frac{\\hat{\\sigma}_\\text{paradoxia}}{\\hat{\\sigma}_\\text{control}}\\right)^2}\\Big) \n$$\n\n:::{.nonincremental}\n- Zur Erinnerung:\n    - TikTok: $\\hat{\\sigma}_\\text{control}=0.55$; $\\hat{\\sigma}_\\text{paradoxia}=0.68$ \n    - Entzündung: $\\hat{\\sigma}_\\text{control}=0.068$; $\\hat{\\sigma}_\\text{paradoxia}=0.078$\n:::\n\n\n\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## {.blackslide .center}\n\n<div class=\"vspace-small\"></div>\n\n:::: {.columns}\n::: {.column width=\"68%\"}\n \nMit diesen Information erhalten Sie folgende t-Werte (* in diesem Fall identisch mit den z-Werten!):\n\n$$\n\\text{TikTok:}\\qquad t=\\frac{\\Delta\\bar{x}}{\\hat{se}} = \\frac{0.577}{0.123} = 4.69\\\\\n\\text{Entzündung:}\\qquad t=\\frac{\\Delta\\bar{x}}{\\hat{se}} = \\frac{0.0243}{0.0147} = 1.65\n$$\n\n\n:::\n::: {.column width=\"32%\"}\n::: {.content-hidden when-format=\"pdf\"}\n\n![](images/paradoxia_group_of_scientists.png){.hcenter-image height=200px style=\"margin-top:-20px !important\"}\n\n:::\n:::\n::::\n\n:::: {.columns}\n::: {.column width=\"60%\"}\nStatt der Standardnormalverteilung integrieren Sie nun einfach die entsprechende Fläche unter der t-Verteilung:\n\n$$\np=\\int_{t}^{\\infty}f_t(x|\\scriptsize\\text{df}\\normalsize)dx = 1-F_t(t|\\scriptsize\\text{df}\\normalsize)\n$$\n\n:::\n::: {.column width=\"40%\"}\n\n![](images/paradoxia_nulldist_t.png)\n\n:::\n::::\n\n[(*) Warum identisch? Weil wir für die z-Werte &mdash; in Abwesenheit anderweitig bekannter Werte &mdash; ebenfalls die Stichprobenstreuung verwendet hatten.]{style=\"font-size: 23px; margin-top: 15px;\"}\n\n\n## {.blackslide .center}\n\n<!-- <div class=\"vspace-small\"></div> -->\n\n:::: {.columns}\n::: {.column width=\"68%\"}\n\n:::{style=\"margin-top: -15px\"}\nDie große Frage ist: würden weiterhin beide Effekte signifikant bleiben? Antwort:\n:::\n\n<!-- <div class=\"vspace-small\"></div> -->\n\n$$\n\\text{TikTok:}\\qquad p= 1 - F_t(4.83|93.7) \\overset{\\text{(Computer)}}{=} 0.000003\n$$\n\n<div class=\"vspace-small\"></div>\n\n$$\n\\text{Entzündung:}\\qquad p= 1 - F_t(1.65|96.2) \\overset{\\text{(Computer)}}{=} 0.051\n$$\n\n:::\n::: {.column width=\"32%\"}\n::: {.content-hidden when-format=\"pdf\"}\n![](images/paradoxia_group_of_scientists.png){.hcenter-image height=200px style=\"margin-top:-20px !important\"}\n\n:::\n:::\n::::\n\n\nKurios &mdash; das Pendel beim Entzündungseffekt schlägt exakt auf der anderen Seite des Signifikanzniveaus aus! Der Effekt ist nun nicht mehr signifikant. Der TikTok-Effekt bleibt stabil.\n\nBei beiden Effekten zeigt sich die leicht konservativere Natur der t-Verteilung. Die stärkeren Flanken im Vergleich zur Normalverteilung führen zu geringfügig höheren p-Werten. Notgedrungen müssen Sie Ihre zentrale Grafik anpassen und das Signifikanzsternchen beim Entzündungseffekt entfernen:\n\n![](images/paradoxia_histogram_inflammation_sem_nonsig.png){height=270px}\n\n\n<!-- ```{python}\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport os\nfrom scipy.stats import sem\nimport seaborn as sns\n\nnp.random.seed(0)\nroot = '/home/matteo/OneDrive/lehre/Statistik/stats1_lecture/book/'\n\nfontsize = 15\n\ndf = pd.read_csv(os.path.join(root, 'data', 'paradoxia.csv'))\n# print(df.head())\n\ndata_tiktok_control = df[df.group == 1]['hours_tiktok_per_day'].values\ndata_tiktok_paradoxia = df[df.group == 2]['hours_tiktok_per_day'].values\ndata_inflam_control = df[df.group == 1]['inflammation'].values\ndata_inflam_paradoxia = df[df.group == 2]['inflammation'].values\n\nprint(f'Mean TikTok Control: {np.mean(data_tiktok_control):.2f}')\nprint(f'Mean TikTok Paradoxia: {np.mean(data_tiktok_paradoxia):.2f}')\nprint(f'Mean Inflam Control: {np.mean(data_inflam_control):.2f}')\nprint(f'Mean Inflam Paradoxia: {np.mean(data_inflam_paradoxia):.2f}')\n\nplt.style.use('dark_background')\nplt.figure(figsize=(6, 2.5))\nax = plt.subplot(121)\nplt.gca().set_facecolor('#eee')\nsns.stripplot(data=df, x='group', y='hours_tiktok_per_day', color='#bbb', jitter=0.25)\ncolor = 'k'\nplt.errorbar([0], [np.mean(data_tiktok_control)], yerr=[sem(data_tiktok_control)], fmt='o', markersize=4, capsize=10, capthick=1.5, elinewidth=1.5, ecolor=color, mfc=color, mec=color, zorder=3)\nplt.errorbar([1], [np.mean(data_tiktok_paradoxia)], yerr=[sem(data_tiktok_paradoxia)], fmt='o', markersize=4, capsize=10, capthick=1.5, elinewidth=1.5, ecolor=color, mfc=color, mec=color, zorder=3)\nplt.text(0.25, 0.85, r'$\\bar{x}=' + f'{np.mean(data_tiktok_control):.2f}$', ha='center', color='k', fontsize=fontsize-1, transform=ax.transAxes)\nplt.text(0.75, 0.85, r'$\\bar{x}=' + f'{np.mean(data_tiktok_paradoxia):.2f}$', ha='center', color='k', fontsize=fontsize-1, transform=ax.transAxes)\nplt.plot([0, 1], [2.4, 2.4], 'k-', lw=2, zorder=4)\nplt.text(0.5, 2.32, '***', ha='center', va='center', fontsize=15, color='k', backgroundcolor='#eee', zorder=5)\n\nplt.xticks([0, 1], ['Kontroll', 'Paradoxia'], fontsize=fontsize)\nplt.yticks(fontsize=fontsize-2)\nplt.ylabel('Stunden TikTok / 24h', fontsize=fontsize)\nplt.xlabel('')\n# plt.xlim(-0.5, 1.5)\nplt.ylim(0, 1.1*max(data_tiktok_control.max(), data_tiktok_paradoxia.max()))\n\n\nax = plt.subplot(122)\nplt.gca().set_facecolor('#eee')\nsns.stripplot(data=df, x='group', y='inflammation', color='#bbb', jitter=0.25)\ncolor = 'k'\nplt.errorbar([0], [np.mean(data_inflam_control)], yerr=[sem(data_inflam_control)], fmt='o', markersize=4, capsize=10, capthick=1.5, elinewidth=1.5, ecolor=color, mfc=color, mec=color, zorder=3)\nplt.errorbar([1], [np.mean(data_inflam_paradoxia)], yerr=[sem(data_inflam_paradoxia)], fmt='o', markersize=4, capsize=10, capthick=1.5, elinewidth=1.5, ecolor=color, mfc=color, mec=color, zorder=3)\nplt.text(0.25, 0.85, r'$\\bar{x}=' + f'{np.mean(data_inflam_control):.2f}$', ha='center', color='k', fontsize=fontsize-1, transform=ax.transAxes)\nplt.text(0.75, 0.85, r'$\\bar{x}=' + f'{np.mean(data_inflam_paradoxia):.2f}$', ha='center', color='k', fontsize=fontsize-1, transform=ax.transAxes)\n# plt.plot([0, 1], [0.25, 0.25], 'k-', lw=2, zorder=4)\n# plt.text(0.5, 0.24, '*', ha='center', va='center', fontsize=15, color='k', backgroundcolor='#eee', zorder=5)\n\nplt.xticks([0, 1], ['Kontroll', 'Paradoxia'], fontsize=fontsize)\nplt.yticks(fontsize=fontsize-2)\nplt.ylabel('Entzündungswert', fontsize=fontsize)\nplt.xlabel('')\nplt.xlim(-0.5, 1.5)\nplt.ylim(0, 1.1*max(data_inflam_control.max(), data_inflam_paradoxia.max()))\n\n\nplt.tight_layout()\n\nplt.savefig('images/paradoxia_histogram_inflammation_sem_nonsig.png', bbox_inches='tight')\n``` -->\n\n## {.blackslide .center}\n\n::: {.content-hidden when-format=\"pdf\"}\n![](images/paradoxia_group_of_scientists.png){.hcenter-image height=300px}\n<!-- Source: Midjourney -->\n<div class=\"vspace-small\"></div>\n:::\n\nVor dem Hintergrund dieser neuen Ergebnisse, stellen sich eine Reihe von Fragen:\n\n- Ist die Interpretation der Signifikanz fundamental verschieden zwischen dem z- und dem t-Test?\n- Ist die Entzündungshypothese eindeutig widerlegt?\n- Können Sie aus dem hochsignifikanten Effekt der TikTok-Hypothese und dem nicht-signifikanten Effekt der Entzündungshypothese schlussfolgern, dass der TikTok-Effekt signifikant stärker ist?\n- Können Sie schlusfolgern, dass Paradoxia eindeutig durch den TikTok-Effekt verursacht wird?\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n<!-- ## {.center}\n\n![[xkcd#1347](https://xkcd.com/1347/)](images/xkcd1347.png)\n\n- Siehe auch [https://www.explainxkcd.com/wiki/index.php/1347](https://www.explainxkcd.com/wiki/index.php/1347)\n -->\n\n# [Bonuscontent]{color=\"darkred\"}\n\n\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## [t-Test & Normalverteilung]{color=\"darkred\"}{#tnormal}\n\n![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=110px}\n\n:::: {.columns}\n::: {.column width=\"43%\"}\n\n**Warum ist die Normalverteilung des Merkmals $X$ eine (theoretische) Vorausetzung für den t-Test?** \n\nEigentlich hatten wir ja festgestellt, dass Stichprobenverteilungen der Kennwerte $\\hat{\\theta}$ *unabhängig von der Verteilung des Merkmals* $X$ normalverteilt sind (vgl. zentraler Grenzwertsatz / Vorlesung 08).\n\n:::\n::: {.column width=\"57%\"}\n![](images/central_limit_theorem_average.png){height=225px style=\"margin-top: 15px !important\"}\n:::\n::::\n\n::: {style=\"margin-top: 8px\"}\n:::{.fragment}\n[Ein Grund:]{.underline} damit $t=\\hat{\\theta}/\\hat{se}$ einer t-Verteilung folgt, müssen der Stichprobenkennwert $\\hat{\\theta}$ und sein Standardfehler $\\hat{se}$ unabhängig sein (dürfen nicht korrelieren). Dies ist genau dann erfüllt, *wenn das gemessene Merkmal $X$ einer Normalverteilung folgt* &mdash; tatsächlich lässt sich genau mit dieser Bedingung die Normalverteilung ableiten. Insofern wirkt sich hier die Merkmalsverteilung von $X$ doch auf die Stichprobenverteilung von $\\hat{\\theta}$ aus.\n<!-- - Der zentrale Grenzwertsatz für die Stichprobenverteilung von $\\hat{\\theta}$ gilt streng genommen nur für $n\\rightarrow\\infty$, was in empirischen Studien nie gegeben ist. Ist die Stichprobengröße $n$ begrenzt, kann die Stichprobenverteilung von $\\hat{\\theta}$ nur dann als normalverteilt angenommen werden, wenn auch das gemessene Merkmal $X$ in der Population normalverteilt ist ([Satz von Cramer](https://de.wikipedia.org/wiki/Satz_von_Cram%C3%A9r_(Normalverteilung))). -->\n:::\n\n:::\n\n:::{.fragment style=\"margin-top: 35px\"}\n**Aber wie erwähnt: trotz dieses theoretischen Fallstricks ist der t-Test in der Praxis<br>auch bei nicht-normalverteilten Populationsvariablen $X$ recht robust.**\n:::\n\n\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## [Die t-Verteilung ist bereits standardisiert]{color=\"darkred\"}\n\n![](images/kein_klausurstoff.png){.absolute top=295 right=0 height=100px}\n\nVor der Einführung des z-Tests hatten wir zunächst die **unstandardisierte Normalverteilung** kennengelernt, die durch zwei Parameter definiert ist: Mittelwert $\\mu$ und Standardabweichung $\\sigma$:\n\n$$\nf(x)=\\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^2}\n$$\n\nVerwenden wir statt $x$ die standardisierte Variable $\\frac{x-\\mu}{\\sigma}$, vereinfacht sich die Nullhypothesen-Verteilung zur **Standardnormalverteilung**:\n\n:::{style=\"margin-top: -10px\"}\n$$\nf(x)=\\varphi(x)=\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{x^2}{2}}\n$$\n:::\n\nDie Standardnormalverteilung hat keinen Parameter mehr (nur noch die *Variable* $x$). Da es sich beim z-Wert auch um eine standardisierte Variable handelte, konnten wir auch für $z$ eine Standardnormalverteilung annehmen:\n\n:::{style=\"margin-top: -10px\"}\n$$\nf(z)=\\varphi(z)=\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{z^2}{2}}\n$$\n:::\n\nDie **t-Verteilung** hatten wir dagegen direkt auf Basis der standardisierten Prüfgröße $\\frac{\\hat{\\theta}}{\\hat{se}}$ eingeführt. [**Die klassische t-Verteilung ist aus diesem Grund bereits eine *standardisierte Verteilung*, die nicht mehr vom Mittelwert oder Streuung abhängt.**]{color=\"navy\"} Im Gegensatz zur Standardnormalverteilung hat sie aber noch einen Parameter: die Zahl der Freiheitsgrade $\\text{df}$.\n\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## [Unstandardisierte t-Verteilung]{color=\"darkred\"}\n\n![](images/kein_klausurstoff.png){.absolute top=10 right=0 height=110px}\n\nDie Formel für die klassische (standardisierte) t-Verteilung lautet:\n\n:::{style=\"margin-top: -7px\"}\n$$\nf_t(x|\\scriptsize\\text{df}\\normalsize) = \\frac{\\Gamma\\left(\\frac{\\scriptsize\\text{df}\\normalsize+1}{2}\\right)} {\\sqrt{\\scriptsize\\text{df}\\normalsize\\,\\pi}~\\Gamma\\left(\\frac{\\scriptsize\\text{df}\\normalsize}{2}\\right)}\\left(1+\\frac{1}{\\scriptsize\\text{df}\\normalsize}x^{2}\\right)^{-\\frac{\\text{df}+1}{2}}\\qquad \\left(\\Gamma\\text{ ist die Gamma-Funktion}\\right)\n$$\n:::\n\nWie die Standardnormalverteilung hat die t-Verteilung Mittelwert 0 (daher kann sie als Nullhypothesenverteilung fungieren). Ihre Streuung ist jedoch nicht exakt 1, sondern hängt von der Zahl der Freiheitsgrade ab: $\\sigma^2=\\frac{\\scriptsize\\text{df}\\normalsize}{\\scriptsize\\text{df}\\normalsize-2}$.\n\n:::{style=\"margin-top: -3px\"}\nTatsächlich gibt es auch zur t-Verteilung ein unstandardisiertes Pendant, die **nicht-standardisierte t-Verteilung**, die von Mittelwert $\\color{green}{\\mu}$ und Streuung $\\color{blue}{\\sigma}$ abhängt:\n:::\n\n$$\nf_t(x|\\color{green}{\\mu},\\color{blue}{\\sigma},\\scriptsize\\text{df}\\normalsize) = \\frac{\\Gamma\\left(\\frac{\\scriptsize\\text{df}\\normalsize+1}{2}\\right)} {\\color{blue}{\\sigma}\\sqrt{\\scriptsize\\text{df}\\normalsize\\,\\pi}~\\Gamma\\left(\\frac{\\scriptsize\\text{df}\\normalsize}{2}\\right)}\\left(1+\\frac{1}{\\scriptsize\\text{df}\\normalsize}\\left(\\frac{x-\\color{green}{\\mu}}{\\color{blue}{\\sigma}}\\right)^2\\right)^{-\\frac{\\text{df}+1}{2}}\n$$\n\nÄhnlich wie beim z-Test hat es sich in der Praxis aber durchgesetzt immer mit standardisierten Prüfgrößen (wie $z$ oder $t$) zu arbeiten. Daher finden die unstandardisierte t- und Normalverteilung im Kontext der Hypothesentestung selten eine Anwendung.\n\n:::{style=\"margin-top: -5px\"}\nDer **Vorteil standardisierter Prüfgrößen** ist, dass diese vergleichbar zwischen Studien sind. Ein bestimmter z- oder t-Wert hat eine Aussagekraft, ohne den Standardfehler einer Studie zu kennen.\n:::\n\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## [Intuition: verdickte Flanken der t-Verteilung]{style=\"color: darkred\"}\n\n![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=110px}\n\n:::{.nonincremental}\n- Warum sind die Flanken der Verteilung der Testgröße $t=\\frac{\\hat{\\theta}}{\\hat{se}}$ stärker ausgeprägt, wenn $\\hat{se}$ auf Basis der Stichprobe geschätzt werden muss?\n- Der Grund liegt in der (Chi-)Verteilung der Zufallsvariable $\\hat{se}$ im Nenner: \n    - Bei kleinen Stichprobengrößen (kleines df), gibt es eine Assymmetrie der Verteilung hin zu Werten kleiner dem Mittelwert (welcher die korrekte Schätzung von $se$ repräsentiert &mdash; in der Abbildung gestrichelte Linien)\n    - D.h. wir *teilen* $\\hat{\\theta}$ *überproportional häufig durch zu kleine Werte*, wodurch die *Teststatistik* $t=\\frac{\\hat{\\theta}}{\\hat{se}}$ *überproportional häufig zu extreme (negative oder positive) Werte* liefert.\n    - Dies führt zu den stärkeren Flanken der t-Verteilung!\n:::\n\n![](images/chi.png){style=\"margin-top: -20px !important\"}\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## [Funktionen der t-Verteilung]{color=\"darkred\"}\n\n![](images/kein_klausurstoff.png){.absolute top=10 right=0 height=110px}\n\n![](images/tdist_cdf.png){height=300px style=\"margin-left:40px !important\"}\n\n![](images/tdist_cdfinv.png){height=400px}\n\n\n\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## [Herleitung des gepoolten Standardfehlers]{color=\"darkred\"}{#pooledvariance}\n\n![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=110px}\n\n:::{style=\"margin-top: -10px\"}\n- Im Fall unabhängiger Messungen und ähnlicher Varianzen wird eine **gepoolte Streuung** $\\hat{\\sigma}_\\text{pooled}$ herangezogen:\n:::\n\n:::{style=\"margin-top: -50px\"}\n:::{.fragment}\n$$\n\\hat{se} = \\hat{\\sigma}_\\text{pooled}\\sqrt{\\frac{1}{n_A}+\\frac{1}{n_B}}\n$$\n:::\n:::\n\n:::{style=\"margin-top: -15px\"}\n- Zur Herleitung starten wir mit der allgemeinen Varianzsummenformel: wir wissen, dass sich die Varianzen der beiden Stichprobenmittelwerte (=quadrierte Standardfehler $\\hat{se}_A^2$ und $\\hat{se}_B^2$) aufaddieren:\n:::\n\n:::{style=\"margin-top: -54px\"}\n:::{.fragment}\n$$\n\\hat{se}^2 = \\hat{se}_A^2 + \\hat{se}_B^2\\quad\\rightarrow\\quad \\hat{se} = \\sqrt{\\hat{se}_A^2 + \\hat{se}_B^2} = \\sqrt{\\frac{\\hat{\\sigma}_A^2}{n_A} + \\frac{\\hat{\\sigma}_B^2}{n_B}}\n$$\n:::\n:::\n\n:::{style=\"margin-top: -15px\"}\n- Können die Varianzen $\\hat{\\sigma}_A^2$ und $\\hat{\\sigma}_B^2$ als ähnlich angenommen werden, gilt folgende Überlegung: statt beide Varianzen einzeln zu schätzen, wird eine einheitliche gepoolte Varianz $\\hat{\\sigma}_\\text{pooled}$ auf Basis beider Stichproben geschätzt (vgl. Vorlesung 07).\n  - Vorteil: diese Varianz kann präziser geschätzt werden als die Einzelvarianzen, da die kombinierte Stichprobenzahl $n_A+n_B$ zugrundegelegt wird.\n- Wir ersetzen also $\\hat{\\sigma}_A^2$ und $\\hat{\\sigma}_B^2$ jeweils durch $\\hat{\\sigma}_\\text{pooled}^2$:\n:::\n\n:::{style=\"margin-top: -20px\"}\n:::{.fragment}\n$$\n\\hat{se} = \\sqrt{\\frac{\\hat{\\sigma}_\\text{pooled}^2}{n_A} + \\frac{\\hat{\\sigma}_\\text{pooled}^2}{n_B}} = \\hat{\\sigma}_\\text{pooled}\\sqrt{\\frac{1}{n_A}+\\frac{1}{n_B}}\\qquad\\text{q.e.d.}\n$$\n:::\n:::\n\n\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## [Intuition zur Welch–Satterthwaite-Gleichung]{color=\"darkred\"}{#welchsatterthwaiteintuition}\n\n![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=110px}\n\nAuch wenn die Welch–Satterthwaite-Gleichung für die Freiheitsgrade beim Zweistichproben-t-Test mit unterschiedlicher Varianz recht kompliziert aussieht, ist eine nähere Betrachtung aufschlussreich.\n\nFür $n_A=n_B=n$ gilt:\n\n$$\n\\text{df}=(n-1)\\Big(1+\\frac{2}{\\left(\\frac{\\hat{\\sigma}_A}{\\hat{\\sigma}_B}\\right)^2+\\left(\\frac{\\hat{\\sigma}_B}{\\hat{\\sigma}_A}\\right)^2}\\Big)\n$$\n\nZwei Fälle sind interessant:\n\n<div class=\"vspace-small\"></div>\n\n[Fall 1: Sind die Varianzen gleich]{.underline} (entgegen der Annahme), d.h. $\\hat{\\sigma}_A=\\hat{\\sigma}_B$, so vereinfacht sich die Formel zu\n\n$$\n\\text{df} = (n-1)(1+\\frac{2}{2}) = 2n -2,\n$$\n\n**also exakt die Formel des klassichen Zweistichprobentests.**\n\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## [Intuition zur Welch–Satterthwaite-Gleichung]{color=\"darkred\"}\n\n![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=110px}\n\n[Fall 2: Sind die Varianzen extrem unterschiedlich]{.underline}, so wird entweder $\\left(\\frac{\\hat{\\sigma}_A}{\\hat{\\sigma}_B}\\right)^2$ oder $\\left(\\frac{\\hat{\\sigma}_B}{\\hat{\\sigma}_A}\\right)^2$ extrem groß und die Formel vereinfacht sich zu\n\n$$\n\\text{df} = (n-1)(1+\\frac{2}{\\infty}) = (n-1)(1+0) = n-1\n$$\n\n**also exakt die Formel des Einstichprobentests.**\n\nFür extrem ungleiche Varianzen reduzieren sich also die Freiheitsgrade &mdash; und damit die *effektive Stichprobengröße* &mdash; auf die Größe einer der beiden verglichenen Gruppen. \n\nDas ist durchaus intuitiv: ist z.B. $\\hat{\\sigma}_A$ extrem viel kleiner als $\\hat{\\sigma}_B$, so spielt die Varianz der Gruppe A nahezu keine Rolle mehr. Die Versuchspersonen dieser Gruppe gehen also für die Berechnung des Standardfehlers \"verloren\", was sich entsprechend auf die Freiheitsgrade auswirkt.\n\n*Im Grenzfall* spielt die Varianz dieser Gruppe überhaupt keine Rolle mehr, sondern nur noch ihr Mittelwert. Die Gruppe hat damit die gleiche Funktion wie der Referenzwert $\\mu_0$ beim Einstichproben-t-Test.\n\n\n\n\n\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## [Inferenzstatistik für Regressionskoeffizienten]{color=\"darkred\"}{#treg}\n\n![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=110px}\n\n:::: {.columns}\n::: {.column width=\"64%\"}\n\n:::{.nonincremental}\n- Die Hypothesentestung für den Regressionskoeffizienten der einfachen Regression (d.h. 1 UV) unterscheidet sich nicht von der Korrelation.\n:::\n\n:::{style=\"margin-top: -15px\"}\n- Auch für den Regressionskoeffizienten können wir einen Standardfehler definieren:\n:::\n\n:::{.fragment}\n$$\n\\hat{se}(\\hat{b}_1)= \\frac{\\hat{\\sigma}_Y}{\\hat{\\sigma}_X}\\sqrt{\\frac{1-\\hat{\\rho}^2}{n-2}}\n$$\n:::\n\n:::\n::: {.column width=\"36%\"}\n![](images/regression_basics2_v2.png)\n:::\n::::\n\n- .. und einen darauf basierenden t-Wert:\n\n:::{.fragment}\n$$\nt = \\frac{\\hat{b}_1}{\\hat{se}(\\hat{b}_1)} \\overset{\\text{(s. nächste Folie)}}{=} \\hat{\\rho}\\sqrt{\\frac{n-2}{1-\\hat{\\rho}^2}}\n$$\n:::\n\n- Die Zahl der Freiheitsgrade ist wie bei der Korrelation $\\text{df}=n-2$, da auch hier für die Berechnung des Standardfehlers die beiden Mittelwerte $\\bar{x}$ und $\\bar{y}$ bestimmt werden müssen.\n- Der Rest ist bekannt.\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## [Inferenzstatistik für Regressionskoeffizienten]{color=\"darkred\"}\n\n![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=110px}\n\n:::{.nonincremental}\n- Während die Regressionssteigung abhängt davon, welche Variable als UV (bzw. $x$) und welche als AV (bzw. $y$) definiert wird, sind die t-Werte (und damit auch die p-Werte) unabhängig von der Rollenverteilung der Variablen.\n- Dies ergibt sich direkt aus dem Zusammenhang von $r$ und $b_1$ (vgl. Vorlesung 06):\n:::\n\n$$\nb_1 = \\frac{\\hat{\\sigma}_Y}{\\hat{\\sigma}_X}r\n$$\n\n:::{.nonincremental}\n- Damit ist die Prüfgröße $t$:\n:::\n\n:::{style=\"margin-top: -12px\"}\n$$\nt = \\frac{b_1}{\\hat{se}(b_1)} = \\frac{\\frac{\\hat{\\sigma}_Y}{\\hat{\\sigma}_X}r}{\\frac{\\hat{\\sigma}_Y}{\\hat{\\sigma}_X}\\sqrt{\\frac{1-r^2}{n-2}}} = \\frac{r}{\\sqrt{\\frac{1-r^2}{n-2}}} = r\\sqrt{\\frac{n-2}{1-r^2}}\n$$\n:::\n\n:::{.nonincremental}\n- Der t-Wert bei der einfachen Regression ist also identisch zum t-Wert der Korrelation und insbesondere nur noch abhängigg von $r$ und nicht mehr $b_1$\n- Da für die Korrelation $r$ die Rollenverteilung der beiden Zusammenhangsvariablen<br>unerheblich ist, folgt, dass der p-Wert bei der Regression ebenso wenig von der<br>Zuordnung der Variablen als UV und AV abhängt.\n:::\n\n\n\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## [Testung des y-Achsenabschnitts bei der Regression]{color=\"darkred\"}\n\n![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=110px}\n\n:::{.nonincremental}\n- Wir haben bislang den Achsenabschnitt $b_0$ aus der Diskussion außen vor gelassen.\n- Im Kontext der Regression wird der Achsenabschnitt $b_0$ idR nicht getestet. \n- Grund: die Frage, ob Variable $Y$ bei $X=0$ einen y-Achsenabschnitt aufweist, der signifikant von Null verschieden ist, ist im Kontext der Regression selten interessant &mdash; schließlich ist es ja der ganze Zweck der Regression die systematische Verändeurng von $Y$ in $X$ zu analysieren und dabei gerade nicht nur einen bestimmten Wert von $X$ zu betrachten.\n- Nichts desto trotz ist auch die Schätzung von $b_0$ mit Unsicherheit verbunden, die durch folgenden Standardfehler definiert ist: \n:::\n$$\n\\hat{se}(b_0) = \\underbrace{\\sqrt{\\frac{\\sum\\left(y_i-\\hat{y_i}\\right)^2}{n-2}}}_\\text{Standardabweichung der Residuen}\\sqrt{\\frac{1}{n}+\\frac{\\bar{x}^2}{\\sum\\left(x_i-\\bar{x}\\right)^2}}\n$$\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## [Testung des y-Achsenabschnitts bei der Regression]{color=\"darkred\"}\n\n![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=110px}\n\n:::{.nonincremental}\n- Ein Spezialfall ist das lineare Modell ohne Steigung (bzw. ohne x!):\n:::\n\n$$\n\\hat{y} = b_0\n$$\n\n:::{.nonincremental}\n- In diesem Modell kommt dem Regressionskoeffizienten $b_0$ und dessen Unsicherheit eine interessantere Bedeutung zu: die Frage ob $b_0$ signifikant verschieden von 0 ist, ist hier gleichbedeutend mit der Frage ob die Zufallsvariable $Y$ **signifikant verschieden von Null ist**.\n- Mit anderen Worten: dieses Modell ist nichts anderes als ein Einstichproben-t-Test!\n- Dies beinhaltet auch den Vergleich zweier abhängiger Messungen A und B, wenn wir zuvor $Y$ als Differenzvariable definieren: \n$Y=Y_A-Y_B$\n:::\n:::{.nonincremental}\n- .. dann testet \n:::\n\n$$\n\\hat{y} = b_0\n$$\n\n:::{.nonincremental}\n- die Frage, ob die Mittelwertsdifferenz von A und B signifikant verschieden von Null ist.\n:::\n\n\n\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## [\"Common statistical tests are linear models\"]{color=\"darkred\"}\n\n![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=110px}\n\n\nDie Parallele von bekannten statistischen Tests und (generalisierter) linearer Regression lässt sich auf alle Tests erweitern, die wir in Statistik 1 und Statistik 2 kennenlernen.\n\nHier eine Auswahl der Tests aus Statistik 1:\n\n<!---  Table --->\n| Test | Lineares Modell | Spezifierung | Nullhypothese |\n|-|-|-|-|\n| Pearson-Korrelation | $\\hat{y}=\\beta_0 + \\beta_1 x$ | - | $\\mathcal{H}_0: \\beta_1 = 0$|\n| Spearman-Korrelation | $\\text{Rang}(\\hat{y})=\\beta_0 + \\beta_1 \\text{Rang}(x)$ | - | $\\mathcal{H}_0: \\beta_1 = 0$|\n| Einstichproben-t-Test | $\\hat{y}=\\beta_0$ | - | $\\mathcal{H}_0: \\beta_0 = 0$|\n| Differenzen-t-Test | $\\hat{y_A}-\\hat{y_B}=\\beta_0$ | - | $\\mathcal{H}_0: \\beta_0 = 0$|\n| Zweistichproben-t-Test | $\\hat{y}=\\beta_0 + \\beta_1 x$ | $x=0$ für alle Datenpunkte von Gruppe A und $x=1$ für alle Datenpunkte von Gruppe B &rarr; Regression auf binäre x-Variable! | $\\mathcal{H}_0: \\beta_1 = 0$|\n\n: {tbl-colwidths=\"[20, 25, 40, 15]\"}\n\n::: {.caption-style}\nDie Analogie von bekannten statistischen Tests und linearem Modell ist lange bekannt, ging aber 2021 durch Beiträge von Jonas Lindeløv viral^[https://stats.stackexchange.com/questions/303269/common-statistical-tests-as-linear-models] ^[https://lindeloev.github.io/tests-as-linear/] ^[https://twitter.com/jonaslindeloev/status/1110907133833502721].\n:::\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}