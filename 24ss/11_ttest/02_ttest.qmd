# Durchführung eines t-Testes

<!----------------->
<!--- New slide --->
<!----------------->
## t-Test

Zur Durchführung des t-Tests müssen wir uns über folgende Punkte Gedanken machen:

:::{.fragment}
**0. Sind die Voraussetzungen für einen t-Test gegeben?**

Jeder statistische Test basiert auf bestimmten Annahmen. Der Test sollte daher nur dann angewendet werden, wenn diese Annahmen erfüllt sind (oder sich eine Verletzung der Annahme in der Praxis als wenig problematisch herausgestellt hat).
:::

:::{.fragment}
**1. Welche Art von t-Test benötige ich?**

Für verschiedene Szenarien gibt es unterschiedliche t-Tests, die sich unterscheiden in a) dem verwendeten Standardfehler und b) der Zahl der Freiheitsgrade $\text{df}$.
:::

:::{.fragment}
**2. Zahl der Freiheitsgrade**

Die Zahl der Freiheitsgrade $\text{df}$ ist als Parameter für die t-Verteilung notwendig, und damit auch notwendig um Flächen (wie p-Werte) unter der Verteilung zu berechnen. De facto übernehmen das heute Computerprogramme, jedoch ist es nach wie vor Usus die Zahl der Freiheitsgrade eines statistischen Testes in wissenschaftlichen Veröffentlichungen anzugeben.
:::

:::{.fragment}
**3. Signifikanzniveau & ein/zweiseitige Testung**

Welchen Wert bestimme ich als Signifikanzniveau $\alpha$? Ist mein Test einseitig (gerichtete Hypothese) oder zweiseitig (ungerichtete Hypothese)? &xrarr; siehe auch Vorlesung 10
:::




<!----------------->
<!--- New slide --->
<!----------------->
## 0. Sind die Voraussetzungen für einen t-Test gegeben?

:::: {.columns}
::: {.column width="70%"}

:::{.nonincremental}
- Mindestens **intervallskalierte Daten**.
- **Hinreichende Normalverteilung** des gemessenen Merkmals $X$ in der Population (Zweistichproben-t-Test: Normalverteilung von $X_A$ und $X_B$ in den beiden Gruppen A und B!)
    - [Allerdings zeigen Simulationsstudien, dass der t-Test sehr „robust“ gegen Verletzungen der Normalverteilungsannahme ist.]{color="darkgreen"}
    - Problematisch sind stark schiefe Verteilungen (rechts- oder linksschief) bei kleinen Stichprobengrößen.
    - Kann von keiner Normalverteilung ausgegangen werden: nicht-parametrische Testverfahren (z.B. Mann-Whitney-U-Test).
- Siehe Bonuscontent für eine [Begründung der Normalverteilungsvoraussetzung beim t-Test](#tnormal){style="color: darkred"}.
:::
:::
::: {.column width="30%"}
![Mr. T](images/mrT.png)

:::
::::



<!----------------->
<!--- New slide --->
<!----------------->
## 1. Welche Art von t-Test benötige ich?

:::{.vcenter}
![](images/ttest_decisiontree_v2.png){height=640px}
:::



<!----------------->
<!--- New slide --->
<!----------------->
## 2. Zahl der Freiheitsgrade

::: {.nonincremental style="font-size: 26px"}
- Die [**Zahl der Freiheitsgrade**]{color="navy"} gibt die **Zahl der frei variierbaren Werte** bei der Berechnung eines statistischen Kennwertes an.
- Häufig kann die Zahl der Freiheitsgrade recht einfach berechnet werden als Stichprobengröße $n$ *minus* die Anzahl der Zwischenparameter, die für die Berechnung des statistischen Kennwertes geschätzt werden müssen.
:::


<!---  Example --->
::: {.example .fragment style="font-size:21px !important; margin-top:10px"}
:::: {.columns}
::: {.column width="7%"}
::: {style="margin-top: 10px"}
![](images/example.png){height=50px}
:::
:::
::: {.column width="93%"}
**Beispiel Varianz:** Angenommen, wir wollen für einer Stichprobe aus vier Werten die Varianz bestimmen:

::: {style="margin-top:-15px !important; margin-bottom:-5px !important"}
$$
\hat{\sigma}^2 = \frac{1}{4-1}\sum_{i=1}^4 (x_i-\bar{x})^2
$$
:::

**Frage: wie viele Freiheitsgrade haben wir für die Berechnung der Varianz?**

Aus der Formel der Varianz erkennen wir, dass wir zur Berechnung der Varianz **einen Parameter** aus den Daten bestimmen müssen, nämlich der Mittelwert $\bar{x}$. Die Zahl der Freiheitsgrade ergibt sich damit plain & simple nach obiger Definition als **Stichprobengröße n minus 1**, also in diesem Beispiel $\text{df}=n-1=4-1=3$. 

**Intuition:** dadurch, dass die Formel der Varianz den Mittelwert aller Datenpunkte als Parameter enthält, können wir nicht mehr alle 4 Datenpunkte beliebig frei variieren. Wir könnten drei beliebige Datenwerte frei wählen, der vierte Wert aber wäre durch den gegebenen Mittelwert $\bar{x}$ festgelegt. Sagen wir der Mittelwert sei $\bar{x}=2$ und wir würden frei drei Werte als (2, 4, 1) frei wählen. Der vierte Wert ist nun nicht mehr frei, denn um die Randbedingung $\bar{x}=2$ zu garan- tieren, muss der vierte Wert gleich 1 sein. In diesem Sinne kann man auch sagen: Zwischenparameter wie $\bar{x}$ geben wie in einem Gleichungssystem Randbedingen vor, die die Zahl frei wählbarer Werte für die sonstigen Parameter reduzieren.
:::
::::
:::


<!----------------->
<!--- New slide --->
<!----------------->
## 2. Zahl der Freiheitsgrade: t-Test


:::: {.columns}
::: {.column width="70%"}

:::{.nonincremental}
- Für die Zahl der Freiheitsgrade beim t-Test gilt, dass die Zahl der Freiheitsgrade ausschließlich auf Basis der Streuung $\hat{se}$ im Nenner bestimmt wird.
:::

$$
t=\frac{\hat{\theta}}{\hat{se}}
$$
:::
::: {.column width="30%"}
:::{style="margin-top: -70px"}
![](images/df_cartoon.jpg)
:::
:::
::::


- Häufig reicht es, zu zählen, wie viele Mittelwerte für die Berechnung von $\hat{se}$ im Nenner des t-Wertes verwendet werden.
- Beispiel: Stichprobenkennwert $\hat{\theta}$ = Mittelwertdifferenz $\Delta\bar{x}$
    - Vergleich des Mittelwertes einer Einzelmessung $\bar{x}$ mit Referenzwert $\mu_0$:<br>Berechnung von $\hat{se}$ erfordert 1 Mittelwert für 1 Stichprobe &xrarr; $\text{df}=n-1$
    - Vergleich der Mittelwerte $\bar{x}_A$ und $\bar{x}_B$ zweier abhängiger Messungen:<br>Berechnung von $\hat{se}$ erfordert 1 Mittelwert für 1 Stichprobe (hier: Mittelwert der Differenzen) &xrarr; $\text{df}=n-1$
    - Vergleich der Mittelwerte $\bar{x}_A$ und $\bar{x}_B$ zweier unabhängiger Messungen (Annahme: Varianzen $\hat{\sigma}_A^2$ und $\hat{\sigma}_B^2$ ähnlich):<br>Berechnung von $\hat{se}$ erfordert 2 Mittelwerte für 2 Stichproben &xrarr; $\text{df}=n_A+n_B-2$


<!-- - Eine berechtigte Frage ist, warum beim t-Test die Streuung $\hat{\sigma}$ nicht auch als Freiheitsgrad abgezogen werden muss (schließlich wird dieser Parameter bei der Berechnung des t-Wertes verwendet).
- Der Grund ist subtil und hängt damit zusammen, dass wir die t-Verteilung *unter der Voraussetzung verwenden, dass der Standardfehler geschätzt werden musste*. Der Verlust dieses Freiheitsgrades ist also in der Verteilung selbst bereits berücksichtigt und muss post-hoc nicht mehr als zusätzlicher Freiheitsgrad abgezogen werden.^[https://stats.stackexchange.com/questions/226483/does-the-determination-of-the-mean-and-sd-imply-the-loss-of-one-or-two-degrees-o] -->

<!----------------->
<!--- New slide --->
<!----------------->
<!-- ## [3. Zahl der Freiheitsgrade]{color="darkred"}

![](images/kein_klausurstoff.png){.absolute top=15 right=20 height=100px}

:::: {.columns}
::: {.column width="65%"}

:::{.nonincremental}
- Generell gilt: **wir wollen (idealerweise) eine möglichst große Zahl von Freiheitsgraden** für die Bestimmung unseres statistischen Kennwertes, denn alle Freiheitsgerade die nicht "unterwegs verloren gehen" (bei der Berechnung von Zwischenparametern), fließen in die Schätzung des Kennwertes ein und präzisieren damit dessen Schätzung.
- Das Konzept der Freiheitsgrade wird **besonders wichtig bei komplexeren Modellen**, wie sie in Statistik 2 behandelt werden (multiple Regression). Dort gehen schnell eine große Zahl von Freiheitsgraden "flöten" und die Zahl der Freiheitsgrade muss daher bereits bei der Wahl eines Modells berücksichtig werden.
:::
:::
::: {.column width="35%"}

![Bildnachweis^[https://www.facebook.com/SaraswathiAnalytics/photos/a.101349091331739/428667868599858]](images/df_cartoon.jpg){style="margin-top: 60px !important"}

:::
::::

:::{style="margin-top: -15px"}
:::{.nonincremental}
- Der **Begriff "Freiheitsgrad" ist wenig intuitiv**, weil die Datenpunkte nur im Gedankenexperiment "frei" gewählt werden können &mdash; in Realität sind sie natürlich gegeben.
- Ein intuitiverer Ausdruck wäre **effektive Stichprobengröße**: wie viele Datenpunkte aus meiner Stichprobe kann ich effektiv zur Schätzung meines statistischen Zielkennwerts nutzbar machen?
:::
::: -->



<!----------------->
<!--- New slide --->
<!----------------->
## 3. Signifikanzniveau & ein/zweiseitige Testung

**Erinnerung:**

::: {.colorbox}
Das **Signifikanzniveau** $\alpha$ gibt legt ein Kriterium für die Ablehnung der Nullhypothese fest.<br><br>[Es gilt:]{.underline} ist $p<\alpha$ lehnen wir die Nullhypothese ab und werten unseren Effekt als statistisch signifikant.
:::

:::: {.columns .fragment}
::: {.column width="52%"}

:::{.nonincremental}
- Der Wert $\alpha$ wird auch **Irrtumswahrscheinlichkeit** genannt &mdash; sie gibt das Risiko an, mit dem wir bereit sind, die Nullhypothese fälschlicherweise abzulehnen.
    - Beispiel: ist $\alpha=0.05$, so gibt es eine 5%-ige Wahrscheinlichkeit, die Nullhypothese abzulehnen, *obwohl sie in Wahrheit zutrifft*.
    - Je kleiner $\alpha$, desto "konservativer" der Test, d.h. desto eher will ich vermeiden, einen Effekt fälschlicherweise als signifikant zu werten (erhöhe aber dabei mein Risko, einen wahren Effekt zu "verpassen").
:::

:::
::: {.column width="48%"}
![](images/significance_level.png){style="margin-top:0px !important"}
:::
::::

<!----------------->
<!--- New slide --->
<!----------------->
## 3. Signifikanzniveau & ein/zweiseitige Testung

:::{.nonincremental}
- Abhänging davon, ob die Hypothese gerichtet bzw. ungerichtet wird ein einseitiger bzw. zweiseitiger t-Test durchgeführt.
:::

<!-- <div class="vspace-medium"></div> -->

<!---  Table --->
|| Einseitiger Test<br>(gerichtete Hypothese) | Zweiseitiger Test<br>(ungerichtete Hypothese) |
|-|:-:|:-:|
| **Berechnung des kritischen t-Wertes** | ![](images/ttest1_alpha2.png) | ![](images/ttest1_alpha_ungerichtet2.png) |
| **Berechnung des p-Wertes** | ![](images/ttest1_pvalue.png){style="margin-top:15px !important"} | ![](images/ttest1_pvalue_ungerichtet.png){style="margin-top:15px !important"} |

: {tbl-colwidths="[33, 33, 33]"}
