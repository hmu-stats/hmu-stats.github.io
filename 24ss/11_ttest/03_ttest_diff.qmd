# t-Test für Mittelwertdifferenzen



<!----------------->
<!--- New slide --->
<!----------------->
## t-Test für Mittelwertdifferenzen

:::{.nonincremental}
- Zur Erinnerung, bei einem statistischen Test zu Mittelwertdifferenzen stellen wir folgende Fragen: 
    - Unterscheidet sich ein Mittelwert signifikant von einem Referenzwert? (Einstichprobentest mit Einzelmessung)    
    - Unterscheiden sich die Mittelwerte von zwei abhängigen Bedingungen signifikant voneinander? (Einstichprobentest mit zwei abhängigen Messungen)
    - Unterscheiden sich die Mittelwerte von zwei unabhängigen Stichproben signifikant voneinander? (Zweistichprobentest)
:::

:::{style="margin-top: -15px"}
- Beispiel Paradoxia (Zweistichprobentest):
:::

:::{.fragment style="margin-top: 15px"}
![](images/mittelwertdifferenz_paradoxia.png){height=300px}
:::

<!----------------->
<!--- New slide --->
<!----------------->
## t-Test für Mittelwertdifferenzen

:::{.nonincremental}
- Um den t-Wert für eine Mittelwertdifferenz $\Delta\bar{x}$ zu erhalten, ersetzen wir $\hat{\theta}$ durch $\Delta\bar{x}$:
:::

$$
\text{t-Wert für Mittelwertdifferenz:}\qquad t = \frac{\hat{\theta}}{\hat{se}} = \frac{\Delta\bar{x}}{\hat{se}}
$$

- Die Mittelwertdifferenz $\Delta\bar{x}$ ist einfach zu bestimmen, die zentrale Frage lautet daher: **wie berechnet sich der Standardfehler $\hat{se}$ einer Mittelwertdifferenz $\Delta\bar{x}$?**


::: {.merke .fragment style="margin-top: 130px; font-size: 26px"}
:::: {.columns}
::: {.column width="5%"}
::: {style="margin-top: 18px"}
![](images/merke.png){height="55px"}
:::
:::
::: {.column width="95%"}
Der Standardfehler im Nenner des t-Wertes bezieht sich immer auf die Prüfgröße $\hat{\theta}$. Die Frage lautet also bei jedem t-Test: was ist der Standardfehler von $\hat{\theta}$ bzw. was ist die Standardabweichung der Stichprobenverteilung von $\hat{\theta}$?
:::
::::
:::



<!----------------->
<!--- New slide --->
<!----------------->
## [t-Test: Veranschaulichung der Standardfehler von Mittelwertdifferenzen]{style="font-size:37px"}

<div class="vspace-small"></div>
![](images/stichprobenverteilung_diff_v2.png)


<!----------------->
<!--- New slide --->
<!----------------->
## [Standardfehler bei Mittelwertdifferenzen ($\sigma$ unbekannt): Cheat sheet]{style="font-size:38px"}

Das folgende Cheat sheet gibt Ihnen eine Übersicht über die Berechnung des Standardfehlers $\hat{se}$ von Mittelwertdifferenzen im Nenner der Prüfgröße $t=\frac{\Delta\bar{x}}{\hat{se}}$:

<!---  Table --->
|Fall|Berechnung des Standardfehlers $\hat{se}$|
|-|-|
| **Differenz des Mittelwertes [einer Stichprobe]{.underline} und einem Referenzwert** $\mu_0$<br>(&rarr; Einstichproben-t-Test) | $\hat{se}=\frac{\hat{\sigma}}{\sqrt{n}}$ |
| **Mittelwertdifferenz abhängiger Messungen A und B in [einer Stichprobe]{.underline}**<br>(&rarr; Differenzen-t-Test) |$\hat{se} = \frac{\hat{\sigma}_\Delta}{\sqrt{n}}\qquad\text{mit}$ \
$\hat{\sigma}_\Delta=\sqrt{\hat{\sigma}_A^2+\hat{\sigma}_B^2-2\,\hat{\rho}\hat{\sigma}_A\hat{\sigma}_B}$ \
$\text{oder}\qquad\hat{\sigma}_\Delta=\sqrt{\frac{1}{n-1}\left(\Delta x_i-\Delta\bar{x}\right)^2}$ |
| **Mittelwertdifferenz unabhängiger Messungen in [zwei Stichproben A und B]{.underline} (ähnliche Varianzen)**<br>(&rarr; Klassischer Zweistichproben-t-Test) | $\hat{se} = \hat{\sigma}_\text{pooled}\sqrt{\frac{1}{n_A}+\frac{1}{n_B}}\quad$[(siehe Herleitung)](#pooledvariance){style="color: darkred"} \
$\text{mit}\quad \hat{\sigma}_\text{pooled}=\sqrt{\frac{(n_A-1)\hat{\sigma}^2_A + (n_B-1)\hat{\sigma}^2_B}{n_A+n_B-2}}$ |
| **Mittelwertdifferenz unabhängiger Messungen in [zwei Stichproben A und B]{.underline} (unähnliche Varianzen)**<br>(&rarr; Welch's Zweistichproben-t-Test) | $\hat{se}= \sqrt{\frac{\hat{\sigma}_A^2}{n_A} + \frac{\hat{\sigma}_B^2}{n_B}}$ |c

: {tbl-colwidths="[50, 40]"}


<div class="vspace-small"></div>

::: {.merke style="font-size: 23px !important"}
:::: {.columns}
::: {.column width="5%"}
::: {style="margin-top: 10px"}
![](images/merke.png){height="55px"}
:::
:::
::: {.column width="95%"}
Dieses Cheat Sheet gilt für den Fall, dass die Populationsvarianzen $\sigma^2_A$ bzw. $\sigma^2_B$ **nicht bekannt** sind. In diesem Sinne ist es das in der Praxis relevante Cheat Sheet, da die Populationsvarianzen nahezu nie bekannt sind.
:::
::::
:::


<!----------------->
<!--- New slide --->
<!----------------->
## Zahl der Freiheitsgrade für t-Tests von Mittelwertdifferenzen

<!-- <div class="vspace-medium"></div> -->

<!---  Table --->
|Test|Frage|Zahl der Freiheitsgrade|
|-|-|-|
| **Einstichprobentest mit Einzelmessung** | Ist $\bar{x}$ größer als ein Referenzwert $\mu_0$? | $\text{df} = n - 1$, da für die Berechnung von $t$ genau ein Zwischenparameter bestimmt werden muss (der Mittelwert $\bar{x}$) |
| **Einstichprobentest mit zwei abhängigen Messungen** | Unterscheiden sich die Mittelwerte $\bar{x}_A$ und $\bar{x}_B$ zwischen zwei Bedingungen A und B? In diesem Fall kann man auch fragen: ist der Mittelwert der Differenzvariable ($\Delta\bar{x}=\overline{X_A-X_B}$) verschieden von Null? | $\text{df} = n - 1$, da für die Berechnung von $t$ genau ein Zwischenparameter bestimmt werden muss (der Mittelwert $\overline{X_A-X_B}$)|
| **Zweistichprobentest (ähnliche Varianzen)** | Unterscheiden sich die Mittelwerte $\bar{x}_A$ und $\bar{x}_B$ zwischen zwei Gruppen A und B? ($\Delta\bar{x}=\bar{x}_A-\bar{x}_B$) |$\text{df} = n_A + n_B - 2$, da für die Berechnung von $t$ genau zwei Zwischenparameter bestimmt werden müssen (die Mittelwerte $\bar{x}_A$ und $\bar{x}_B$)|
| **Zweistichprobentest (unähnliche Varianzen, aka Welch's t-Test)** | Unterscheiden sich die Mittelwerte $\bar{x}_A$ und $\bar{x}_B$ zwischen zwei Gruppen A und B? ($\Delta\bar{x}=\bar{x}_A-\bar{x}_B$) | **Welch–Satterthwaite-Gleichung:** \
$\text{df} = \frac{\left(\frac{\hat{\sigma}_A^2}{n_A}+\frac{\hat{\sigma}_B^2}{n_B}\right)^2}{\frac{\left(\hat{\sigma}_A^2/n_A\right)^2}{n_A-1}+\frac{\left(\hat{\sigma}_B^2/n_B\right)^2}{n_B-1}}$ \
Falls $n_A=n_B=n:\quad$[(siehe Intuition)](#welchsatterthwaiteintuition){style="color: darkred"} $\text{df}=(n-1)\Big(1+\frac{2}{\left(\frac{\hat{\sigma}_A}{\hat{\sigma}_B}\right)^2+\left(\frac{\hat{\sigma}_B}{\hat{\sigma}_A}\right)^2}\Big)$ |

: {tbl-colwidths="[23, 35, 42]"}


<!----------------->
<!--- New slide --->
<!----------------->
## Beispiel: t-Test für unabhängige Gruppen

:::: {.columns}
::: {.column width="80%"}

Betrachten wir das Beispiel Med- versus Psych-Nasen für den Fall, dass wir die Standardabweichungen $\sigma_\text{med}$ und $\sigma_\text{psych}$ von Nasenlängen in der Med- und Psych-Population [nicht]{.underline} kennen.

Es gilt immer noch:

$$
\Delta \bar{x} = \bar{x}_\text{med} - \bar{x}_\text{psych} = 0.2cm
$$

:::{.fragment}
.. aber $\sigma_\text{med}$ und $\sigma_\text{psych}$ müssen jetzt aus unseren Messwerten geschätzt werden. Für das Beispiel nehmen wir an:

$$
\hat{\sigma}_\text{med} = 0.5\qquad\qquad\hat{\sigma}_\text{psych} = 0.2
$$
:::

:::{.fragment}
Wir schlagen die Formel für den Standardfehler bei unabhängigen Messungen und unähnlichen Varianzen ($\frac{\hat{\sigma}_\text{med}}{\hat{\sigma}_\text{psych}} > 2\;$!) nach und setzen ein:

$$
\hat{se}= \sqrt{\frac{\hat{\sigma}_\text{med}^2}{n_\text{med}} + \frac{\hat{\sigma}_\text{psych}^2}{n_\text{psych}}} \overset{(Computer)}{=}  0.098
$$

[(Erinnerung: es galt $n_\text{med}=n_\text{psych}=30$)]{style="font-size:20px"}
:::

:::
::: {.column width="20%"}
![](images/psych_med.png)
:::
::::


<!----------------->
<!--- New slide --->
<!----------------->
## Beispiel: t-Test für unabhängige Gruppen

:::: {.columns}
::: {.column width="60%"}

Mit dem Standardfehler bewaffnet, können wir nun den t-Wert berechnen:

:::{style="margin-top: -37px; margin-left: 30px"}
$$
t = \frac{\Delta \bar{x}}{\hat{se}} = \frac{0.2}{0.098} = 2.03
$$
:::

:::{.fragment}
Es fehlen noch die Freiheitsgrade. Bei ungleichen Varianzen ist die Formel recht sperrig:

:::{style="margin-top: -10px"}
$$
\begin{aligned}
\text{df}&=(n-1)\Big(1+\frac{2}{\left(\frac{\hat{\sigma}_\text{med}}{\hat{\sigma}_\text{psych}}\right)^2+\left(\frac{\hat{\sigma}_\text{psych}}{\hat{\sigma}_\text{med}}\right)^2}\Big) = \\
&=(30-1)\Big(1+\frac{2}{\left(\frac{0.5}{0.2}\right)^2+\left(\frac{0.2}{0.5}\right)^2}\Big) = 38.05
\end{aligned}
$$
:::

:::

:::
::: {.column width="40%"}
![](images/ttest1_example_v2.png)
:::
::::

:::{.fragment}
:::{style="margin-top: -12px"}
Aufgrund der gerichteten (positiven) Hypothese ist der p-Wert die Fläche *rechts des t-Wertes* unter der t-Verteilung:
:::

:::{style="margin-top: -35px; margin-left: 120px"}
$$
p=\int_{t}^{\infty}f_t(x|\scriptsize\text{df}\normalsize)dx = \int_{2.03}^{\infty}f_t(x|38.05)dx = 1-F_t(2.03|38.05) \overset{(Computer)}{=} 0.025
$$
:::
:::

:::{.fragment}
Der p-Wert ist dem p-Wert des z-Tests ($0.023$) sehr ähnlich. Dies ist wenig überraschend, da a) der Standardfehler einen ähnlichen Wert aufwies ($se=0.1$ beim z-Test) und b) die Zahl er Freiheitsgrade so hoch ist, dass der Unterschied Normalverteilung vs. t-Verteilung marginal ist.
:::


<!----------------->
<!--- New slide --->
<!----------------->
## t-Test für unabhängige Stichproben

**Klassischer Zweistichproben-t-Test (ähnliche Varianzen) versus Welch's t-Test (unähnliche Varianzen) &mdash; welcher der beiden Tests sollte nun verwendet werden?**

:::{.nonincremental}
- In der Psychologie sind ungleiche Varianzen die realistischere Annahme. Selbst bei randomisiert-kontrollierten Studien, bei denen Versuchspersonen den Gruppen aus einer identischen Ursprungs-Population zugewiesen werden, kann das Treatment selbst einen Einfluss auf die Varianz haben.
- Neben der Faustformel $0.5\le\frac{\hat{\sigma}_A}{\hat{\sigma}_B}\le2$ gibt es auch Testverfahren zur Überprüfung der Varianzgleichheit zwischen Gruppen, allerdings sind diese nicht unproblematisch
    - Ein Grund:auf Varianzgleichheit wird idR auf Basis eines nicht-signifikanten Ergebnis in einem solchen Test angenommen &mdash; "absence of evidence is not evidence of absence"^[Altman DG, Bland JM (1995) Absence of evidence is not evidence of absence. BMJ 311:485.]
:::


:::{style="margin-top: -15px"}
:::: {.columns}
::: {.column width="66%"}
:::{.nonincremental}
- Herrscht Varianzgleichheit vor und ist die Stichprobengröße nicht extrem klein in einer Gruppe, kommen der Student'sche t-Test und Welch's t-Test zu sehr ähnlichen Ergebnissen.
- Vor diesem Hintergrund wird empfohlen^[Delacre M, Lakens D, Leys C (2017) Why Psychologists Should by Default Use Welch’s t-test Instead of Student’s t-test. International Review of Social Psychology 30:92.], bereits ab moderaten Gruppengrößen (ca. $n\ge 8$ pro Gruppe) *immer* Welch's t-Test anzuwenden. In den meisten Statistikprogrammen ist dieser Test implementiert.
:::
:::
::: {.column width="34%"}


![Option für Welch's t-test in JASP.](images/welch_jasp.png){height=270px style="margin-top:-20px"}

:::
::::
:::


<!----------------->
<!--- New slide --->
<!----------------->
## Beispiel: t-Test für abhängige Messungen

:::: {.columns}
::: {.column width="80%"}
Sie führen ein Experiment *innerhalb der Med-Gruppe* (n=32) durch. In einer experimentellen Intervention stellen Sie den Med-Studierenden die Frage 

> Studieren Sie Medizin, weil es der Wunsch Ihrer Eltern ist? 

Sie messen die Nasenlängen dabei sowohl vor ("pre"), als auch nach ("post") der Intervention. Ihre [ungerichtete]{.underline} Hypothese ist, dass sich die Nasenlängen vor und nach der Intervention auf einem Signifikanzniveau $\alpha=0.05$ unterscheiden.
:::
::: {.column width="20%"}
![](images/med.png)
:::
::::

:::{.fragment}
Die Mittelwertdifferenz betrage $\Delta\bar{x} = \bar{x}_\text{post} - \bar{x}_\text{pre} = 0.1cm$.
:::

<div class="vspace-small"></div>


:::{.fragment}
Wir nehmen der Einfachheit halber an, dass die beiden Messungen $X_\text{pre}$ und $X_\text{post}$ unkorreliert sind, d.h. $\hat{\rho}=0$. Die Standardabweichungen seien $\hat{\sigma}_\text{pre}=\hat{\sigma}_\text{post}=0.5$. Die Standardabweichung $\hat{\sigma}_\Delta$ der Differenzvariable $\Delta X$ ist damit:
:::

:::{.fragment}
$$
\hat{\sigma}_\Delta=\sqrt{\hat{\sigma}_\text{pre}^2+\hat{\sigma}_\text{post}^2-2\,\hat{\rho}\hat{\sigma}_\text{pre}\hat{\sigma}_\text{post}} = \sqrt{(0.5)^2+(0.5)^2-0} = \frac{1}{\sqrt{2}}
$$
:::

:::{.fragment}
$$
\text{Standardfehler:}\qquad \hat{se}=\frac{\hat{\sigma}_\Delta}{\sqrt{n}} = \frac{1}{\sqrt{2}\sqrt{32}}=\frac{1}{8}
$$

:::

<!----------------->
<!--- New slide --->
<!----------------->
## Beispiel: t-Test für abhängige Messungen

:::: {.columns}
::: {.column width="60%"}

Nun können wir den t-Wert berechnen:

$$
t = \frac{\Delta\bar{x}}{\hat{se}} = \frac{0.1}{1/8} = 0.8
$$

:::{.fragment}
Aufgrund der ungerichteten Hypothese ist der p-Wert die Summe der Flächen unter der t-Verteilung links von $-|t|=-0.8$ [und]{.underline} rechts von $+|t|=0.8$.

Bei $\text{df}=n-1=31$ Freiheitsgraden gilt:
:::
:::
::: {.column width="40%"}
![](images/ttest1_example2_v2.png)
:::
::::


:::{.fragment}
$$
\begin{aligned}
p&=\int_{-\infty}^{-t}f_t(x|\scriptsize\text{df}\normalsize)dx + \int_{t}^{\infty}f_t(x|\scriptsize\text{df}\normalsize)dx \overset{(Symmetrie)}{=} 2\cdot\int_{-\infty}^{-t}f_t(x|\scriptsize\text{df}\normalsize)dx  = \\
&= 2\cdot F_t(-t|\scriptsize\text{df}\normalsize) \overset{(einsetzen)}{=} 2\cdot F_t(-0.8|31) \overset{(Computer)}{=} 0.43
\end{aligned}
$$
:::

:::{.fragment style="margin-top:60px"}
Der p-Wert ist also deutlich größer als unser Signifikanzniveau $\alpha=0.05$ und wir können die Nullhypothese $\Delta\bar{x}=0$ nicht ablehnen. More research is needed!
:::
