{
  "hash": "2316e080a360d7ea8696d1e9c22dea24",
  "result": {
    "markdown": "---\ntitle: \"Vorlesung 07: Effektstärke\"\n---\n\n## {.blackslide .center}\n\n<div class=\"vspace-small\"></div>\n\n:::: {.columns}\n::: {.column width=\"68%\"}\nSie sinnieren weiterehin über das Ergebnis Ihrer Beobachtungsstudie. Paradoxiker verbringen sowohl mehr Zeit auf TikTok, als auch weisen sie höhere Entzündungswerte auf. Zwar ist der Mittelwertsunterschied bei der TikTok-Zeit größer, aber Sie wissen, dass TikTok-Zeit und Entzündungswerte völlig unterschiedliche Skalen und daher nicht vergleichbar sind. \n\n:::\n::: {.column width=\"32%\"}\n::: {.content-hidden when-format=\"pdf\"}\n![](images/paradoxia_group_of_scientists.png){.hcenter-image height=200px style=\"margin-top:-20px !important\"}\n<!-- Source: Midjourney -->\n:::\n:::\n::::\n\n<div class=\"vspace-medium\"></div>\n![](images/paradoxia_histogram_inflammation_mean_std.png){height=300px}\n\nDie Frage lautet: wie kann man die beiden Gruppenunterschiede bezüglich TikTok-Zeit und Entzündungsparametern vergleichbar machen? Wie können wir eine Aussage treffen, welcher der beiden Effekte [stärker]{.underline} ist?\n\n\n# Effektstärke\n\n\n<!-- ## Der Forschungsprozess {.hcenter-slide}\n\n```yaml { .animate src=\"images/scientific_process.svg\"}\nsetup:\n    - element: \"#results\"\n      modifier: function() { this.node.style.fill = 'green'; }\n    - element: \"#resultsbg\"\n      modifier: function() { this.node.style.fill = '#d8ffe2';}\n``` -->\n\n## Effektstärke\n\n:::: {.columns}\n::: {.column width=\"60%\"}\n- In psycholgischer Forschung untersuchen wir in den meisten Fällen die Auswirkung von Variablen $X_i$ auf Variablen $Y_i$.\n- Diese Auswirkung ist entweder als **Unterschied** (z.B. wenn $X$ die Gruppenzugehörigkeit angibt) oder als **Zusammenhang** (wenn $X$ und $Y$ metrische Variablen mit einer vermuteten kausalen Wechselwirkung sind) messbar &mdash; man spricht auch von [**Effekten**]{color=\"navy\"}.\n- Wie kann die Aussagekraft bzw. Bedeutsamkeit von Effekten bestimmt und kommuniziert werden?\n    - &rArr; **statistische Signifikanz** (ab Vorlesung 10): kann ein Effekt *allein durch Zufall erklärt werden*?\n    - &rArr; **praktische Signifikanz** (Effektstärken): ist die Stärke des Effektes *in der Praxis bedeutsam*?\n:::\n::: {.column width=\"40%\"}\n![Beispiel: Studie zum Wohlbefinden in Regionen mit und ohne Corona-Kontaktsperre](images/mittelwertunterschied.png)\n:::\n::::\n\n- Die Stärke eines Effektes im Sinne der praktischen Signifikanz wird als [**Effektstärke**]{color=\"navy\"} oder [**Effektgröße**]{color=\"navy\"} bezeichnet. Wir werden nachfolgend den Begriff Effektstärke verwenden.\n- Unterschiedlichen Maße für die Effektstärke werden als [**Effektmaße**]{color=\"navy\"} bezeichnet.\n\n## Unstandardisierte Effektstärken\n\n- Mittelwertsdifferenzen, Kovarianzen und Regressionskoeffizienten sind [**unstandardisierte Effektstärken**]{color=\"navy\"}, weil sie in den Rohwerten der Messung vorliegen.\n\n<!---  Example --->\n::: {.example}\n|||\n|:-:|-|\n| ![](images/example.png){height=70px} | **Beispiel Mittelwertunterschied:** der durchschnittliche Größenunterschied von erwachsenen Männern und Frauen in Deutschland beträgt 16**cm**^[https://www.laenderdaten.info/durchschnittliche-koerpergroessen.php]. |\n: {tbl-colwidths=\"[10, 90]\"}\n:::\n\n<div class=\"vspace-small\"></div>\n\n<!---  Example --->\n::: {.example}\n|||\n|:-:|-|\n| ![](images/example.png){height=70px} | **Beispiel unstandardisierter Regressionskoeffizient:** je 0,1 Verbesserung in der **Abiturnote** steigt das monatliche Einstiegseinkommen um durschnittlich 70 **Euro**^[Arbeitsberichte Dresdner Soziologie Nr. 21, https://tud.qucosa.de/api/qucosa%3A24622/attachment/ATT-0/]. |\n: {tbl-colwidths=\"[10, 90]\"}\n:::\n\n- In beiden Beispielen haben die Effektstärken sinnvolle und interpretierbare Einheiten und wären vergleichbar zwischen Studien.\n- Gerade in der Psychologie ist dies aber nicht immer gegeben:\n    - Fragebögen: Punktzahlen hängen willkürlich vom Kodierungsschema und der Zahl der Items ab\n    - Ratingskalen: Ratingskalen unterscheiden sich häufig (Wohlbefinden auf einer Skala von 0 bis 100%, Wohlbefinden auf einer Skala von -5 bis 5, usw.)\n- Falls die Skala (z.B. der verwendete Fragebogen) neu oder wenig bekannt ist, wie soll dann der Effekt interpretiert werden? Wann kann er als groß und wann als klein gelten?    \n\n## Standardisierte Effektstärken\n\n- Um Effektstärken unabhängig von der verwendeten Skala zu vergleichen, werden Effektstärken **standardisiert**.\n- Die Transformation der **Standardisierung** haben wir bereits bei Zufallsvariablen kennengelernt: *Teilen durch die Standardabweichung*.\n  - Dieser Ansatz lässt sich analog auch auf Effekte beziehen\n  - Ein Beispiel für einen Effekt ist die Mittelwertdifferenz &mdash; hier gilt:<br>standardisierte Effektstärke = Mittelwertdifferenz / Standardabweichung\n  - Besteht der Effekt aus einem Produkt zweier Variablen (wie bei der Kovarianz), muss der Effekt durch die Standardabweichung beider Variablen geteilt werden, um die Einheiten herauszukürzen.\n- In der Folge sind standardisierte Effekte einheitslos, da die zugrundegelegten Standardabweichungen die gleiche Einheit wie die Effekte haben.\n- Zu beachten ist, dass das Teilen durch die Standardabweichung der resultierenden Effektstärke eine spezifische Interpretation zuschreibt: *ein Effekt wird als \"stärker\" gewertet, wenn der unstandardisierte Effekt groß ist im Vergleich zur zugrundegelegten Standardabweichung*.\n- Es gibt zwei wesentliche Funktionen / Einsatzzwecke von Effektstärken:\n  - Einordnung der Stärke eines Effektes in einer *einzelnen Studie*\n  - Vergleichbarmachung von Effekten zwischen *verschiedenen Studien*\n\n# Mittelwertunterschiede\n\n## Cohen's d\n\n- Es werden drei Fälle von Mittelwertunterschieden unterschieden:\n    - Fall 1: eine Stichprobe + Einzelmessung: Differenz zwischen dem Mittelwert einer Messung und einem Referenzwert (z.B. IQ=100).\n    - Fall 2: eine Stichprobe + abhängige Messungen: Differenz der Mittelwerte zweier Messungen in derselben Gruppe (z.B. IQ morgens und IQ abends).\n    - Fall 3: zwei Stichproben + unabhängige Messungen: Differenz der Gruppenmittelwerte<br>(z.B. IQ in einer blonden versus brünetten Gruppe).\n- Die standardisierte Effektstärke für alle drei Fälle eines Mittelwertunterschieds berechnet sich als \n\n$$\nd = \\frac{\\text{Mittelwertdifferenz}}{\\text{Standardabweichung}}\n$$\n\n- Die Bezeichnung $d$ für standardisierte Mittelwertunterschiede stammt von dem Statistiker Jacob Cohen &mdash; häufig wird daher auch von [**Cohen's d**]{color=\"navy\"} gesprochen.\n- Während die Mittelwertdifferenz eindeutig ist, ist die weniger triviale Frage: Standardabweichung *von was*?\n\n\n## Fall 1: eine Stichprobe + Einzelmessung\n\n:::: {.columns}\n::: {.column width=\"63%\"}\n**Es gibt nur eine einzelne Messung an einer Gruppe und die Frage ist, ob der Mittelwert $\\bar{x}$ bedeutsam über einem Referenzwert $\\mu_0$ liegt.**\n\n<div class=\"vspace-small\"></div>\n\n$$\n\\text{Mittelwertdifferenz} = \\bar{x} - \\mu_0\n$$\n\n<!-- <div class=\"vspace-medium\"></div> -->\n\n::: {.colorbox .fragment}\n$$\n\\text{Standardisierte Effektstärke:}\\qquad d = \\frac{\\bar{x} - \\mu_0}{\\hat{\\sigma}}\n$$\n:::\n\n\n:::\n::: {.column width=\"37%\"}\n::: {style=\"margin-top:-25px\"}\n![Beispiel: Studie zum Wohlbefinden &mdash; ist das Wohlbefinden *in der Gruppe* mit Kontaktsperre noch im positiven Bereich ($\\bar{x}>\\mu_0 \\text{ mit } \\mu_0=0$)?](images/unterschied_referenz.png){height=300px}\n:::\n:::\n::::\n\n::: {style=\"margin-top:-25px\"}\n- Die Wahl der Standardabweichung bereitet hier keine Kopfzerbrechen &mdash; es ist schlicht die Standardabweichung der Variable $X$ in der Stichprobe.\n- Die Formel für die Standardabweichung ist die bekannte Formel mit Besselkorrketur:\n:::\n\n::: {style=\"margin-top:-25px\"}\n$$\n\\hat{\\sigma} = \\sqrt{\\frac{\\sum\\left(x_i-\\bar{x}\\right)^2}{n\\color{darkgreen}{-1}}}\n$$\n:::\n\n\n\n\n\n## Fall 2: eine Stichprobe + zwei abhängige Messungen\n\n:::: {.columns}\n::: {.column width=\"68%\"}\n\n**Es wird die Mittelwertdifferenz $\\bar{x}_A - \\bar{x}_B$ zweier abhängiger Messungen in einer Stichprobe berechnet und die Frage ist, ob diese Differenz bedeutsam ist.**\n\n\n<!-- <div class=\"vspace-small\"></div> -->\n\n$$\n\\text{Mittelwertdifferenz} = \\bar{x}_A - \\bar{x}_B\n$$\n\n::: {.colorbox .fragment}\n$$\n\\text{Standardisierte Effektstärke:}\n$$\n\n<div class=\"vspace-xsmall\"></div>\n\n$$\nd = \\frac{\\bar{x}_A - \\bar{x}_B}{\\hat{\\sigma}_\\Delta}\n$$\n:::\n\n:::\n::: {.column width=\"32%\"}\n![Beispiel: Unterscheidet sich das Wohlbefinden *in derselben Gruppe* vor und nach einer Kontaktsperre?](images/mittelwertunterschied_within2.png)\n:::\n::::\n\n- $\\hat{\\sigma}_{\\Delta}$ ist die Standardabweichung der Differenzenvariable $\\Delta X=X_A-X_B$:\n\n:::{style=\"margin-top: -25px\"}\n$$\n\\hat{\\sigma}_{\\Delta} = \\sqrt{\\frac{\\sum\\left(\\Delta x_i-\\Delta\\bar{x}\\right)^2}{n-1}} \\qquad\\text{und}\\quad \\Delta x_i = x^{(A)}_i - x^{(B)}_i\n$$\n\n:::\n- Wir bezeichnen diese als **Differenzenvarianz**.\n\n\n\n## Andere Darstellung der Differenzenvarianz\n\n- Mit einigen mathematischen Tricks lässt sich zeigen, dass die Standardabweichung der Differenzwerte auch wie folgt dargestellt werden kann:\n\n:::{style=\"margin-top: -5px\"}\n$$\n\\hat{\\sigma}_\\Delta = \\sqrt{\\hat{\\sigma}^2_A + \\hat{\\sigma}^2_B - 2\\,\\hat{Cov}(X_A,X_B)} = \\sqrt{\\hat{\\sigma}^2_A + \\hat{\\sigma}^2_B - 2\\,\\hat{\\rho}\\hat{\\sigma}_A\\hat{\\sigma}_B}\n$$\n:::\n\n:::{.compact-sublist}\n- $\\hat{\\rho}$ ist der Pearson-Korrelationskoeffizient zwischen den Messungen $X_A$ und $X_B$.\n- Diese Formel macht transparent, dass die Differenzenvarianz vom Zusammenhang zwischen $X_A$ und $X_B$ abhängt:\n    - Sind die Zufallsvariablen *nicht korreliert* ($\\hat{\\rho}=0$), so ist die Varianz der Differenz einfach der Summe der Einzelvarianzen.\n    - Sind die Zufallsvariablen *positiv korreliert* ($\\hat{\\rho}>0$), so reduziert sich die Summe in Abhängigkeit von der Kovarianz.\n    - Sind die Zufallsvariablen *negativ korreliert* ($\\hat{\\rho}<0$), so erhöht sich die Summe in Abhängigkeit von der Kovarianz.<br>(*Subtraktion* der *negativen* Kovarianz resultiert in einer Erhöhung &mdash; \"minus x minus = plus\").\n:::\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## Andere Darstellung der Differenzenvarianz\n\n\nDer Effekt der Kovarianz auf die Varianz der Differenzwerte ist besonders intuitiv bei einer positiven Korrelation. Betrachten wir zwei Variablen $X_A$ und $X_B$ mit unterschiedlichen Kovarianzen und wie sich dabei jeweils die Variabilität des Differenzwertes entwickelt:\n\n<div class=\"vspace-medium\"></div>\n\n![In allen drei Plots gilt $\\bar{x}_A=6$ und $\\bar{x}_B=5$, d.h. $\\bar{x}_A-\\bar{x}_B=1$.](images/pooled_variance_dependent.png)\n\n<div class=\"vspace-medium\"></div>\n\nWir sehen: je höher die Korrelation $\\bar{x}_A$ und $\\bar{x}_B$, desto geringer die Variabilität der Differenz von $\\bar{x}_A-\\bar{x}_B$! Ist die Korrelation perfekt ($r=1$), so ist die Differenz sogar konstant, d.h. ihre Variabilität ist gleich 0.\n\n::: {#07bac678 .cell execution_count=1}\n\n::: {.cell-output .cell-output-stdout}\n```\ncov=1.039; r=1.000; deltaX=1.00\ncov=0.940; r=0.749; deltaX=1.00\ncov=0.006; r=0.004; deltaX=1.00\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-revealjs/cell-2-output-2.png){width=949 height=229}\n:::\n:::\n\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## Fall 2: eine Stichprobe + zwei abhängige Messungen\n\n- Bei der Standardisierung mit $\\hat{\\sigma}^2_\\Delta$ wird der Effekt (Mittelwertdifferenz) mit der *Streuung des Effektes* (Varianz der Mittelwertdifferenz) ins Verhältnis gesetzt.\n- Diese Art der Standardisierung entspricht der intuitiven Grundidee von Cohen's d: den unstandardisierte Effekt an seiner eigenen Streuung zu relativieren (d.h. zu standardisieren).\n\n**Variante b): gepoolte Varianz**\n\n$$\nd = \\frac{\\bar{x}_A - \\bar{x}_B}{\\hat{\\sigma}_\\text{pooled}}\n$$\n\n- **Problem:** häufig sollen Effektstärken zwischen Designs mit *abhängigen* und *unabhängigen* Messungen verglichen werden &mdash; jedoch lässt sich in Fall 2 (unabhängige Messungen) keine Differenzenvarianz berechnen.\n- Aus diesem Grund gibt es eine zweite gängige von Cohen's d bei abhängigen Messungen, die auf der **gepoolten Varianz** basiert (analog zu Fall 2):\n\n:::{style=\"margin-top: -12px\"}\n$$\n\\hat{\\sigma}^2_\\text{pooled} = \\frac{\\hat{\\sigma}^2_A + \\hat{\\sigma}^2_B}{2}\\quad\\text{bzw.}\\quad\\hat{\\sigma}_\\text{pooled} = \\sqrt{\\frac{\\hat{\\sigma}^2_A + \\hat{\\sigma}^2_B}{2}}\n$$\n:::\n\n- Beachte, dass hier die gepoolte Varianz $\\hat{\\sigma}^2_\\text{pooled}$ identisch mit der ungepoolten (einfach gemittelten) Varianz $\\hat{\\sigma}^2_\\text{av}$ ist, da bei abhängigen Messungen immer gilt: $n=n_A=n_B$.\n\n\n\n\n## Fall 3: zwei Stichproben + unabhängige Messungen\n\n:::: {.columns}\n::: {.column width=\"68%\"}\n\n**Es wird die Mittelwertdifferenz $\\bar{x}_A - \\bar{x}_B$ zweier unabhängiger Gruppen berechnet und die Frage ist, ob diese Differenz bedeutsam ist.**\n\n<div class=\"vspace-small\"></div>\n\n$$\n\\text{Mittelwertdifferenz} = \\bar{x}_A - \\bar{x}_B\n$$\n\n<div class=\"vspace-small\"></div>\n\n::: {.colorbox .fragment}\n$$\n\\text{Standardisierte Effektstärke:}\\qquad d = \\frac{\\bar{x}_A - \\bar{x}_B}{\\hat{\\sigma}_\\text{pooled}}\\qquad\n$$\n:::\n\n- Im Nenner von Cohen's d wird hier die **gepoolte Varianz** verwendet. \n- Es handelt sich dabei um die mittlere Varianz über beide Gruppen hinweg, entsprechend einem an den Stichprobengrößen $n_A$ und $n_B$ gewichteten Mittelwert:\n\n:::\n::: {.column width=\"32%\"}\n![Unterscheidet sich der Mittelwert zweier Gruppen?](images/effectsize_pooledSD.png)\n\n:::\n::::\n\n$$\n\\hat{\\sigma}_\\text{pooled} = \\sqrt{\\frac{(n_A-1)\\hat{\\sigma}_A^2 + (n_B-1)\\hat{\\sigma}_B^2}{n_A+n_B-2}}\\qquad\\quad\\text{Falls }n_A=n_B=n:\\;\\; \\hat{\\sigma}_\\text{pooled} = \\sqrt{\\frac{\\hat{\\sigma}_A^2 + \\hat{\\sigma}_B^2}{2}}\n$$\n\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## [Einschub: gepoolte Varianz]{color=\"darkred\"}\n\n![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=110px}\n\n- Bei unabhängigen Messungen ist es nicht (wie in Fall 3) möglich, die Einzelmesswerte $x_{A,i}$ und $x_{B,i}$ direkt voneinander abzuziehen. Nicht zuletzt wäre es völlig unklar, welche Versuchsperson aus A jeweils von welcher Versuchsperson aus B subtrahiert wird.\n- Damit kann auch nicht die Varianz der individuellen Effekte der Versuchspersonen berechnet werden (\"Differenzenvarianz\"), sondern lediglich eine **gepoolte Varianz** $\\hat{\\sigma}^2_\\text{pooled}$.\n- Die Annahme ist dabei, dass beide Gruppen eine ähnliche Streuung haben, z.B. weil sie randomisiert aus derselben Population gezogen wurden und man nicht erwartet, dass die Gruppenzugehörigkeit die Varianz beeinflusst.\n- Der Name leitet sich von der Vorstellung ab, die Datenpunkte beider Gruppen in einen gemeinsamen \"Pool\" zu werfen, und dann die Varianz auf allen Daten zu berechnen.\n- Vor dem \"Wurf in den Pool\" müssen die Mittelwerte der Datenpunkte aus den jeweiligen Gruppen gleichgesetzt werden &mdash; im einfachsten Fall so, dass jeweils der Gruppenmittelwert von den Datenpunkten abgezogen wird (die Daten werden **zentriert** &mdash; beide Gruppen haben danach den Mittelwert 0):\n\n:::{style=\"margin-top:-43px\"}\n$$\nX'_A = X_A - \\bar{X}_A\\qquad und\\qquad X'_B = X_B - \\bar{X}_B\n$$\n:::\n\n$$\nX_\\text{pooled} = [X'_A; X'_B]\n$$\n\n$$\n\\hat{\\sigma}^2_\\text{pooled} = \\hat{Var}(X_\\text{pooled})\n$$\n\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## [Einschub: gepoolte Varianz]{color=\"darkred\"}\n\n![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=110px}\n\n:::{.nonincremental}\n- Es lässt sich mathematisch recht einfach zeigen, dass die gepoolte Varianz identisch dem an den Stichprobengrößen $n_A$ und $n_B$ gewichteten Varianzmittelwert ist:\n:::\n\n$$\n\\hat{\\sigma}^2_\\text{pooled} = \\frac{(n_A-1)\\hat{\\sigma}^2_A + (n_B-1)\\hat{\\sigma}^2_B}{n_A+n_B-2}\\quad\\text{bzw.}\\quad\\hat{\\sigma}_\\text{pooled} = \\sqrt{\\frac{(n_A-1)\\hat{\\sigma}^2_A + (n_B-1)\\hat{\\sigma}^2_B}{n_A+n_B-2}}\n$$\n\n:::{.fragment .smaller}\n&numsp;&numsp;Die Subtraktion von 1 von den Stichprobengrößen $n_A$ und $n_B$ ist Ausdruck der Besselkorrektur.\n:::\n\n- Die Gewichtung mit den Stichprobengrößen grenzt die gepoolte Varianz von der einfach gemittelten Varianz $\\hat{\\sigma}_\\text{av}^2$ ab:\n\n:::{style=\"margin-top: -20px\"}\n$$\n\\hat{\\sigma}_\\text{av}^2 = \\frac{\\hat{\\sigma}_A^2+\\hat{\\sigma}_B^2}{2}\\quad\\text{bzw.}\\quad\\hat{\\sigma}_\\text{av}^2 = \\sqrt{\\frac{\\hat{\\sigma}_A^2+\\hat{\\sigma}_B^2}{2}}\n$$\n:::\n\n- $\\hat{\\sigma}_\\text{av}^2$ wird auch als **ungepoolte Varianz** bezeichnet, weil hier nicht alle Datenpunkte in einen Pool geworfen werden, sondern die Varianzen $\\hat{\\sigma}_A^2$ und $\\hat{\\sigma}_B^2$ einzeln berechnet und anschließend ohne Berücksichtigung unterschiedlicher Stichprobengrößen gemittelt werden.\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## [Einschub: gepoolte Varianz]{color=\"darkred\"}\n\n![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=95px}\n\n- Der Nachteil der gepoolten Varianz ist, dass sie nicht mehr der interindividuellen Variabilität des Effektes (hier Mittelwertdifferenz) entspricht, sondern der Variabilität des gemessenen Merkmals $X$.\n    - Die Mittelwertdifferenz im Zähler wird also streng genommen nicht mehr ins Verhältnis zu ihrer eigenen Variabilität gesetzt.\n- Die gepoolte Varianz hat jedoch auch einen Vorteil: es wird de facto nur eine Varianz geschätzt (die Popuationsvarianz des Merkmals $X$) und diese Schätzung basiert auf $n_A+n_B$ Versuchspersonen. Sie kann also recht präzise geschätzt werden. Die Präzision der Varianz bestimmt wiederum direkt und wesentlich die Präzision des Effektstärkenmaßes selbst.\n- Wenn Effektstärken in erster Linie zur Vergleichbarmachung mit anderen Studien dienen (Stichwort **Metaanalyse**), ist eine a) *präzise* und b) *zwischen Studien vergleichbare* Schätzung der Varianz ein wichtiger Aspekt &mdash; ggf. wichtiger als die Interpretierbarkeit des resultierenden Effektmaßes.\n\n\n<!---  Example --->\n::: {.example}\n:::: {.columns}\n::: {.column width=\"10%\"}\n::: {style=\"margin-top: 10px\"}\n![](images/example.png){height=70px}\n:::\n:::\n::: {.column width=\"90%\"}\nBei einem Pre-post-Interventionsdesign (Messung vor und nach einer Intervention an derselben Gruppe), kann es vorteilhaft sein, nur die *Standardabweichung des Vortestes* für die Standardisierung zu nehmen. Grund: die Variabilität *vor* einer Intervention ist am ehesten zwischen Studien vergleichbar &mdash; damit werden auch die Effektstärken besser vergleichbar.^[Cumming G (2013) Cohen’s d needs to be readily interpretable: Comment on Shieh (2013). Behav Res 45:968–971.] In der Praxis geschieht dies aber selten (nicht immer ist die statistisch beste auch die populärste Praxis).\n:::\n::::\n:::\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## [Einschub: gepoolte Varianz]{color=\"darkred\"}\n\n![](images/kein_klausurstoff.png){.absolute top=10 right=0 height=100px}\n\n- Eine wichtige Voraussetzung für die Verwendung der gepoolten Varianz ist, dass die<br>Einzelvarianzen $\\sigma^2_A$ und $\\sigma^2_A$ ähnlich sind.\n- Warum? Die Idee ist, die Varianzschätzung des Merkmals durch Nutzung der Datenpunkte *beider* Gruppen zu verbessern. Sind die Varianzen in beiden Gruppen jedoch unterschiedlich, so ist der Fall gegeben, dass es gar nicht *die eine* Varianz des Merkmals gibt, sondern die Varianz stark von der Gruppenzugehörigkeit abhängt.\n- Eine gängige Faustregel besagt, dass die Varianzen sich höchstens um den Faktor 2 unterscheiden sollten, d.h. $0{,}5<\\frac{\\sigma^2_A}{\\sigma^2_B}<2$.\n- Diese Einschränkung bei der Verwendung der gepoolten Varianz wird jedoch häufg missachtet, mutmaßlich auch, weil sich keine alternative Lösung für den Fall unabhängiger Messungen in großer Breite etabliert hat.\n    - In einem aktuellen Preprint schlagen Delacre und Kollegen für den Fall unabhängiger Messungen und unterschiedlicher Varianzen die Effektstärkengröße *Hedges*’ g* auf Basis der ungepoolten Varianz $\\hat{\\sigma}_\\text{av}$ vor ^[Delacre M, Lakens D, Ley C, Liu L, Leys C (2023) Why Hedges’ g*s based on the non-pooled standard deviation should be reported with Welch’s t-test. Open Science Framework. Available at: https://osf.io/tu6mp. Hinweis: der Terminus \"ungepoolte\" Varianz meint hier, dass die Daten nicht implizit in einen Pool geworfen werden und dann die Gesamtvarianz berechnet wird; stattdessen wird unabhängig von möglicherweise unterschiedlich großen Gruppengrößen $n_A$ und $n_B$ der Mittelwert der beiden Einzelvarianzen berechnet.]:\n\n$$\n\\text{Hedges'}\\,g^* \\approx \\left(1-\\frac{3}{4(n_A+n_B)-9}\\right)\\cdot \\frac{\\bar{x}_A - \\bar{x}_B}{\\hat{\\sigma}_\\text{av}}\\quad\\text{mit}\\quad \\hat{\\sigma}_\\text{av}=\\sqrt{\\frac{\\hat{\\sigma}^2_A+\\hat{\\sigma}^2_B}{2}}\n$$\n\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## [Aktuelle Forschung]{color=\"darkred\"}\n\n![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=110px}\n\n- Laut einer aktuellen Forschungsarbeit^[Cousineau D (2020) Approximating the distribution of Cohen’s d_p in within-subject designs. TQMP 16:418–421.] sind die Werte von Cohen's d auf Basis der gepoolten Varianz nicht exakt vergleichbar zwischen abhängigen und unabhängigen Messungen (auch dann, wenn die Varianzen ähnlich sind).\n- Die Arbeit bietet dafür folgende Modifikation von Cohen's d für abhängige Messungen an:\n\n\n$$\nd = \\sqrt{\\frac{2(1-r)}{n}}\\cdot t'_\\nu(\\lambda)\\quad\\text{mit}\\quad \\lambda = \\sqrt{\\frac{n}{2(1-r)}}\\cdot\\frac{\\bar{x}_A - \\bar{x}_B}{\\hat{\\sigma}_\\text{pooled}}\n$$\n\n:::{.smaller}\nwobei $r$ die Pearson-Korrelation zwischen den beiden abhängigen Messungen ist und $t'$ die nichtzentrale *t*-Verteilung mit $\\nu = 2(n − 1)/(1 + r^2)$ Freiheitsgraden. Beachte, dass die Formel nur gilt, falls ähnliche Varianzen in den beiden Bedingungen A und B angenommen werden können.\n:::\n\n- Laut dem Autor Denis Cousineau der Forschungsarbeit ist damit Cohen's d exakt vergleichbar zwischen abhängigen und unabhängigen Messungen.\n- Weiterer nützlicher Link zu Effektstärken bei abhängigen Messungen: ^[http://jakewestfall.org/blog/index.php/2016/03/25/five-different-cohens-d-statistics-for-within-subject-designs/]\n\n\n# Interpretation\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## Interpretation von Cohen's d\n\n- Die Werte von Cohen's $d$ reichen von $-\\infty$ bis $+\\infty$. Negative Werte sind möglich, da das Vorzeichen davon abhängt, welcher Mittelwert von welchem abgezogen wird.\n    - Es ist Konvention, $d$ so zu berechnen, dass $d$ positiv ausfällt, falls der Effekt in die hypothesierte Richtung geht.\n    - Die Interpretation der Effektstärke macht sich aber am absoluten Wert $|d|$ fest: wenn $d=-0{,}3$, dann hat der Effekt eine Stärke von $d=0{,}3$, aber in eine andere Richtung als erwartet.\n- Durch die Standardisierung mit der Standardabweichung gilt umgekehrt, dass Cohen's d ausdrückt, um wie viel Standardabweichungen ein Effekt von einem Nulleffekt abweicht. Diese Interpretation ist am intuitivsten für den Fall einer *Einzelmessung mit Referenzwert*:\n\n\n<!---  Example --->\n::: {.example}\n:::: {.columns}\n::: {.column width=\"10%\"}\n::: {style=\"margin-top: 10px\"}\n![](images/example.png){height=70px}\n:::\n:::\n::: {.column width=\"90%\"}\nEine Studie untersucht, ob die Schlafdauer in einer Gruppe von Psychologiestudierenden in der Bachelorarbeitsphase geringer ist als die durchschnittliche Schlafdauer in Deutschland (7:45 Stunden). Tatsächlich zeigt sich eine verringerte Schlafdauer mit einem Cohen's d von $0{,}3$.\n:::\n::::\n:::\n\n- Die Effektstärke von $0{,}3$ sagt aus, dass die Schlafdauer um $0{,}3$ *Standardabweichungen* gegenüber dem Durchschnittswert verringert ist. Die Einheit *Standardabweichung* bezieht sich dabei auf die Standardabweichung $\\hat{\\sigma}$ der Schlafdauer in der untersuchten Gruppe.\n    - Bei mehreren Bedingungen/Gruppen gilt zwar weiterhin die Interpretation im Sinne von *in Einheiten von Standardabweichungen*, allerdings ist die Definition der Standardabweichungen ($\\hat{\\sigma}_{\\Delta}$, $\\hat{\\sigma}_\\text{pooled}$) eher kompliziert und damit nicht mehr sonderlich intuitiv.\n\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## Interpretation von Effektstärken\n\n- Um Effektstärken besser einordnen und kommunizieren zu können, hat Jacob Cohen folgende Unterteilung vorgeschlagen:\n\n\n:::{style=\"margin-top: -25px\"}\n<!---  Table --->\n|d|r|Interpretation|\n|:-:|:-:|-|\n| $<0.2$ | $<0.1$ | Trivialer Effekt |\n| ab $0.2$ | ab $0.1$ | Kleiner Effekt |\n| ab $0.5$ | ab $0.3$ | Mittlerer Effekt |\n| ab $0.8$ | ab $0.5$ | Großer Effekt |\n: {tbl-colwidths=\"[33, 33, 34]\"}\n\n:::\n\n- Zugleich fügt aber Cohen selbst folgende Qualifizierung an:\n\n![](images/cohen_effectsizes.png){height=140px}\n\n- Effektstärken sollten also idealerweise in ihrem jeweiligen Kontext interpretiert werden.\n- **Beispiel:** Effektstärken bezüglich der Veränderung des Körpergewichts durch Diäten sind erwartbar größer, als Veränderungen bei eher stabilen Merkmalen wie Persönlichkeitsfacetten. &rArr; Ein d-Wert der einer vergleichsweise geringen Veränderung des Körpergewichts entspricht, würde vielleicht in der Persönlichkeitsforschung als starker Effekt gelten.\n\n\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## Interpretation von Cohen's d\n\n- Um zu beurteilen, was als kleine / mittlere / starke Effekte in einem spezifischen Kontext gilt, konsultiert man prinzipiell die entsprechende Fachliteratur nach typischen Referenzeffektstärken.\n- Problem: es gibt gute Evidenz, dass *publizierte Effekte* die *wahren Effekte*<br>überschätzen (**Publikationsbias**) &rArr; führt zu falschen Maßstäben\n\n:::: {.columns}\n::: {.column width=\"70%\"}\n\n![](images/effectsizes_prereg_schaefer.png){height=330px}\n\n:::\n::: {.column .caption-style width=\"30%\"}\nDie Abbildung zeigt, dass Effekte, bei denen Hypothesen und Analysen vorab registriert wurden (\"with pre-registration\") deutlich geringere Effektstärken aufweisen, als Effekte \"without pre-registration\". In der Abbildung ist zu beachten, dass die absolute und nicht die relative Häufigkeit aufgetragen ist, wodurch Studien ohne Preregistrierung &mdash; von denen es deutlich mehr gibt &mdash; visuell dominieren.^[Schäfer T, Schwarz MA (2019) The Meaningfulness of Effect Sizes in Psychological Research: Differences Between Sub-Disciplines and the Impact of Potential Biases. Frontiers in Psychology 10 Available at: https://www.frontiersin.org/articles/10.3389/fpsyg.2019.00813.]\n\n:::\n::::\n\n&rArr; Die Interpretation und Einordnung von Effektstärken ist ein nicht-triviales Problem, das viel \"domain knowledge\" erfordert. Dies gilt für standardisierte wie unstandardisierte Effektstärken.\n\n- Faustregeln finden sich hier: \n<a href=\"https://imaging.mrc-cbu.cam.ac.uk/statswiki/FAQ/effectSize\" target=\"_blank\">https://imaging.mrc-cbu.cam.ac.uk/statswiki/FAQ/effectSize</a>\n\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## [Typische Effektstärken in der Sozialpsychologie]{color=\"darkred\"}\n\n![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=110px}\n\n<div class=\"vspace-medium\"></div>\n![Typische Effektstärke in der sozialpsychologischen Literatur^[Lovakov A, Agadullina ER (2021) Empirically derived guidelines for effect size interpretation in social psychology. Eur J Soc Psychol 51:485–504.].](images/lovakov2021_typical.png){height=550px}\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## [Typische Effektstärken in der Sozialpsychologie]{color=\"darkred\"}\n\n![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=110px}\n\n<div class=\"vspace-medium\"></div>\n![Trotz Publikationsbias sind die tatsächlich in der Literatur berichteten Effektstärken geringer als bei der Einteilung nach Cohen angenommen. Auf Basis dieser Studie wären die korrekten Grenzen für Cohen's d 0,15, 0,36, und 0,65. Bild adaptiert von Lovakov & Agadulina (2021)^[Lovakov A, Agadullina ER (2021) Empirically derived guidelines for effect size interpretation in social psychology. Eur J Soc Psychol 51:485–504.].](images/lovakov2021_effectsizes.png){height=550px}\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n:::{.content-hidden when-format=\"pdf\"}\n## https://rpsychologist.com/d3/cohend/\n<iframe width=100% height=100% src=\"https://rpsychologist.com/d3/cohend/\"></iframe>\n:::\n\n\n## Standardisierte oder unstandardisierte Effektstärken?\n\n- Die Frage ob Effektstärken in standardisierter oder unstandardisierter Form berichtet werden sollten wird durchaus kontrovers diskutiert^[https://twitter.com/ceptional/status/1687577019629142017] ^[Baguley T (2009) Standardized or simple effect size: What should be reported? British Journal of Psychology 100:603–617.].\n- Standardisierte Effektstärken ermöglichen eine bessere Vergleichbarkeit zwischen unterschied-lichen Skalen, gleichzeitig wird die intuitive Bedeutung von *Effektstärke* aber verwässert.\n\n<!---  Example --->\n::: {.example}\n:::: {.columns}\n::: {.column width=\"10%\"}\n::: {style=\"margin-top: 10px\"}\n![](images/example.png){height=70px}\n:::\n:::\n::: {.column width=\"90%\"}\nEs wird berichtet, dass ein Coronoaimpfstoff die Viruslast bei einer Infektion reduziert. Die Effektstärke wird mit $\\text{Cohen's }d=0.4$ angegeben.\n:::\n::::\n:::\n\n- Aus diesem Beispiel wird klar, dass die Effektstärke zum einen wenig intuitiv ist (in jedem Fall für Nicht-Wissenschaftler:innen), zum anderen ist nicht ersichtlich, ob die Viruslast nennenswert reduziert wurde oder ob der Rückgang eher klein war, aber die Standardabweichung in der Gruppe so gering, dass dennoch ein hoher $d$-Wert erreicht wurde.\n- Darüber hinaus hängt die Standardabweichung einer Variable häufig mit eher nebensächlichen Details eines experimentellen Designs (within-subject vs. between-subject) oder einer Stichprobe (nur Psychologiestudierende oder heterogeneres Sample der Allgemeinbevölkerung?) zusammenhängt, die für die Effektstärke wenig relevant sind.\n- Aus diesen Gründen sollte für **Effekte, die in interpretierbaren Einheiten vorliegen, immer (auch) die unstandardisierte Effektstärke** angegeben werden (z.B. Notenstufen, Einkommen, IQ-Punkte, Größe- Gewichtsangaben, Zeitangaben).\n\n# Effektstärke bei Zusammenhängen\n\n## Korrelationskoeffizient\n\n- Im Fall von Zusammenhangsanalysen haben wir die standardisierte Effektstärke bereits kennengelernt: der **Korrelationskoeffizient** ($r$, $r_s$, $\\tau$, $\\phi$). Beispiel Pearson-Korrelation:\n\n$$\nr = \\frac{Cov(X,Y)}{s_X s_Y}\n$$\n\n- Der Nenner $s_X s_Y$ stellt hier die Standardisierung dar.\n- Wir können sehen, dass $r$ standardisiert ist, da es keine Einheit hat und eine vergleichbar ist zwischen verschiedenen Skalen und verschiedenen Variablen.\n\n::: {.merke}\n:::: {.columns}\n::: {.column width=\"5%\"}\n::: {style=\"margin-top: 18px\"}\n![](images/merke.png){height=\"55px\"}\n:::\n:::\n::: {.column width=\"95%\"}\nAlle Korrelationskoeffizienten ($r$, $r_s$, $\\tau$, $\\phi$) sind bereits Effektstärken.\n:::\n::::\n:::\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## [Umrechnung von Cohen's $d$ und Korrelationskoeffizient $r$]{color=\"darkred\"}\n\n![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=110px}\n\nFassen Metaanalysen sowohl Studien zusammen, die Effekte als Korrelation berichten (Effektmaß $r$), als auch Studien, die Effekte als Mittelwertsunterschiede zwischen Bedingungen/Gruppen berichten (Effektmaß $d$), entsteht die Notwendigkeit $r$ und $d$ ineinander umzurechnen.\n\n**Fall 1: eine der Variablen in der Korrelation ist eine natürliche binäre Variable (z.B. männl./weibl.)**\n\nIn diesem Fall gilt:\n\n$$\nd=\\frac{2r}{\\sqrt{1-r^2}} \\qquad\\qquad \\hat{se}(d) = \\frac{2}{\\sqrt{(n-1)(1-r^2)}}\n$$\n\nwobei $\\hat{se}(d)$ der Standardfehler der Effektstärke $d$ ist, der zusätzlich angegeben werden sollte.\n\nUmgekehrt gilt:\n\n$$\nr = \\frac{d}{\\sqrt{d^2+4}}\n$$\n\n\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## [Umrechnung von Cohen's $d$ und Korrelationskoeffizient $r$]{color=\"darkred\"}\n\n![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=110px}\n\n**Fall 2: beide Variablen in der Korrelation sind kontinuierlich, oder eine Variable ist binär, aber enstand durch Dichotomisierung einer kontinuierlichen Variable (advanced!)**\n\nIn diesem Fall muss eine Variable als unabhängige Variable $X$ definiert werden. Falls eine der Variablen durch Dichotomisierung binär ist, ist diese Variable in jedem Fall die unabhängige Variable.\n\nEs gilt:\n\n:::{style=\"margin-top: -35px\"}\n$$\nd=\\frac{kr}{\\hat{\\sigma}_X\\sqrt{1-r^2}} \\qquad\\qquad \\hat{se}(d) = |d|\\sqrt{\\frac{1}{r^2(n-3)} + \\frac{1}{2(n-1)}}\n$$\n:::\n\nwobei $\\hat{se}(d)$ der Standardfehler der Effektstärke $d$ ist, der zusätzlich angegeben werden sollte.\n\n**Interpretation:** $d$ entspricht der durchschnittlichen Zunahme der standarsierten $Y$-Variable mit jeder Zunahme von $X$ um $k$ (Rohwert)Einheiten &mdash; $k$ muss vom Forscher gewählt werden. \n\nHier wird klar, dass die Formel in Fall 1 implizit $k=2\\hat{\\sigma}_X$ annnimmt. Wählt man dieses $k$ auch in Fall 2, ist die Berechnung von $d$ identisch zu Fall 1 &mdash; der Standardfehler unterscheidet sich allerdings weiterhin! Quelle: ^[Mathur MB, VanderWeele TJ (2020) A Simple, Interpretable Conversion from Pearson’s Correlation to Cohen’s d for Continuous Exposures. Epidemiology 31:e16–e18.]\n\nUmgekehrt gilt:\n\n:::{style=\"margin-top: -40px\"}\n$$\nr = \\frac{d \\hat{\\sigma}_X}{\\sqrt{d^2\\hat{\\sigma}_X^2+k^2}}\n$$\n:::\n\n# Weitere Effektmaße\n\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## [Effektstärken für Mittelwertunterschiede bei mehr als zwei Messungen]{style=\"font-size: 36px; color: darkred\"}\n\n![](images/kein_klausurstoff.png){.absolute top=60 right=0 height=100px}\n\n- Gibt es mehr als zwei Experimentalbedingungen oder Gruppen (A, B, C, ...), gibt es zwei Möglichkeiten:\n    1. Von Interesse sind die **paarweisen** Mittelwertunterschiede (z.B: $A-B$, $A-C$, $B-C$) &xrarr; in diesem Fall kann wie bisher Cohen's d für für jedes Paar angewendet werden.\n    2. Von Interesse ist, ob sich die Mittelwerte in den Gruppen A, B, C **in ihrer Gesamtheit betrachtet** unterscheiden, d.h. ob die Aufteilung in diese spezifischen Gruppen sinnvoll ist.\n\nFall 2 ist unser erster Kontakt mit der **Varianzanalyse**, die in Statistik 2 ausführlich behandelt wird. Man kann die Fragestellung in Fall 2 auch folgendermaßen formulieren: \n\n    Zu welchem Grad wird die Varianz der gepoolten Daten aller Gruppen bereits erklärt durch die Mittelwerte der Gruppen?\n\n- Auf Basis dieser Formulierung ist nicht mehr überraschend, dass die Effektstärke für Mittlwertunterschiede von mehreren Messungen als *Verhältnis zweier Streuungen* ausgedrückt werden kann:\n\n\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n$$\n\\eta^2 = \\frac{QS_\\text{Mittelwerte}}{QS_\\text{Gesamt}}\n$$\n:::\n::: {.column width=\"50%\"}\n![Die Quadratsumme entspricht dem Zähler in der Formel für die Varianz.](images/quadratsumme.png){height=80px}\n\n:::\n::::\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## [Effektstärken für Mittelwertunterschiede bei mehr als zwei Messungen]{style=\"font-size: 36px; color: darkred\"}\n\n![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=100px}\n\n![Courtesy of Prof. Thomas Schäfer, Medical School Berlin](images/effectsize_eta_squared.png){height=320px}\n\n- $\\eta^2$ (\"Eta Quadrat\") gibt an, wie viel der Gesamtvarianz durch die Varianz der Mittelwerte aufgeklärt wird.\n- Es kann zwischen 0 (Mittelwerte erklären keine Varianz) und 1 (Mittelwerte erklären die komplette Varianz) liegen.\n- Die Berechnung von $QS_\\text{Gesamt}$ umfasst 1) die Varianz zwischen den Bedingungen, 2) die Varianz zwischen zwischen Personen (über Bedingungen hinweg), und 3) wie sehr sich die Varianz der Bedingungen zwischen Personen unterscheidet:\n\n\n:::{style=\"margin-top: -15px\"}\n$$\nQS_\\text{Gesamt} = QS_\\text{Bedingungen} + QS_\\text{Personen} + QS_\\text{Personen x Bedingungen}\n$$\n:::\n\n\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## [Effektstärken für Mittelwertunterschiede bei mehr als zwei Messungen]{style=\"font-size: 36px; color: darkred\"}\n\n![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=100px}\n\n\n- Es kann argumentiert werden, dass die Varianz, die lediglich die interindividuellen Unterschiede der Versuchspersonen (Varianzanteil 2 bzw. $QS_\\text{Personen}$) charakterisiert, für die Effektstärke irrelevant ist und nicht zu $QS_\\text{Gesamt}$ gezählt werden sollte, d.h.:\n$$\nQS_\\text{Gesamt} = QS_\\text{Bedingungen} + QS_\\text{Personen x Bedingungen}\n$$\n- Wird die Varianz $QS_\\text{Personen}$ nicht berücksichtigt, spricht man vom [**partiellen**]{color=\"navy\"} $\\color{navy}{\\eta_p^2}$.\n\n- Eine ausführliche Diskussion zum Pro und Kontra von $\\eta^2$ vs. $\\eta_p^2$ findet sich z.B. im Buch von Eid, Gollwitzer und Schmitt im Kapitel zur Varianzanalyse.\n\n::: {.notabene}\n:::: {.columns}\n::: {.column width=\"7%\"}\n::: {style=\"margin-top: 10px\"}\n![](images/notabene2.png){height=\"65px\"}\n:::\n:::\n::: {.column width=\"93%\"}\nWarum werden bei der Berechnung von $\\eta^2$ die Quadratsummen und nicht die Varianzen direkt verwendet? Grund ist, dass die Varianz die *durchschnittliche* (quadrierte) Abweichung vom Mittelwert angibt (daher der Faktor $\\frac{1}{n}$), und beim Vergleich verschiedener Variabilitätskomponenten nicht festgestellt werden kann, wie viel der Datenvariabilität *absolut gesehen* durch eine Variabilitätskomponente erklärt wird.\n\n:::\n::::\n:::\n\n\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## Absolute Risikoreduktion (ARR)\n\nSind beide Variablen dichotom, sind weder der Korrelationskoeffizient noch Cohen's d intuitive Effektmaße. \n\n<!---  Example --->\n::: {.example}\n|||\n|:-:|-|\n| ![](images/example.png){height=70px} | Sie untersuchen, ob ein neues Medikament die Heilungsrate (Erfolgsrate) einer Krankheit verbessert. Die Treatmentgruppe erhält das Medikament, die Kontrollgruppe Placebo.\n: {tbl-colwidths=\"[10, 90]\"}\n:::\n\nEine sinnnvolles Effektmaß ist hier, *um wie viel* die Erfolgsrate in der Treatmentgruppe die Erfolgsrate in der Kontrollgruppe übersteigt. Dies lässt sich einfach aus einer Vierfeldertafel ableiten:\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n![](images/vierfeldertafel.png)\n:::\n::: {.column width=\"50%\"}\n![](images/arr.png)\n\n:::\n::::\n\n- $ARR$ ist die [**Absolute Risikoreduktion**]{color=\"navy\"}.\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## Numbers Needed to Treat (NNT)\n\n- Noch gängiger als die Absolute Risikoreduktion ist die inverse Größe, die als [**Numbers Needed to Treat (NNT)**]{color=\"navy\"} bezeichnet wird.\n\n::: {.definition}\n<!---  Definition--->\n|||\n|:-:|-|\n|||\n| ![](images/definition.svg){height=70px} | **Number Needed to Treat:** Anzahl der Personen, die behandelt werden müssten, damit eine zusätzliche Person einen Nutzen hat. | \n|||\n: {tbl-colwidths=\"[10, 90]\"}\n\n:::\n\nMathematisch ist $NNT$ das Inverse der $ARR$:\n\n$$\nNNT = \\frac{1}{ARR}\n$$\n\n- Da es um Personen geht, wird die NNT immer aufgerundet.\n\n<!---  Example --->\n::: {.example style=\"border-width: 0 !important\"}\n||||\n|:-:|-|-|\n||||\n| ![](images/example.png){height=60px} | ![](images/vierfeldertafel_numbers.png) | $ARR = \\frac{90}{90+10} - \\frac{35}{35+35}=0{,}9-0{,}5=0{,}4\\quad\\rightarrow\\quad NRR=\\frac{1}{0{,}4}=2{,}5$ \\\n&rArr; Drei weitere Personen müssten behandelt werden, damit eine zusätzliche Person einen Nutzen hat (d.h. die andernfalls nicht geheilt würde).|\n||||\n: {tbl-colwidths=\"[10, 30, 60]\"}\n\n:::\n\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## Numbers Needed to Treat (NNT)\n\n- Auch wenn das Ziel von $NNT$ eine einfache laienverständliche Kommunikation der Treatmenteffizienz ist, darf angezweifelt werden, ob dies immer der Fall ist, wie durch folgendes Beispiel demonstriert^[Andrade C (2015) The Numbers Needed to Treat and Harm (NNT, NNH) Statistics: What They Tell Us and What They Do Not: (Practical Psychopharmacology). J Clin Psychiatry 76:e330–e333.\n]:\n\n![](images/quote_NNT.png)\n\n\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## Odds Ratio (OR)\n\n- Das [**Odds Ratio**]{color=\"navy\"} ($OR$) vergleicht das *Heilerfolgsverhältnis in der Treatmentgruppe* zum *Heilerfolgsverhältnis in der Kontrollgruppe*:\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n![](images/vierfeldertafel.png)\n\n:::\n::: {.column width=\"50%\"}\n$$\n\\text{OR} = \\frac{\\frac{A}{B}}{\\frac{C}{D}} = \\frac{A\\cdot C}{B\\cdot D}\n$$\n\n[Beachte: Als Heilerfolgsverhältnis wird hier das Verhältnis der Zahl der geheilten Patienten gegenüber der Zahl der nicht geheilten Patienten verstanden.]{style=\"font-size: 20px; line-height: 1.05 !important; display: block; margin-top: 40px; color:#777\"}\n\n:::\n::::\n\n- Hat das Treatment keine Auswirkung, so sind die Heilerfolgsverhältnisse in beiden Gruppen gleich, d.h. $OR=1$.\n- Ist das Treatment erfolgreich, ist das Heilerfolgsverhältnis in der Treatmentgruppen höher als in der Kontrollgruppe, d.h. $OR>1$.\n- Ist das Treatment sogar nachteilig, ist das Heilerfolgsverhältnis in der Treatmentgruppen *kleiner* als in der Kontrollgruppe, d.h. $OR<1$.\n\n::: {.notabene}\n:::: {.columns}\n::: {.column width=\"7%\"}\n::: {style=\"margin-top: 10px\"}\n![](images/notabene2.png){height=\"65px\"}\n\n:::\n:::\n::: {.column width=\"93%\"}\nAls kleine Übung kann man das Odds Ratio für die beiden hypothetischen Beispiele auf der vorherigen Folie berechnen. Spoiler: das Odds Ratio ist für beide Fälle gleich ($OR=13.5$)!\n\n:::\n::::\n:::\n\n## Übersicht Effektmaße\n\n<div class=\"vspace-medium\"></div>\n\n![](images/overview_effectsizes.png){height=600px}\n\n\n<!----------------->\n<!--- New slide --->\n<!----------------->\n## [Referenz]{color=\"darkred\"}\n\n![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=110px}\n\nEmpfehlungen nach Lakens (2013)^[Lakens D (2013) Calculating and reporting effect sizes to facilitate cumulative science: a practical primer for t-tests and ANOVAs. Frontiers in Psychology 4 Available at: https://www.frontiersin.org/articles/10.3389/fpsyg.2013.00863]:\n\n![](images/effectsizes_recommendation_lakens2013.png)\n\n\n\n\n\n<!-- ```{python}\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport os\nimport seaborn as sns\n\nnp.random.seed(0)\nroot = '/home/matteo/OneDrive/lehre/Statistik/stats1_lecture/book/'\n\nfontsize = 15\ncolor = 'k'\n\nN = 50\n\ndf = pd.read_csv(os.path.join(root, 'data', 'paradoxia.csv'))\n# print(df.head())\n\ndata_tiktok_control = df[df.group == 1]['hours_tiktok_per_day'].values\ndata_tiktok_paradoxia = df[df.group == 2]['hours_tiktok_per_day'].values\ndata_inflam_control = df[df.group == 1]['inflammation'].values\ndata_inflam_paradoxia = df[df.group == 2]['inflammation'].values\n\nd_tiktok = (np.mean(data_tiktok_paradoxia) - np.mean(data_tiktok_control)) / np.sqrt((np.var(data_tiktok_paradoxia)+np.var(data_tiktok_control))/(2*(1-1/N)))\nd_inflam = (np.mean(data_inflam_paradoxia) - np.mean(data_inflam_control)) / np.sqrt((np.var(data_inflam_paradoxia)+np.var(data_inflam_control))/(2*(1-1/N)))\n\n# Formula from https://stats.stackexchange.com/questions/495015/what-is-the-formula-for-the-standard-error-of-cohens-d\nd_se_tiktok = (8+d_tiktok**2)/(4*N)\nd_se_inflam = (8+d_inflam**2)/(4*N)\n\nplt.style.use('dark_background')\nplt.figure(figsize=(3, 2.5))\nplt.gca().set_facecolor('#eee')\nplt.errorbar([0], [d_tiktok], yerr=[d_se_tiktok], fmt='o', markersize=4, capsize=10, capthick=2, elinewidth=2, ecolor=color, mfc=color, mec=color, zorder=3)\nplt.errorbar([1], [d_inflam], yerr=[d_se_inflam], fmt='o', markersize=4, capsize=10, capthick=2, elinewidth=2, ecolor=color, mfc=color, mec=color, zorder=3)\nplt.text(0, 0.07, r'$d=' + f'{d_tiktok:.2f}'.replace('.', '{,}') + '$', ha='center', color='k', fontsize=fontsize-2)\nplt.text(1, 0.07, r'$d=' + f'{d_inflam:.2f}'.replace('.', '{,}') + '$', ha='center', color='k', fontsize=fontsize-2)\n\nplt.xticks([0, 1], ['TikTok', 'Entzündung'], fontsize=fontsize)\nplt.yticks(fontsize=fontsize-2)\nplt.ylabel(\"Cohen's $d$\", fontsize=fontsize)\nplt.xlabel('')\nplt.xlim(-0.5, 1.5)\nplt.ylim(0, 1.6)\nplt.grid(True, color='#e2e2e2')\n\n\nplt.savefig('images/paradoxia_cohensd.png', bbox_inches='tight')\n\n``` -->\n\n## {.blackslide .center}\n\n<div class=\"vspace-medium\"></div>\n\n:::: {.columns}\n::: {.column width=\"65%\"}\nSie berechnen nun Cohen's d für die beiden Gruppenunterschiede hinsichtlich der TikTok-Zeit und Entzündungswerte:\n:::\n::: {.column width=\"35%\"}\n::: {.content-hidden when-format=\"pdf\"}\n![](images/paradoxia_group_of_scientists.png){.hcenter-image height=200px style=\"margin-top:-100px !important\"}\n<!-- Source: Midjourney -->\n\n:::\n:::\n::::\n\n:::: {.columns}\n::: {.column width=\"70%\"}\n<div class=\"vspace-large\"></div>\n![](images/paradoxia_cohensd.png){height=300px}\n:::\n::: {.column width=\"30%\"}\n::: {.caption-style style=\"margin-top:250px !important; margin-left:-180px\"}\nHinweis: in der Abbildung wurde nicht nur die Effektstärke selbst aufgetragen, sondern auch ein Streuungsmaß der Effektstärke (Standardfehler der Effektstärke). Dazu kommen wir in Vorlesung 08.\n:::\n:::\n::::\n\nLangsam schärft sich das Bild: während die Entzündungswerte höchstens eine mittlere Effektstärke aufweisen ($d=0{,}33$), ist der TikTok-Effekt beeindruckend groß: $\\;d=0{,}93$.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}