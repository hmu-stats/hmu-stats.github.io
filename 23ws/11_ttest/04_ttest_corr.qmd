


# t-Tests für Zusammenhänge


<!----------------->
<!--- New slide --->
<!----------------->
## Stichprobenverteilung der Korrelation

:::: {.columns}
::: {.column width="60%"}

:::{.nonincremental}
- Analog zu Mittelwertsunterschieden kann auch die **Stichprobenverteilung der Korrelation** aufgestellt werden: als **Normalverteilung** mit dem **Mittelwert unserer Kennwertschätzung (hier $r$)** und einer Streuung, die dem **Standardfehler** ($\hat{se}$) des Kennwertes entspricht.
:::

:::{style="margin-top: -15px"}
- Den Standardfehler der Korrelation haben wir bereits in Vorlesung 08 kennengelernt:
:::

:::{.fragment style="margin-top: -15px"}
$$
\hat{se}(r) = \sqrt{\frac{1-r^2}{n-2}}
$$
:::

:::
::: {.column width="40%"}
![](images/nulldist_r.png)
:::
::::

:::{.fragment}
:::{.nonincremental}
- Auch dieser Standardfehler ist eine Schätzung auf Basis der Stichprobe und entsprechend stellt die standardisierte Prüfgröße einen t-Wert dar:
:::

:::{style="margin-top: -15px"}
$$
t = \frac{r}{\hat{se}(r)} = r\sqrt{\frac{n-2}{1-r^2}}
$$
:::
:::

:::{.fragment}
[(Präziser gesagt handelt es sich auch hier wieder um das Verhältnis einer normalverteilten Variable ($r$) und einer chi-verteilten Variable ($\hat{se}(r)$) &mdash; ein solches Verhältnis führt zu einer t-verteilten Prüfgröße)]{style="font-size: 23px"}
:::




<!----------------->
<!--- New slide --->
<!----------------->
## Nullhypothese und Hypothesentestung bei Korrelationen

:::: {.columns}
::: {.column width="60%"}

:::{.nonincremental}
- Die **Nullhypothesenverteilung** der Korrelation ist also eine **t-Verteilung**.
- Die Nullhypothese entspricht der Annahme, dass der wahre Zusammenhang in der Population $\rho = 0$ ist.
:::

:::{style="margin-top: -15px"}
- Auch hier können wir gerichtete und ungerichtete Hypothesen testen:
    - Gerichtete Hypothesen: 
        - die Korrelation ist größer 0 ($\rho>0$)
        - die Korrelation ist kleiner 0 ($\rho<0$)
    - Ungerichtete Hypothese: die Korrelation ist ungleich 0 ($\rho\neq 0$)
:::
:::
::: {.column width="40%"}

![](images/ttest1_r.png)

:::
::::

- Die Berechnung der p-Werte erfolgt analog wie bei Mittelwertunterschieden.

::: {.merke .fragment}
:::: {.columns}
::: {.column width="5%"}
::: {style="margin-top: 18px"}
![](images/merke.png){height="55px"}
:::
:::
::: {.column width="95%"}
Die Zahl der Freiheitsgrade der Korrelation ist $\text{df}=n-2$. Grund: die Streuung $\hat{se}$ im Nenner des t-Wertes enthält den Korrelationskoeffizient $r$ und dieser involviert die Berechnung von **zwei** Mittelwerten (Mittelwert $\bar{x}$ der Variable $X$ und Mittelwert $\bar{y}$ der Variable $Y$).
:::
::::
:::



<!----------------->
<!--- New slide --->
<!----------------->
## Beispiel: Bestimmung des p-Wertes bei der Korrelation

:::{.nonincremental}
- Nehmen wir an, die Korrelation von Größe und Gewicht in einer Stichprobe von $n=12$ betrage $r=0{,}4$.
:::
:::{style="margin-top: -15px"}
- Wir wollen testen, ob die Korrelation auf einem Signifikanzniveau $\alpha=0{,}05$ signifikant größer als 0 ist.
:::

:::: {.columns}
::: {.column width="55%"}

- Berechnung von der Prüfgröße $t$:

:::{.fragment}
$$
t = r\sqrt{\frac{n-2}{1-r^2}} = 0{,}4\sqrt{\frac{12-2}{1-0{,}4^2}} \overset{(Computer)}{=} 1{,}38
$$
:::

- Wir sehen in der Tabelle, dass der kritische t-Wert für $\text{df}=n-2=10$ Freiheitsgrade bei einem (einseitigen!) Signifikanzniveau von $\alpha=0{,}05$ gleich $1{,}813$ beträgt.
- Die Nullhypothese wird also nicht abgelehnt, und der Effekt als nicht signifikant gewertet.

:::
::: {.column width="45%"}
:::{.fragment}
![](images/ttable_r.png)
:::
:::
::::

<!----------------->
<!--- New slide --->
<!----------------->
## Beispiel: Bestimmung des p-Wertes bei der Korrelation

:::: {.columns}
::: {.column width="61%"}
:::{.nonincremental}
- Statistische Programme geben den p-Wert in der Regel automatisch mit an und es ist somit ersichtlich,  ob es sich um eine statistisch signifikante Korrelation handelt.
:::
:::{style="margin-top: -15px"}
- **Standardmäßig** handelt es sich dabei immer um einen **Test für eine ungerichtete Hypothese**. 
- War die Hypothese dagegen gerichtet, gilt:
    - Halbiere den p-Wert der ungerichteten Hypothese, falls das Vorzeichen von $r$ in Richtung der Hypothese ist.
    - Verdoppele den p-Wert der ungerichteten Hypothese, falls das Vorzeichen von $r$ in gegensätzlicher Richtung der Hypothese ist.
    - Im Beispiel wäre also der Korrelationskoeffizient $2\times 0{,}198=0{,}396$, falls wir einen negativen Zusammenhang vorhergesagt hätten, und $0{,}198/2=0{,}099$, falls wir einen positiven Zusammenhang vorhergesagt hätten.
:::
:::
::: {.column width="39%"}

<div class="vspace-medium"></div>

![Auswahl in JASP: Regression &rarr; Klassisch &rarr; Korrelation. Zusätzliche Selektion des Streudiagramms.](images/jasp_weight_height.png){width=375px}
:::
::::
