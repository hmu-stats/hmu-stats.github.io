# t-Test für Mittelwertdifferenzen



<!----------------->
<!--- New slide --->
<!----------------->
## t-Test für Mittelwertdifferenzen

- Zur Erinnerung, bei einem statistischen Test zu Mittelwertdifferenzen stellen wir folgende Fragen: 
    - Unterscheiden sich die Mittelwerte von zwei unabhängigen Stichproben signifikant voneinander? (Zweistichproben-Test)
    - Unterscheiden sich die Mittelwerte von zwei abhängigen Bedingungen signifikant voneinander? (Einstichproben-Test mit zwei abhängigen Messungen)
    - Unterscheidet sich ein Mittelwert signifikant von einem fixen Referenzwert? (Einstichproben-Test mit Einzelmessung)
- Beispiel Paradoxia:

:::{.fragment style="margin-top: 15px"}
![](images/mittelwertdifferenz_paradoxia.png){height=300px}
:::

<!----------------->
<!--- New slide --->
<!----------------->
## t-Test für Mittelwertdifferenzen

:::{.nonincremental}
- Um den t-Wert für eine Mittelwertdifferenz $\Delta\bar{x}$ zu erhalten, ersetzen wir $\hat{\theta}$ durch $\Delta\bar{x}$:
:::

$$
\text{t-Wert für Mittelwertdifferenz:}\qquad t = \frac{\hat{\theta}}{\hat{se}} = \frac{\Delta\bar{x}}{\hat{se}}
$$

- Die Mittelwertdifferenz $\Delta\bar{x}$ ist einfach zu bestimmen, die zentrale Frage lautet daher: **wie berechnet sich der Standardfehler $\hat{se}$ einer Mittelwertdifferenz $\Delta\bar{x}$?**
- **Merke:** der Standardfehler im Nenner des t-Wertes bezieht sich immer auf die Prüfgröße $\hat{\theta}$. Die Frage lautet also bei jedem t-Test: was ist der Standardfehler von $\hat{\theta}$ bzw. was ist die Standardabweichung der Stichprobenverteilung von $\hat{\theta}$?
- Wie beim z-Test hängt die Berechnung des Standardfehlers von Mittelwertdifferenzen von verschiedenen Faktoren ab.



<!----------------->
<!--- New slide --->
<!----------------->
## [Standardfehler bei Mittelwertdifferenzen ($\sigma$ unbekannt)]{style="font-size:40px"}

<div class="vspace-small"></div>
![](images/stichprobenverteilung_diff.png)


<!----------------->
<!--- New slide --->
<!----------------->
## [Standardfehler bei Mittelwertdifferenzen ($\sigma$ unbekannt): Cheat sheet]{style="font-size:38px"}

Das folgende Cheat sheet gibt Ihnen eine Übersicht über die Berechnung des Standardfehlers $\hat{se}$ von Mittelwertdifferenzen im Nenner der Prüfgröße $t=\frac{\Delta\bar{x}}{\hat{se}}$:

<!---  Table --->
|Fall|Berechnung des Standardfehlers $\hat{se}$|
|-|-|
| **Differenz des Mittelwertes [einer Stichprobe]{.underline} und einem Referenzwert** $\mu_0$<br>(&rarr; Einstichproben-t-Test) | $\hat{se}=\frac{\hat{\sigma}}{\sqrt{n}}$ |
| **Mittelwertdifferenz unabhängiger Messungen in [zwei Stichproben A und B]{.underline} (ähnliche Varianzen)**<br>(&rarr; Klassischer Zweistichproben-t-Test) | $\hat{se} = \hat{\sigma}_\text{pooled}\sqrt{\frac{1}{n_A}+\frac{1}{n_B}}$ \
$\text{mit}\quad \hat{\sigma}_\text{pooled}=\sqrt{\frac{(n_A-1)\hat{\sigma}^2_A + (n_B-1)\hat{\sigma}^2_B}{n_A+n_B-2}}$ |
| **Mittelwertdifferenz unabhängiger Messungen in [zwei Stichproben A und B]{.underline} (unterschiedliche Varianzen)**<br>(&rarr; Welch's Zweistichproben-t-Test) | $\hat{se}= \sqrt{\frac{\hat{\sigma}_A^2}{n_A} + \frac{\hat{\sigma}_B^2}{n_B}}$ |c
| **Mittelwertdifferenz abhängiger Messungen A und B in [einer Stichprobe]{.underline}**<br>(&rarr; Differenzen-t-Test) |$\hat{se} = \frac{\hat{\sigma}_\Delta}{\sqrt{n}}\qquad\text{mit}$ \
$\hat{\sigma}_\Delta=\sqrt{\hat{\sigma}_A^2+\hat{\sigma}_B^2-2\,\hat{Cov}(X_A,X_B)}$ \
$\text{oder}\qquad\hat{\sigma}_\Delta=\sqrt{\frac{1}{n-1}\left(\Delta x_i-\Delta\bar{x}\right)^2}$ |

: {tbl-colwidths="[50, 40]"}


<div class="vspace-small"></div>

::: {.merke style="font-size: 23px !important"}
:::: {.columns}
::: {.column width="5%"}
::: {style="margin-top: 10px"}
![](images/merke.png){height="55px"}
:::
:::
::: {.column width="95%"}
Dieses Cheat Sheet gilt für den Fall, dass die Populationsvarianzen $\sigma^2_A$ bzw. $\sigma^2_B$ **nicht bekannt** sind. In diesem Sinne ist es das in der Praxis relevante Cheat Sheet, da die Populationsvarianzen nahezu nie bekannt sind.
:::
::::
:::


<!----------------->
<!--- New slide --->
<!----------------->
## [Einschub: gepoolter Standardfehler]{color="darkred"}

![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=110px}

:::{style="margin-top: -10px"}
- Im Cheat sheet auf der vorherigen Folie ist folgender Standardfehler für den Fall unabhängiger Messungen und ähnlicher Varianzen angegeben:
:::

:::{style="margin-top: -30px"}
:::{.fragment}
$$
\hat{se} = \hat{\sigma}_\text{pooled}\sqrt{\frac{1}{n_A}+\frac{1}{n_B}}
$$
:::
:::

:::{style="margin-top: -15px"}
- Zur Herleitung starten wir wieder mit der allgemeinen Varianzsummenformel: wir wissen, dass sich die Varianzen der beiden Stichprobenmittelwerte (=quadrierte Standardfehler $\hat{se}_A^2$ und $\hat{se}_B^2$) aufaddieren:
:::

:::{style="margin-top: -54px"}
:::{.fragment}
$$
\hat{se}^2 = \hat{se}_A^2 + \hat{se}_B^2\quad\rightarrow\quad \hat{se} = \sqrt{\hat{se}_A^2 + \hat{se}_B^2} = \sqrt{\frac{\hat{\sigma}_A^2}{n_A} + \frac{\hat{\sigma}_B^2}{n_B}}
$$
:::
:::

:::{style="margin-top: -15px"}
- Können die Varianzen $\hat{\sigma}_A^2$ und $\hat{\sigma}_B^2$ als ähnlich angenommen werden, gilt folgende Überlegung: statt beide Varianzen einzeln zu schätzen, wird eine einheitliche **gepoolte Varianz** $\hat{\sigma}_\text{pooled}$ auf Basis beider Stichproben geschätzt (vgl. Vorlesung 07).
  - Vorteil: diese Varianz kann präziser geschätzt werden als die Einzelvarianzen, da die kombinierte Stichprobenzahl $n_A+n_B$ zugrundegelegt wird.
- Wir ersetzen also $\hat{\sigma}_A^2$ und $\hat{\sigma}_B^2$ jeweils durch $\hat{\sigma}_\text{pooled}^2$:
:::

:::{style="margin-top: -20px"}
:::{.fragment}
$$
\hat{se} = \sqrt{\frac{\hat{\sigma}_\text{pooled}^2}{n_A} + \frac{\hat{\sigma}_\text{pooled}^2}{n_B}} = \hat{\sigma}_\text{pooled}\sqrt{\frac{1}{n_A}+\frac{1}{n_B}}\qquad\text{q.e.d.}
$$
:::
:::



<!----------------->
<!--- New slide --->
<!----------------->
## Zahl der Freiheitsgrade für t-Tests von Mittelwertdifferenzen

<div class="vspace-medium"></div>

<!---  Table --->
|Test|Frage|Zahl der Freiheitsgrade|
|-|-|-|
| **Einstichprobentest mit Einzelmessung** | Ist $\bar{x}$ größer als ein Referenzwert $\mu_0$? | $\text{df} = n - 1$, da für die Berechnung von $t$ genau ein Zwischenparameter bestimmt werden muss (der Mittelwert $\bar{x}$) |
| **Einstichprobentest mit zwei abhängigen Messungen** | Unterscheiden sich die Mittelwerte $\bar{x}_A$ und $\bar{x}_B$ zwischen zwei Bedingungen A und B? In diesem Fall kann man auch fragen: ist der Mittelwert der Differenzvariable ($\Delta\bar{x}=\overline{X_A-X_B}$) verschieden von Null? | $\text{df} = n - 1$, da für die Berechnung von $t$ genau ein Zwischenparameter bestimmt werden muss (der Mittelwert $\overline{X_A-X_B}$)|
| **Zweistichprobentest (ähnliche Varianzen)** | Unterscheiden sich die Mittelwerte $\bar{x}_A$ und $\bar{x}_B$ zwischen zwei Gruppen A und B? ($\Delta\bar{x}=\bar{x}_A-\bar{x}_B$) |$\text{df} = n_A + n_B - 2$, da für die Berechnung von $t$ genau zwei Zwischenparameter bestimmt werden müssen (die Mittelwerte $\bar{x}_A$ und $\bar{x}_B$)|
| **Zweistichprobentest (unterschiedliche Varianzen, aka Welch's t-Test)** | Unterscheiden sich die Mittelwerte $\bar{x}_A$ und $\bar{x}_B$ zwischen zwei Gruppen A und B? ($\Delta\bar{x}=\bar{x}_A-\bar{x}_B$) | **Welch–Satterthwaite-Gleichung:** \
$\text{df} = \frac{\left(\frac{\hat{\sigma}_A^2}{n_A}+\frac{\hat{\sigma}_B^2}{n_B}\right)^2}{\frac{\left(\hat{\sigma}_A^2/n_A\right)^2}{n_A-1}+\frac{\left(\hat{\sigma}_B^2/n_B\right)^2}{n_B-1}}$ \
Falls $n_A=n_B=n$: $\text{df}=(n-1)\Big(1+\frac{2}{\left(\frac{\hat{\sigma}_A}{\hat{\sigma}_B}\right)^2+\left(\frac{\hat{\sigma}_B}{\hat{\sigma}_A}\right)^2}\Big)$ |

: {tbl-colwidths="[23, 35, 42]"}


<!----------------->
<!--- New slide --->
<!----------------->
## [Intuition zur Welch–Satterthwaite-Gleichung]{color="darkred"}

![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=110px}

Auch wenn die Welch–Satterthwaite-Gleichung für die Freiheitsgrade beim Zweistichproben-t-Test mit unterschiedlicher Varianz recht kompliziert aussieht, ist eine nähere Betrachtung aufschlussreich.

Für $n_A=n_B=n$ gilt:

$$
\text{df}=(n-1)\Big(1+\frac{2}{\left(\frac{\hat{\sigma}_A}{\hat{\sigma}_B}\right)^2+\left(\frac{\hat{\sigma}_B}{\hat{\sigma}_A}\right)^2}\Big)
$$

Zwei Fälle sind interessant:

<div class="vspace-small"></div>

[Fall 1: Sind die Varianzen gleich]{.underline} (entgegen der Annahme), d.h. $\hat{\sigma}_A=\hat{\sigma}_B$, so vereinfacht sich die Formel zu

$$
\text{df} = (n-1)(1+\frac{2}{2}) = 2n -2,
$$

**also exakt die Formel des klassichen Zweistichprobentests.**


<!----------------->
<!--- New slide --->
<!----------------->
## [Intuition zur Welch–Satterthwaite-Gleichung]{color="darkred"}

![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=110px}

[Fall 2: Sind die Varianzen extrem unterschiedlich]{.underline}, so wird entweder $\left(\frac{\hat{\sigma}_A}{\hat{\sigma}_B}\right)^2$ oder $\left(\frac{\hat{\sigma}_B}{\hat{\sigma}_A}\right)^2$ extrem groß und die Formel vereinfacht sich zu

$$
\text{df} = (n-1)(1+\frac{2}{\infty}) = (n-1)(1+0) = n-1
$$

**also exakt die Formel des Einstichprobentests.**

Für extrem ungleiche Varianzen reduzieren sich also die Freiheitsgrade &mdash; und damit die *effektive Stichprobengröße* &mdash; auf die Größe einer der beiden verglichenen Gruppen. 

Das ist durchaus intuitiv: ist z.B. $\hat{\sigma}_A$ extrem viel kleiner als $\hat{\sigma}_B$, so spielt die Varianz der Gruppe A nahezu keine Rolle mehr. Die Versuchspersonen dieser Gruppe gehen also für die Berechnung des Standardfehlers "verloren", was sich entsprechend auf die Freiheitsgrade auswirkt.

*Im Grenzfall* spielt die Varianz dieser Gruppe überhaupt keine Rolle mehr, sondern nur noch ihr Mittelwert. Die Gruppe hat damit die gleiche Funktion wie der Referenzwert $\mu_0$ beim Einstichproben-t-Test.



<!----------------->
<!--- New slide --->
<!----------------->
## Beispiel: t-Test für unabhängige Gruppen

:::: {.columns}
::: {.column width="80%"}

Betrachten wir das Beispiel Med- versus Psych-Nasen für den Fall, dass wir die Standardabweichungen $\sigma_\text{med}$ und $\sigma_\text{psych}$ von Nasenlängen in der Med- und Psych-Population nicht kennen.

Es gilt immer noch:

$$
\Delta \bar{x} = \bar{x}_\text{med} - \bar{x}_\text{psych} = 0{,}2cm
$$

:::{.fragment}
.. aber $\sigma_\text{med}$ und $\sigma_\text{psych}$ müssen jetzt aus unseren Messwerten geschätzt werden. Für das Beispiel nehmen wir an:

$$
\hat{\sigma}_\text{med} = 0{,}5\qquad\qquad\hat{\sigma}_\text{psych} = 0{,}25
$$
:::

:::{.fragment}
Wir schlagen die Formel für den Standardfehler bei unabhängigen Messungen und ungleichen Varianzen nach und setzen ein:

$$
\hat{se}= \sqrt{\frac{\hat{\sigma}_\text{med}^2}{n_\text{med}} + \frac{\hat{\sigma}_\text{psych}^2}{n_\text{psych}}} \overset{(Computer)}{=}  0{,}102
$$

Erinnerung: es galt $n_\text{med}=n_\text{psych}=30$.
:::

:::
::: {.column width="20%"}
![](images/psych_med.png)
:::
::::


<!----------------->
<!--- New slide --->
<!----------------->
## Beispiel: t-Test für unabhängige Gruppen

:::: {.columns}
::: {.column width="60%"}

Mit dem Standardfehler bewaffnet, können wir nun den t-Wert berechnen:

:::{style="margin-top: -37px; margin-left: 30px"}
$$
t = \frac{\Delta \bar{x}}{\hat{se}} = 1{,}96
$$
:::

:::{.fragment}
Es fehlen noch die Freiheitsgrade. Bei ungleichen Varianzen ist die Formel recht sperrig:

:::{style="margin-top: -10px"}
$$
\begin{aligned}
\text{df}&=(n-1)\Big(1+\frac{2}{\left(\frac{\hat{\sigma}_\text{med}}{\hat{\sigma}_\text{psych}}\right)^2+\left(\frac{\hat{\sigma}_\text{psych}}{\hat{\sigma}_\text{med}}\right)^2}\Big) = \\
&=(30-1)\Big(1+\frac{2}{\left(\frac{0{,}5}{0{,}25}\right)^2+\left(\frac{0{,}25}{0{,}5}\right)^2}\Big) = 42{,}6
\end{aligned}
$$
:::

:::

:::
::: {.column width="40%"}
![](images/ttest1_example.png)
:::
::::

:::{.fragment}
:::{style="margin-top: -12px"}
Aufgrund der gerichteten (positiven) Hypothese ist der p-Wert die Fläche *rechts des t-Wertes* unter der t-Verteilung:
:::

:::{style="margin-top: -35px; margin-left: 120px"}
$$
p=\int_{t}^{\infty}f_t(x|\scriptsize\text{df}\normalsize)dx = \int_{1{,}96}^{\infty}f_t(x|42{,}6)dx = 1-F_t(1{,}96|42{,}6) \overset{(Computer)}{=} 0{,}028
$$
:::
:::

:::{.fragment}
Der p-Wert ist dem p-Wert des z-Tests ($0{,}023$) sehr ähnlich. Dies ist wenig überraschend, da a) der Standardfehler einen ähnlichen Wert aufwies ($se=2$ beim z-Test) und b) die Zahl er Freiheitsgrade so hoch ist, dass der Unterschied Normalverteilung vs. t-Verteilung marginal ist.
:::


<!----------------->
<!--- New slide --->
<!----------------->
## t-Test für unabhängige Stichproben

**Klassischer Zweistichproben-t-Test (ähnliche Varianzen) versus Welch's t-Test (unterschiedliche Varianzen) &mdash; welcher der beiden Tests sollte nun verwendet werden?**

:::{.nonincremental}
- In der Psychologie sind ungleiche Varianzen die realistischere Annahme. Selbst bei randomisiert-kontrollierten Studien, bei denen Versuchspersonen den Gruppen aus einer identischen Ursprungs-Population zugewiesen werden, kann das Treatment selbst einen Einfluss auf die Varianz haben.
- Neben der Faustformel $0{,}5<\frac{\hat{\sigma}_A}{\hat{\sigma}_B}<2$ gibt es auch Testverfahren zur Überprüfung der Varianzgleichheit zwischen Gruppen, allerdings sind diese nicht unproblematisch
    - Ein Grund:auf Varianzgleichheit wird idR auf Basis eines nicht-signifikanten Ergebnis in einem solchen Test angenommen &mdash; "absence of evidence is not evidence of absence"^[Altman DG, Bland JM (1995) Absence of evidence is not evidence of absence. BMJ 311:485.]
:::


:::{style="margin-top: -15px"}
:::: {.columns}
::: {.column width="66%"}
:::{.nonincremental}
- Herrscht Varianzgleichheit vor und ist die Stichprobengröße nicht extrem klein in einer Gruppe, kommen der Student'sche t-Test und Welch's t-Test zu sehr ähnlichen Ergebnissen.
- Vor diesem Hintergrund wird empfohlen^[Delacre M, Lakens D, Leys C (2017) Why Psychologists Should by Default Use Welch’s t-test Instead of Student’s t-test. International Review of Social Psychology 30:92.], bereits ab moderaten Gruppengrößen (ca. $n\ge 8$ pro Gruppe) *immer* Welch's t-Test anzuwenden. In den meisten Statistikprogrammen ist dieser Test implementiert.
:::
:::
::: {.column width="34%"}


![Option für Welch's t-test in JASP.](images/welch_jasp.png){height=270px style="margin-top:-20px"}

:::
::::
:::


<!----------------->
<!--- New slide --->
<!----------------->
## Beispiel: t-Test für abhängige Messungen

:::: {.columns}
::: {.column width="80%"}
Sie führen ein Experiment *innerhalb der Med-Gruppe* (n=32) durch. In einer experimentellen Intervention stellen Sie den Med-Studierenden die Frage 

> Studieren Sie Medizin, weil es der Wunsch Ihrer Eltern ist? 

Sie messen die Nasenlängen dabei sowohl vor ("pre"), als auch nach ("post") der Intervention. Ihre [ungerichtete]{.underline} Hypothese ist, dass sich die Nasenlängen vor und nach der Intervention auf einem Signifikanzniveau $\alpha=0{,}05$ unterscheiden.
:::
::: {.column width="20%"}
![](images/med.png)
:::
::::

:::{.fragment}
Die Mittelwertdifferenz betrage $\Delta\bar{x} = \bar{x}_\text{post} - \bar{x}_\text{pre} = 0{,}1cm$.
:::

<div class="vspace-small"></div>


:::{.fragment}
Wir nehmen der Einfachheit halber an, dass die beiden Messungen $X_\text{pre}$ und $X_\text{post}$ unkorreliert sind, d.h. $\hat{Cov}(X_\text{pre}, X_\text{post})=0$. Die Standardabweichungen seien $\hat{\sigma}_\text{pre}=\hat{\sigma}_\text{post}=0{,}5$. Die Standardabweichung $\hat{\sigma}_\Delta$ der Differenzvariable $\Delta X$ ist damit:
:::

:::{.fragment}
$$
\hat{\sigma}_\Delta=\sqrt{\hat{\sigma}_\text{pre}^2+\hat{\sigma}_\text{post}^2-2\,\hat{Cov}(X_\text{pre}, X_\text{post})} = \sqrt{(0{,5})^2+(0{,5})^2-2\cdot 0} = \frac{1}{\sqrt{2}}
$$
:::

:::{.fragment}
$$
\text{Standardfehler:}\qquad \hat{se}=\frac{\hat{\sigma}_\Delta}{\sqrt{n}} = \frac{1}{\sqrt{2}\sqrt{32}}=\frac{1}{8}
$$

:::

<!----------------->
<!--- New slide --->
<!----------------->
## Beispiel: t-Test für abhängige Messungen

:::: {.columns}
::: {.column width="60%"}

Nun können wir den t-Wert berechnen:

$$
t = \frac{\Delta\bar{x}}{\hat{se}} = \frac{0{,}1}{1/8} = 0{,}8
$$

:::{.fragment}
Aufgrund der ungerichteten Hypothese ist der p-Wert die Summe der Flächen unter der t-Verteilung links von $t=-0{,}8$ [und]{.underline} rechts von $t=+0{,}8$. Bei $\text{df}=n-1=31$ Freiheitsgraden gilt:
:::
:::
::: {.column width="40%"}
![](images/ttest1_example2.png)
:::
::::


:::{.fragment}
$$
\begin{aligned}
p&=\int_{-\infty}^{-t}f_t(x|\scriptsize\text{df}\normalsize)dx + \int_{t}^{\infty}f_t(x|\scriptsize\text{df}\normalsize)dx \overset{(Symmetrie)}{=} 2\cdot\int_{-\infty}^{-t}f_t(x|\scriptsize\text{df}\normalsize)dx  = \\
&= 2\cdot F_t(-t|\scriptsize\text{df}\normalsize) \overset{(einsetzen)}{=} 2\cdot F_t(-0{,}8|31) \overset{(Computer)}{=} 0{,}43
\end{aligned}
$$
:::

:::{.fragment}
Der p-Wert ist also deutlich größer als unser Signifikanzniveau $\alpha=0{,}05$ und wir können die Nullhypothese $\Delta\bar{x}=0$ nicht ablehnen. More research is needed!
:::
