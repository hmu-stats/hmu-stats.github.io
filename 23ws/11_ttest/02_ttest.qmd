# Durchführung eines t-Testes

<!----------------->
<!--- New slide --->
<!----------------->
## t-Test

Zur Durchführung des t-Tests müssen wir uns über folgende Faktoren Gedanken machen:

:::{.fragment}
**0. Sind die Voraussetzungen für einen t-Test gegeben?**

Jeder statistische Test basiert auf bestimmten Annahmen. Der Test sollte daher nur dann angewendet werden, wenn diese Annahmen erfüllt sind (oder sich eine Verletzung der Annahme in der Praxis als wenig problematisch herausgestellt hat).
:::

:::{.fragment}
**1. Welche Art von t-Test benötige ich?**

Für verschiedene Szenarien gibt es unterschiedliche t-Tests, die sich unterscheiden in a) dem verwendeten Standardfehler und b) der Zahl der Freiheitsgrade $\text{df}$.
:::

:::{.fragment}
**2. Zahl der Freiheitsgrade**

Die Zahl der Freiheitsgrade $\text{df}$ ist als Parameter für die t-Verteilung notwendig, und damit auch notwendig um Flächen (wie p-Werte) unter der Verteilung zu berechnen. De facto übernehmen das heute Computerprogramme, jedoch ist es nach wie vor Usus die Zahl der Freiheitsgrade eine statistischen Testes in wissenschaftlichen Veröffentlichungen anzugeben.
:::

:::{.fragment}
**3. Signifikanzniveau & ein/zweiseitige Testung**

Welchen Wert bestimme ich als Signifikanzniveau $\alpha$? Ist mein Test einseitig (gerichtete Hypothese) oder zweiseitig (ungerichtete Hypothese)? &xrarr; siehe auch Vorlesung 10
:::




<!----------------->
<!--- New slide --->
<!----------------->
## 0. Sind die Voraussetzungen für einen t-Test gegeben?

:::: {.columns}
::: {.column width="70%"}

:::{.nonincremental}
- Mindestens **intervallskalierte Daten**.
- **Hinreichende Normalverteilung** des gemessenen Merkmals $X$ in der Population (Zweistichproben-t-Test: Normalverteilung von $X_A$ und $X_B$ in den beiden Gruppen A und B!)
    - [Allerdings zeigen Simulationsstudien, dass der t-Test sehr „robust“ gegen Verletzungen der Normalverteilungsannahme ist.]{color="darkgreen"}
    - Problematisch sind stark schiefe Verteilungen (rechts- oder linksschief) bei kleinen Stichprobengrößen.
    - Kann von keiner Normalverteilung ausgegangen werden: nicht-parametrische Testverfahren (z.B. Mann-Whitney-U-Test).
:::
:::
::: {.column width="30%"}
![Mr. T](images/mrT.png)

:::
::::


<!----------------->
<!--- New slide --->
<!----------------->
## [But wait..]{color="darkred"}

![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=110px}

:::: {.columns}
::: {.column width="38%"}

[.. hatten wir nicht festgestellt, dass die Stichprobenverteilung von Kennwerten $\hat{\theta}$ gemäß dem zentralen Grenzwertsatz bei *beliebigen* Populationsverteilungen des gemessenen Merkmals $X$ normalverteilt ist? (vgl. Vorlesung 08)]{style="font-size: 24px"}

:::
::: {.column width="62%"}
![](images/central_limit_theorem_average.png){height=230px style="margin-top: 15px !important"}
:::
::::


:::{.fragment style="font-size: 24px"}
**Warum wird also plötzlich eine Normalverteilung des Merkmals $X$ in der Population vorausgesetzt?**
:::

::: {style="font-size:24px !important"}
:::{.fragment}
Zwei Gründe:
:::

::: {style="margin-top: -13px"}
- Damit $t=\hat{\theta}/\hat{se}$ einer t-Verteilung folgt, müssen der Stichprobenkennwert $\hat{\theta}$ und sein Standardfehler $\hat{se}$ unabhängig sein (dürfen nicht korrelieren). Dies ist theoretisch nur erfüllt, wenn das gemessene Merkmal $X$ einer Normalverteilung folgt &mdash; tatsächlich lässt sich genau mit dieser Bedingung die Normalverteilung ableiten.
- Der zentrale Grenzwertsatz für die Stichprobenverteilung von $\hat{\theta}$ gilt streng genommen nur für $n\rightarrow\infty$, was in empirischen Studien nie gegeben ist. Ist die Stichprobengröße $n$ begrenzt, kann die Stichprobenverteilung von $\hat{\theta}$ nur dann als normalverteilt angenommen werden, wenn auch das gemessene Merkmal $X$ in der Population normalverteilt ist ([Satz von Cramer](https://de.wikipedia.org/wiki/Satz_von_Cram%C3%A9r_(Normalverteilung))).
:::

:::

:::{.fragment style="margin-top: -15px"}
**Aber wie erwähnt: trotz dieser theoretischen Fallstricke ist der t-Test in der Praxis<br>auch bei nicht-normalverteilten Populationsvariablen $X$ recht robust.**
:::




<!----------------->
<!--- New slide --->
<!----------------->
## 1. Welche Art von t-Test benötige ich?

:::{.vcenter}
![](images/ttest_decisiontree.png){height=640px}
:::



<!----------------->
<!--- New slide --->
<!----------------->
## 2. Zahl der Freiheitsgrade

::: {.nonincremental style="font-size: 26px"}
- Die [**Zahl der Freiheitsgrade**]{color="navy"} gibt die **Zahl der frei variierbaren Werte** bei der Berechnung eines statistischen Kennwertes an.
- Häufig kann die Zahl der Freiheitsgrade recht einfach berechnet werden als Stichprobengröße $n$ *minus* die Anzahl der Zwischenparameter, die für die Berechnung des statistischen Kennwertes geschätzt werden müssen.
:::


<!---  Example --->
::: {.example .fragment style="font-size:23px !important; margin-top:-12px"}
:::: {.columns}
::: {.column width="7%"}
::: {style="margin-top: 10px"}
![](images/example.png){height=50px}
:::
:::
::: {.column width="93%"}
**Beispiel Varianz:** Angenommen, wir wollen für einer Stichprobe aus vier Werten die Varianz bestimmen:

::: {style="margin-top:-15px !important; margin-bottom:-5px !important"}
$$
\sigma^2 = \frac{1}{4}\sum_1^4 (x_i-\bar{x})^2
$$
:::

Aus der Formel der Varianz erkennen wir, dass wir zur Berechnung der Varianz **einen Parameter** aus den Daten bestimmen müssen, nämlich der Mittelwert $\bar{x}$. Die Zahl der Freiheitsgrade ergibt sich damit plain & simple nach obiger Definition als **Stichprobengröße n minus 1**, also in diesem Beispiel $\text{df}=3$. 

Dadurch, dass die Formel der Varianz den Mittelwert aller Datenpunkte als Parameter enthält, können wir nicht mehr alle 4 Datenpunkte beliebig frei variieren. Wir könnten drei beliebige Datenwerte frei bestimmen, der vierte Wert aber wäre durch den Mittelwertparameter automatisch festgelegt. Sagen wir der Mittelwert sei $\bar{x}=2$ und wir würden frei drei Werte als (2, 4, 1) frei wählen. Der vierte Wert ist nun nicht mehr frei, denn um die Randbedingung $\bar{x}=2$ zu garantieren, muss der vierte Wert gleich 1 sein. Diese Logik gilt nicht nur für den Mittelwertsparameter, sondern für jeden Parameter der "auf dem Weg" zur Berechnung einer statistischen Größe geschätzt werden muss (bei der Varianz ist der Mittelwert aber der einzige Zwischenparameter).
:::
::::
:::


<!----------------->
<!--- New slide --->
<!----------------->
## 2. Zahl der Freiheitsgrade: t-Test


:::: {.columns}
::: {.column width="70%"}

:::{.nonincremental}
- Für die Zahl der Freiheitsgrade beim t-Test gilt, dass die Zahl der Freiheitsgrade ausschließlich auf Basis der Streuung $\hat{\sigma}$ im Nenner bestimmt wird.
:::

$$
t=\frac{\hat{\theta}}{\hat{\sigma}/\sqrt{n}}
$$
:::
::: {.column width="30%"}
:::{style="margin-top: -70px"}
![](images/df_cartoon.jpg)
:::
:::
::::


- Häufig reicht es, zu zählen, wie viele Mittelwerte für die Berechnung von $\hat{\sigma}$ im Nenner des t-Wertes für die verschiedenen Tests verwendet werden:
    - Einstichproben-t-Test: 1 Mittelwert für 1 Stichprobe &xrarr; $\text{df}=n-1$
    - Differenzen-t-Test: 1 Mittelwert für 1 Stichprobe (hier: Mittelwert $\Delta\bar{x}$ der Differenzen $\Delta\bar{x}_i$) &xrarr; $\text{df}=n-1$
    - Zweistichproben-t-Test (ähnliche Varianzen): 2 Mittelwerte für 2 Stichproben &xrarr; $\text{df}=n_A+n_B-2$
    - (Ausnahme: Zweistichprobentest mit unterschiedlichen Varianzen &xrarr; Welch–Satterthwaite-Gleichung)
    - Korrelation und Regression: 2 Mittelwerte für die zwei Zusammenhangsvariablen $X$ und $Y$ &xrarr; $\text{df}=n-2$


<!-- - Eine berechtigte Frage ist, warum beim t-Test die Streuung $\hat{\sigma}$ nicht auch als Freiheitsgrad abgezogen werden muss (schließlich wird dieser Parameter bei der Berechnung des t-Wertes verwendet).
- Der Grund ist subtil und hängt damit zusammen, dass wir die t-Verteilung *unter der Voraussetzung verwenden, dass der Standardfehler geschätzt werden musste*. Der Verlust dieses Freiheitsgrades ist also in der Verteilung selbst bereits berücksichtigt und muss post-hoc nicht mehr als zusätzlicher Freiheitsgrad abgezogen werden.^[https://stats.stackexchange.com/questions/226483/does-the-determination-of-the-mean-and-sd-imply-the-loss-of-one-or-two-degrees-o] -->

<!----------------->
<!--- New slide --->
<!----------------->
<!-- ## [3. Zahl der Freiheitsgrade]{color="darkred"}

![](images/kein_klausurstoff.png){.absolute top=15 right=20 height=100px}

:::: {.columns}
::: {.column width="65%"}

:::{.nonincremental}
- Generell gilt: **wir wollen (idealerweise) eine möglichst große Zahl von Freiheitsgraden** für die Bestimmung unseres statistischen Kennwertes, denn alle Freiheitsgerade die nicht "unterwegs verloren gehen" (bei der Berechnung von Zwischenparametern), fließen in die Schätzung des Kennwertes ein und präzisieren damit dessen Schätzung.
- Das Konzept der Freiheitsgrade wird **besonders wichtig bei komplexeren Modellen**, wie sie in Statistik 2 behandelt werden (multiple Regression). Dort gehen schnell eine große Zahl von Freiheitsgraden "flöten" und die Zahl der Freiheitsgrade muss daher bereits bei der Wahl eines Modells berücksichtig werden.
:::
:::
::: {.column width="35%"}

![Bildnachweis^[https://www.facebook.com/SaraswathiAnalytics/photos/a.101349091331739/428667868599858]](images/df_cartoon.jpg){style="margin-top: 60px !important"}

:::
::::

:::{style="margin-top: -15px"}
:::{.nonincremental}
- Der **Begriff "Freiheitsgrad" ist wenig intuitiv**, weil die Datenpunkte nur im Gedankenexperiment "frei" gewählt werden können &mdash; in Realität sind sie natürlich gegeben.
- Ein intuitiverer Ausdruck wäre **effektive Stichprobengröße**: wie viele Datenpunkte aus meiner Stichprobe kann ich effektiv zur Schätzung meines statistischen Zielkennwerts nutzbar machen?
:::
::: -->



<!----------------->
<!--- New slide --->
<!----------------->
## 3. Signifikanzniveau & ein/zweiseitige Testung

**Erinnerung:**

::: {.colorbox}
Das **Signifikanzniveau** $\alpha$ gibt legt ein Kriterium für die Ablehnung der Nullhypothese fest.<br><br>[Es gilt:]{.underline} ist $p<\alpha$ lehnen wir die Nullhypothese ab und werten unseren Effekt als statistisch signifikant.
:::

:::: {.columns .fragment}
::: {.column width="50%"}

:::{.nonincremental}
- Der Wert $\alpha$ wird auch Irrtumswahrscheinlichkeit genannt &mdash; sie gibt das Risiko an, mit dem wir bereit sind, die Nullhypothese fälschlicherweise abzulehnen.
    - Beispiel: ist $\alpha=0{,}05$, so gibt es eine 5%-ige Wahrscheinlichkeit, einen signifikanten Effekt zu erhalten *obwohl die Nullhypothese zutrifft*.
    - Je kleiner $\alpha$, desto "konservativer" der Test, d.h. desto eher will ich vermeiden, einen Effekt fälschlicherweise als signifikant zu werten (erhöhe aber dabei mein Risko, einen wahren Effekt zu "verpassen").
:::

:::
::: {.column width="50%"}
![](images/significance_level.png){style="margin-top:0px !important"}
:::
::::