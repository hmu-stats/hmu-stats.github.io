



<!----------------->
<!--- New slide --->
<!----------------->
## Inferenzstatistik für Regressionskoeffizienten

:::: {.columns}
::: {.column width="64%"}

:::{.nonincremental}
- Die Hypothesentestung für den Regressionskoeffizienten der einfachen Regression (d.h. 1 UV) unterscheidet sich nicht von der Korrelation.
:::

:::{style="margin-top: -15px"}
- Auch für den Regressionskoeffizienten können wir einen Standardfehler definieren:
:::

:::{.fragment}
$$
\hat{se}(b_1)= \frac{\hat{\sigma}_Y}{\hat{\sigma}_X}\sqrt{\frac{1-r^2}{n-2}}
$$
:::

:::
::: {.column width="36%"}
![](images/regression_basics2.png)
:::
::::

- .. und einen darauf basierenden t-Wert:

:::{.fragment}
$$
t = \frac{b_1}{\hat{se}(b_1)} \overset{\text{(s. nächste Folie)}}{=} r\sqrt{\frac{n-2}{1-r^2}}
$$
:::

- Die Zahl der Freiheitsgrade ist wie bei der Korrelation $\text{df}=n-2$, da auch hier für die Berechnung des Standardfehlers die beiden Mittelwerte $\bar{x}$ und $\bar{y}$ bestimmt werden müssen.
- Der Rest ist bekannt.

<!----------------->
<!--- New slide --->
<!----------------->
## [Inferenzstatistik für Regressionskoeffizienten]{color="darkred"}

![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=110px}

:::{.nonincremental}
- Während die Regressionssteigung abhängt davon, welche Variable als UV (bzw. $x$) und welche als AV (bzw. $y$) definiert wird, sind die t-Werte (und damit auch die p-Werte) unabhängig von der Rollenverteilung der Variablen.
- Dies ergibt sich direkt aus dem Zusammenhang von $r$ und $b_1$ (vgl. Vorlesung 06):
:::

$$
b_1 = \frac{\hat{\sigma}_Y}{\hat{\sigma}_X}r
$$

:::{.nonincremental}
- Damit ist die Prüfgröße $t$:
:::

:::{style="margin-top: -12px"}
$$
t = \frac{b_1}{\hat{se}(b_1)} = \frac{\frac{\hat{\sigma}_Y}{\hat{\sigma}_X}r}{\frac{\hat{\sigma}_Y}{\hat{\sigma}_X}\sqrt{\frac{1-r^2}{n-2}}} = \frac{r}{\sqrt{\frac{1-r^2}{n-2}}} = r\sqrt{\frac{n-2}{1-r^2}}
$$
:::

:::{.nonincremental}
- Der t-Wert bei der einfachen Regression ist also identisch zum t-Wert der Korrelation und insbesondere nur noch abhängigg von $r$ und nicht mehr $b_1$
- Da für die Korrelation $r$ die Rollenverteilung der beiden Zusammenhangsvariablen<br>unerheblich ist, folgt, dass der p-Wert bei der Regression ebenso wenig von der<br>Zuordnung der Variablen als UV und AV abhängt.
:::




<!----------------->
<!--- New slide --->
<!----------------->
## [Testung des y-Achsenabschnitts bei der Regression]{color="darkred"}

![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=110px}

:::{.nonincremental}
- Wir haben bislang den Achsenabschnitt $b_0$ aus der Diskussion außen vor gelassen.
- Im Kontext der Regression wird der Achsenabschnitt $b_0$ idR nicht getestet. 
- Grund: die Frage, ob Variable $Y$ bei $X=0$ einen y-Achsenabschnitt aufweist, der signifikant von Null verschieden ist, ist im Kontext der Regression selten interessant &mdash; schließlich ist es ja der ganze Zweck der Regression die systematische Verändeurng von $Y$ in $X$ zu analysieren und dabei gerade nicht nur einen bestimmten Wert von $X$ zu betrachten.
- Nichts desto trotz ist auch die Schätzung von $b_0$ mit Unsicherheit verbunden, die durch folgenden Standardfehler definiert ist: 
:::
$$
\hat{se}(b_0) = \underbrace{\sqrt{\frac{\sum\left(y_i-\hat{y_i}\right)^2}{n-2}}}_\text{Standardabweichung der Residuen}\sqrt{\frac{1}{n}+\frac{\bar{x}^2}{\sum\left(x_i-\bar{x}\right)^2}}
$$

<!----------------->
<!--- New slide --->
<!----------------->
## [Testung des y-Achsenabschnitts bei der Regression]{color="darkred"}

![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=110px}

:::{.nonincremental}
- Ein Spezialfall ist das lineare Modell ohne Steigung (bzw. ohne x!):
:::

$$
\hat{y} = b_0
$$

:::{.nonincremental}
- In diesem Modell kommt dem Regressionskoeffizienten $b_0$ und dessen Unsicherheit eine interessantere Bedeutung zu: die Frage ob $b_0$ signifikant verschieden von 0 ist, ist hier gleichbedeutend mit der Frage ob die Zufallsvariable $Y$ **signifikant verschieden von Null ist**.
- Mit anderen Worten: dieses Modell ist nichts anderes als ein Einstichproben-t-Test!
- Dies beinhaltet auch den Vergleich zweier abhängiger Messungen A und B, wenn wir zuvor $Y$ als Differenzvariable definieren: 
$Y=Y_A-Y_B$
:::
:::{.nonincremental}
- .. dann testet 
:::

$$
\hat{y} = b_0
$$

:::{.nonincremental}
- die Frage, ob die Mittelwertsdifferenz von A und B signifikant verschieden von Null ist.
:::




<!----------------->
<!--- New slide --->
<!----------------->
## ["Common statistical tests are linear models"]{color="darkred"}

![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=110px}


Die Parallele von bekannten statistischen Tests und (generalisierter) linearer Regression lässt sich auf alle Tests erweitern, die wir in Statistik 1 und Statistik 2 kennenlernen.

Hier eine Auswahl der Tests aus Statistik 1:

<!---  Table --->
| Test | Lineares Modell | Spezifierung | Nullhypothese |
|-|-|-|-|
| Pearson-Korrelation | $\hat{y}=\beta_0 + \beta_1 x$ | - | $\mathcal{H}_0: \beta_1 = 0$|
| Spearman-Korrelation | $\text{Rang}(\hat{y})=\beta_0 + \beta_1 \text{Rang}(x)$ | - | $\mathcal{H}_0: \beta_1 = 0$|
| Einstichproben-t-Test | $\hat{y}=\beta_0$ | - | $\mathcal{H}_0: \beta_0 = 0$|
| Differenzen-t-Test | $\hat{y_A}-\hat{y_B}=\beta_0$ | - | $\mathcal{H}_0: \beta_0 = 0$|
| Zweistichproben-t-Test | $\hat{y}=\beta_0 + \beta_1 x$ | $x=0$ für alle Datenpunkte von Gruppe A und $x=1$ für alle Datenpunkte von Gruppe B &rarr; Regression auf binäre x-Variable! | $\mathcal{H}_0: \beta_1 = 0$|

: {tbl-colwidths="[20, 25, 40, 15]"}

::: {.caption-style}
Die Analogie von bekannten statistischen Tests und linearem Modell ist lange bekannt, ging aber 2021 durch Beiträge von Jonas Lindeløv viral^[https://stats.stackexchange.com/questions/303269/common-statistical-tests-as-linear-models] ^[https://lindeloev.github.io/tests-as-linear/] ^[https://twitter.com/jonaslindeloev/status/1110907133833502721].
:::

<!----------------->
<!--- New slide --->
<!----------------->
## {.blackslide .center}

<div class="vspace-small"></div>

:::: {.columns}
::: {.column width="68%"}

![](images/paradoxia_histogram_correlation_paradoxiker.png){height=300px}

:::
::: {.column width="32%"}
::: {.content-hidden when-format="pdf"}

![](images/paradoxia_group_of_scientists.png){.hcenter-image height=250px style="margin-top:-20px !important; margin-left:-20px !important"}

:::
:::
::::


Stichwort Signifikanz von Zusammenhängen: die Signifikanz des unerwarteten Zusammenhangs von TikTok-Onlinezeit und Entzündungswerten haben Sie bislang nicht getestet.

Basierend auf dem Korrelationskoeffizienten $r=0{,}517$ und der Stichprobengröße $n=50$ ergibt sich die Prüfgröße $t$ direkt:

<div class="vspace-small"></div>

$$
t = \frac{r}{\hat{se}(r)} = r\sqrt{\frac{n-2}{1-r^2}} = 0{,}517\sqrt{\frac{50-2}{1-0{,}517^2}} = 4{,}18
$$

<!----------------->
<!--- New slide --->
<!----------------->
## {.blackslide .center}

<div class="vspace-small"></div>

:::: {.columns}
::: {.column width="60%"}

Der Zusammenhang war unerwartet und es gab dementsprechend keine gerichtete Hypothese. Der p-Wert ist in diesem Fall also der doppelte Wert der Fläche rechts des (positiven) t-Werts von $4{,}18$, oder analog, der doppelte Wert links des negierten t-Werts $-4{,}18$.

$$
p=2\int_{-\infty}^{-4{,}18}f_t(x|\scriptsize\text{df}\normalsize)dx = 2F_t(-4{,}18|48)=0{,}0001
$$

[(Die Zahl der Freiheitsgrade beim t-Test der Korrelation ist $n-2$)]{style="font-size:24px"}


:::
::: {.column width="40%"}
::: {.content-hidden when-format="pdf"}

![](images/paradoxia_nulldist_t_r.png)

:::
:::
::::


Der Zusammenhang von TikTok-Onlinezeit und Entzündungswerten ist also deutlich signifikant.

Trotz des hochsignifikanten Effektes bleiben Sie skeptisch &mdash; Ihr größtes Fragezeichen: was ist Ursache, was ist Wirkung? Folgen erhöhte Entzündungswerte tatsächlich auf TikTok-Konsum (einschlägiger Kanäle)? Oder ist es einfach so, dass Erkrankte (mit erhöhten Entzündungswerten) Rat und Solidarität auf TikTok suchen?


<!----------------->
<!--- New slide --->
<!----------------->
## {.blackslide .center}

<div class="vspace-small"></div>

:::: {.columns}
::: {.column width="68%"}
Um die Gruppen*unterschiede* nun ebenfalls mithilfe des t-Tests zu überprüfen, listen Sie nochmals alle relevanten  Werte auf, die Sie zum Teil bereits beim z-Test bestimmt hatten:

<!---  Table --->
||Fallzahl $n$|$\Delta\bar{x}$ |Standardfehler $\hat{se}$|Freiheitsgrade $\text{df}$|
|-|-|-|-|-|
| [TikTok]{.underline} | $2\times 50$ | $0{,}577$ | ${0{,}123}$ | $93{,}7$ |
| [Entzündung]{.underline} | $2\times 50$ |$0{,}0243$ | ${0{,}0147}$ | $96{,}2$ |

: {tbl-colwidths="[18, 18, 10, 27, 27]"}


:::
::: {.column width="32%"}
::: {.content-hidden when-format="pdf"}

![](images/paradoxia_group_of_scientists.png){.hcenter-image height=200px style="margin-top:-20px !important"}

:::
:::
::::

<div class="vspace-medium"></div>

:::{.nonincremental}
- Neu hinzugekommen sind die Freiheitsgrade, die Sie in der Tabelle mit der Formel für ungleiche Varianzen bestimmt haben:
:::

$$
\text{df}=(n-1)\Big(1+\frac{2}{\left(\frac{\hat{\sigma}_\text{control}}{\hat{\sigma}_\text{paradoxia}}\right)^2+\left(\frac{\hat{\sigma}_\text{paradoxia}}{\hat{\sigma}_\text{control}}\right)^2}\Big) 
$$

:::{.nonincremental}
- Zur Erinnerung:
    - TikTok: $\hat{\sigma}_\text{control}=0{,}55$; $\hat{\sigma}_\text{paradoxia}=0{,}68$ 
    - Entzündung: $\hat{\sigma}_\text{control}=0{,}068$; $\hat{\sigma}_\text{paradoxia}=0{,}078$
:::




<!----------------->
<!--- New slide --->
<!----------------->
## {.blackslide .center}

<div class="vspace-small"></div>

:::: {.columns}
::: {.column width="68%"}
 
Mit diesen Information erhalten Sie folgende t-Werte (* in diesem Fall identisch mit den z-Werten!):

$$
\text{TikTok:}\qquad t=\frac{\Delta\bar{x}}{\hat{se}} = \frac{0{,}577}{0{,}123} = 4{,}69\\
\text{Entzündung:}\qquad t=\frac{\Delta\bar{x}}{\hat{se}} = \frac{0{,}0243}{0{,}0147} = 1{,}65
$$


:::
::: {.column width="32%"}
::: {.content-hidden when-format="pdf"}

![](images/paradoxia_group_of_scientists.png){.hcenter-image height=200px style="margin-top:-20px !important"}

:::
:::
::::

:::: {.columns}
::: {.column width="60%"}
Statt der Standardnormalverteilung integrieren Sie nun einfach die entsprechende Fläche unter der t-Verteilung:

$$
p=\int_{t}^{\infty}f_t(x|\scriptsize\text{df}\normalsize)dx = 1-F_t(t|\scriptsize\text{df}\normalsize)
$$

:::
::: {.column width="40%"}

![](images/paradoxia_nulldist_t.png)

:::
::::

[(*) Warum identisch? Weil wir für die z-Werte &mdash; in Abwesenheit anderweitig bekannter Werte &mdash; ebenfalls die Stichprobenstreuung verwendet hatten.]{style="font-size: 23px; margin-top: 15px;"}


## {.blackslide .center}

<!-- <div class="vspace-small"></div> -->

:::: {.columns}
::: {.column width="68%"}

:::{style="margin-top: -15px"}
Die große Frage ist: würden weiterhin beide Effekte signifikant bleiben? Antwort:
:::

<!-- <div class="vspace-small"></div> -->

$$
\text{TikTok:}\qquad p= 1 - F_t(4{,}83|93{,}7) \overset{\text{(Computer)}}{=} 0{,}000003
$$

<div class="vspace-small"></div>

$$
\text{Entzündung:}\qquad p= 1 - F_t(1{,}65|96{,}2) \overset{\text{(Computer)}}{=} 0{,}051
$$

:::
::: {.column width="32%"}
::: {.content-hidden when-format="pdf"}
![](images/paradoxia_group_of_scientists.png){.hcenter-image height=200px style="margin-top:-20px !important"}

:::
:::
::::


Kurios &mdash; das Pendel beim Entzündungseffekt schlägt exakt auf der anderen Seite des Signifikanzniveaus aus! Der Effekt ist nun nicht mehr signifikant. Der TikTok-Effekt bleibt stabil.

Bei beiden Effekten zeigt sich die leicht konservativere Natur der t-Verteilung. Die stärkeren Flanken im Vergleich zur Normalverteilung führen zu geringfügig höheren p-Werten. Notgedrungen müssen Sie Ihre zentrale Grafik anpassen und das Signifikanzsternchen beim Entzündungseffekt entfernen:

![](images/paradoxia_histogram_inflammation_sem_nonsig.png){height=270px}


<!-- ```{python}
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import os
from scipy.stats import sem
import seaborn as sns

np.random.seed(0)
root = '/home/matteo/OneDrive/lehre/Statistik/stats1_lecture/book/'

fontsize = 15

df = pd.read_csv(os.path.join(root, 'data', 'paradoxia.csv'))
# print(df.head())

data_tiktok_control = df[df.group == 1]['hours_tiktok_per_day'].values
data_tiktok_paradoxia = df[df.group == 2]['hours_tiktok_per_day'].values
data_inflam_control = df[df.group == 1]['inflammation'].values
data_inflam_paradoxia = df[df.group == 2]['inflammation'].values

print(f'Mean TikTok Control: {np.mean(data_tiktok_control):.2f}')
print(f'Mean TikTok Paradoxia: {np.mean(data_tiktok_paradoxia):.2f}')
print(f'Mean Inflam Control: {np.mean(data_inflam_control):.2f}')
print(f'Mean Inflam Paradoxia: {np.mean(data_inflam_paradoxia):.2f}')

plt.style.use('dark_background')
plt.figure(figsize=(6, 2.5))
ax = plt.subplot(121)
plt.gca().set_facecolor('#eee')
sns.stripplot(data=df, x='group', y='hours_tiktok_per_day', color='#bbb', jitter=0.25)
color = 'k'
plt.errorbar([0], [np.mean(data_tiktok_control)], yerr=[sem(data_tiktok_control)], fmt='o', markersize=4, capsize=10, capthick=1.5, elinewidth=1.5, ecolor=color, mfc=color, mec=color, zorder=3)
plt.errorbar([1], [np.mean(data_tiktok_paradoxia)], yerr=[sem(data_tiktok_paradoxia)], fmt='o', markersize=4, capsize=10, capthick=1.5, elinewidth=1.5, ecolor=color, mfc=color, mec=color, zorder=3)
plt.text(0.25, 0.85, r'$\bar{x}=' + f'{np.mean(data_tiktok_control):.2f}$'.replace('.', '{,}'), ha='center', color='k', fontsize=fontsize-1, transform=ax.transAxes)
plt.text(0.75, 0.85, r'$\bar{x}=' + f'{np.mean(data_tiktok_paradoxia):.2f}$'.replace('.', '{,}'), ha='center', color='k', fontsize=fontsize-1, transform=ax.transAxes)
plt.plot([0, 1], [2.4, 2.4], 'k-', lw=2, zorder=4)
plt.text(0.5, 2.32, '***', ha='center', va='center', fontsize=15, color='k', backgroundcolor='#eee', zorder=5)

plt.xticks([0, 1], ['Kontroll', 'Paradoxia'], fontsize=fontsize)
plt.yticks(fontsize=fontsize-2)
plt.ylabel('Stunden TikTok / 24h', fontsize=fontsize)
plt.xlabel('')
# plt.xlim(-0.5, 1.5)
plt.ylim(0, 1.1*max(data_tiktok_control.max(), data_tiktok_paradoxia.max()))


ax = plt.subplot(122)
plt.gca().set_facecolor('#eee')
sns.stripplot(data=df, x='group', y='inflammation', color='#bbb', jitter=0.25)
color = 'k'
plt.errorbar([0], [np.mean(data_inflam_control)], yerr=[sem(data_inflam_control)], fmt='o', markersize=4, capsize=10, capthick=1.5, elinewidth=1.5, ecolor=color, mfc=color, mec=color, zorder=3)
plt.errorbar([1], [np.mean(data_inflam_paradoxia)], yerr=[sem(data_inflam_paradoxia)], fmt='o', markersize=4, capsize=10, capthick=1.5, elinewidth=1.5, ecolor=color, mfc=color, mec=color, zorder=3)
plt.text(0.25, 0.85, r'$\bar{x}=' + f'{np.mean(data_inflam_control):.2f}$'.replace('.', '{,}'), ha='center', color='k', fontsize=fontsize-1, transform=ax.transAxes)
plt.text(0.75, 0.85, r'$\bar{x}=' + f'{np.mean(data_inflam_paradoxia):.2f}$'.replace('.', '{,}'), ha='center', color='k', fontsize=fontsize-1, transform=ax.transAxes)
# plt.plot([0, 1], [0.25, 0.25], 'k-', lw=2, zorder=4)
# plt.text(0.5, 0.24, '*', ha='center', va='center', fontsize=15, color='k', backgroundcolor='#eee', zorder=5)

plt.xticks([0, 1], ['Kontroll', 'Paradoxia'], fontsize=fontsize)
plt.yticks(fontsize=fontsize-2)
plt.ylabel('Entzündungswert', fontsize=fontsize)
plt.xlabel('')
plt.xlim(-0.5, 1.5)
plt.ylim(0, 1.1*max(data_inflam_control.max(), data_inflam_paradoxia.max()))


plt.tight_layout()

plt.savefig('images/paradoxia_histogram_inflammation_sem_nonsig.png', bbox_inches='tight')
``` -->

## {.blackslide .center}

::: {.content-hidden when-format="pdf"}
![](images/paradoxia_group_of_scientists.png){.hcenter-image height=300px}
<!-- Source: Midjourney -->
<div class="vspace-small"></div>
:::

Vor dem Hintergrund dieser neuen Ergebnisse, stellen sich eine Reihe von Fragen:

- Ist die Interpretation der Signifikanz fundamental verschieden zwischen dem z- und dem t-Test?
- Ist die Entzündungshypothese eindeutig widerlegt?
- Können Sie aus dem hochsignifikanten Effekt der TikTok-Hypothese und dem nicht-signifikanten Effekt der Entzündungshypothese schlussfolgern, dass der TikTok-Effekt signifikant stärker ist?
- Können Sie schlusfolgern, dass Paradoxia eindeutig durch den TikTok-Effekt verursacht wird?

<!----------------->
<!--- New slide --->
<!----------------->
<!-- ## {.center}

![[xkcd#1347](https://xkcd.com/1347/)](images/xkcd1347.png)

- Siehe auch [https://www.explainxkcd.com/wiki/index.php/1347](https://www.explainxkcd.com/wiki/index.php/1347)
 -->
