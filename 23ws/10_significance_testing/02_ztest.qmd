

<!----------------->
<!--- New slide --->
<!----------------->
## Vereinfachung: Populationsstreuungen $\sigma$ bekannt

:::: {.columns}
::: {.column width="65%"}

Im ersten Schritt betrachten wir daher den vereinfachten (in der Praxis sehr seltenen) Fall, dass wir die Streuung $\sigma_\text{med}$ und $\sigma_\text{psych}$ in den beiden Populationen der Medizin und Psychologie kennen, und damit den Standardfehler $se$ unseres Effektes $\Delta \bar{x}$: 

$$
se=\sqrt{\frac{\sigma_\text{med}^2+\sigma_\text{psych}^2}{n}}
$$

:::{.fragment}
Hinweis: dies ist die Formel für den Standardfehler des Differenzeffektes $\bar{x}_\text{med}-\bar{x}_\text{psych}$. Nehmen wir an, der Standardfehler ergibt sich nach dieser Formel zu $se=0{,}1$.
:::

:::{.fragment}
Nun ist alles angerichtet und wir können unseren ersten p-Wert berechnen! Dazu muss die Fläche unter der Nullhypothesenverteilung [rechts]{.underline} von $\Delta\bar{x}=\bar{x}_\text{med}-\bar{x}_\text{psych}$ berechnet werden (Erinnerung: wir sind an der Wahrscheinlichkeit interessiert, dass die Daten unseren Effekt annehmen *oder einen noch größeren Effekt*).
:::

:::
::: {.column width="34%"}
![](images/nulldist2c.png)
<div class="vspace-medium"></div>
:::{.fragment}
![](images/nulldist2d.png)
:::
:::
::::


<!----------------->
<!--- New slide --->
<!----------------->
## Vereinfachung: Populationsstreuungen $\sigma$ bekannt

:::: {.columns}
::: {.column width="65%"}

Die Fläche bzw. der p-Wert berechnet sich wie folgt:
$$
\begin{aligned}
p &= \int_{\Delta\bar{x}}^{\infty}f(x)dx = 1 - F(\Delta\bar{x}) = \\
&= 1 - F(0{,}2) \overset{(Computer)}{=} 0{,}023
\end{aligned}
$$

wobei $f(x)$ bzw. $F(x)$ hier die Dichte bzw. Verteilunsfunktion der gebenen Normalverteilung $\mathcal{n}(0, 0{,}1)$ ist.

:::{.fragment}
$F(x)$ berechnet die Fläche bis zum Punkt $x$, "1 minus diese Fläche" gibt uns also die Fläche rechts vom angebenen Punkt $x$ &mdash; im vorliegenden Fall die Fläche rechts von $\Delta\bar{x}=\bar{x}_\text{med}-\bar{x}_\text{psych}=0{,}2$.
:::

:::{.fragment}
Der p-Wert ist 0,023. 
:::

:::
::: {.column width="34%"}
![](images/nulldist2d.png)
:::
::::


:::{.fragment}
In Worten können wir feststellen: die Wahrscheinlichkeit, dass unser Effekt $\Delta\bar{x}$ durch Zufall entstanden ist &mdash; also unter der Annahme, dass die Nullhypothese gilt &mdash; beträgt (nur) 2,3%.
:::


<!----------------->
<!--- New slide --->
<!----------------->
## Standardfehler bei Mittelwertdifferenzen

[**Messungen in unabhängigen Gruppen mit unterschiedlichen Varianzen**]{.underline}

Sind die Standardabweichungen in beiden Gruppen unterschiedlich (Faustregel: um mehr als einen Faktor 2), kann keine gepoolte Standardabweichung für beide Gruppen berechnet werden, und die Standardfehler werden für beide Gruppen separat berechnet:

:::{style="margin-top: -8px"}
$$
se_A = \frac{\sigma_A}{\sqrt{n_A}}\qquad\qquad se_B = \frac{\sigma_B}{\sqrt{n_B}}
$$
:::

:::{.fragment}
Die Varianzen der Mittelwerte in beiden Gruppen sind gleich dem quadrierten Standardfehler der Mittelwerte:

:::{style="margin-top: -40px"}
$$
se_A^2 = \frac{\sigma_A^2}{n_A}\qquad\qquad se_B^2 = \frac{\sigma_B^2}{n_B}
$$
:::
:::

:::{.fragment}
Nun sind wir ja an der Differenz der Mittelwerte $\Delta\bar{x}$ interessiert. Allgemein gilt, dass sich die Varianzen von Summen oder Differenz zweier unabhängiger Zufallsvariablen addieren:

$$
se^2 = se_A^2 + se_B^2 = \frac{\sigma_A^2}{n_A} + \frac{\sigma_B^2}{n_B}
$$
:::


:::{.fragment}
Daher gilt für den **Standardfehler der Mittelwertsdifferenz unabhängiger Gruppen A und B**:

:::{style="margin-top: -10px"}
$$
se = \sqrt{\frac{\sigma_A^2}{n_A} + \frac{\sigma_B^2}{n_B}}
$$
:::
:::

<!----------------->
<!--- New slide --->
<!----------------->
## Standardfehler bei Mittelwertdifferenzen

[**Messungen in unabhängigen Gruppen mit ähnlichen Varianzen**]{.underline}

Gilt $\frac{1}{2}<\frac{\sigma_A}{\sigma_B}<2$, die Standardabweichungen sind also ähnlich, wird der Standardfehler auf Basis der gepoolten Standardabweichung berechnet:

$$
se = \sigma_\text{pooled}\sqrt{\frac{1}{n_A} + \frac{1}{n_B}}\qquad\text{mit}\qquad \sigma_\text{pooled} = \sqrt{\frac{n_A\sigma^2_A + n_B\sigma^2_B}{n_A+n_B}}
$$


[**Messungen in abhängigen Bedingungen einer Gruppe**]{.underline .fragment}

:::{.fragment}
Zur Herleitung des Standardfehlers der Mittelwertdifferenz zweier abhängiger Messungen A und B *in einer Stichprobe* können wir die Variablen $X_A$ und $X_B$ im ersten Schritt direkt voneinander abziehen:

$$
\Delta X = X_A - X_B
$$

.. und mit der Standardformel die Standardabweichung $\sigma_\Delta$ dieser Differenz berechnen. 
:::

:::{.fragment}
Der Standardfehler der Mittelwertsdifferenz abhängiger Bedingungen A und B ergibt sich daher bei einer Stichprobengröße $n$ als:

$$
se = \frac{\sigma_\Delta}{\sqrt{n}}\qquad\text{mit}\qquad \sigma_\Delta=\sqrt{\frac{1}{n}\sum\left(\Delta x_i-\Delta\bar{x}\right)^2}
$$
:::





<!----------------->
<!--- New slide --->
<!----------------->
## Standardfehler bei Mittelwertdifferenzen: Cheat sheet

<!---  Table --->
|Fall|Berechnung des Standardfehlers $se$|
|-|-|
| **Differenz des Mittelwertes [einer Gruppe]{.underline} und einem Referenzwert** $\mu_0$  | $se = \frac{\sigma}{\sqrt{n}}$ |
| **Mittelwertdifferenz zweier Bedingungen A und B in [einer Gruppe]{.underline}** | $se = \frac{\sigma_\Delta}{\sqrt{n}}\qquad\text{mit}$ \
$\scriptsize{\sigma_\Delta=\sqrt{\frac{1}{n}\sum\left(\Delta x_i-\Delta\bar{x}\right)^2}\qquad\text{oder}\qquad \sigma_\Delta=\sqrt{\sigma_A^2+\sigma_B^2-2\,Cov(X_A,X_B)}}$ |
| **Mittelwertdifferenz [zweier unabhängiger Gruppen]{.underline} A und B (ähnliche Varianzen)** | $se = \sigma_\text{pooled}\sqrt{\frac{1}{n_A} + \frac{1}{n_B}}\qquad\text{mit}\qquad \sigma_\text{pooled} = \sqrt{\frac{n_A\sigma^2_A + n_B\sigma^2_B}{n_A+n_B}}$ |
| **Mittelwertdifferenz [zweier unabhängiger Gruppen]{.underline} A und B (unterschiedliche Varianzen)** | $se = \sqrt{\frac{\sigma_A^2}{n_A} + \frac{\sigma_B^2}{n_B}}$ |

:  {tbl-colwidths="[40, 50]"}

<div class="vspace-medium"></div>

::: {.merke}
:::: {.columns}
::: {.column width="5%"}
::: {style="margin-top: 18px"}
![](images/merke.png){height="55px"}
:::
:::
::: {.column width="95%"}
Dieses Cheat sheet gilt für den Fall, dass die **Varianzen $\sigma_A^2$ bzw. $\sigma_B^2$ in den Populationen bekannt sind**! Falls dies nicht der Fall ist, sehen die Formeln aufgrund der Besselkorrektur subtil anders aus (vgl. Vorlesung 11).
:::
::::
:::

<!----------------->
<!--- New slide --->
<!----------------->
## [Stichprobenverteilungen von Mittelwertdifferenzen ($\sigma$ bekannt)]{style="font-size:40px"}

<div class="vspace-small"></div>
![](images/stichprobenverteilung_diff_z.png)


<!----------------->
<!--- New slide --->
<!----------------->
## z-Test

In der Praxis wird die Berechnung von p-Werten um das Konzept der [**standardisierten Prüfgröße**]{color="navy"} erweitert.

- Um das Konzept zu verstehen, erinnern wir uns, dass wir im Beispiel eine Fläche unter der Normalverteilung $\mathcal{N}(0, 0{,}1)$ berechnet haben. Für die nächste statistische Analyse müssten wir sehr wahrscheinlich die Fläche unter einer Normalverteilung mit einer anderen Streuung als $0{,}1$ berechnen.
- Gerade im Vorcomputerzeitalter war die Berechnung von Flächen unter beliebigen Normalverteilungen eine Herausforderung.
- Abhilfe schafft die **Standardisierung** des Effektes:

:::: {.columns}
::: {.column width="65%"}

:::{.fragment style="margin-top: -20px"}
$$
z = \frac{\Delta\bar{x}}{se}
$$
:::

:::{.fragment}
Nach Teilen von $\Delta\bar{x}$ durch die Streuung $se$, hat die Nullverteilung nicht mehr die Streuung $se$, sondern *immer* die Streuung $\frac{se}{se}=1$!
:::

:::
::: {.column width="34%"}
:::{.fragment}
![](images/nulldist2e.png){style="margin-top:-80px !important"}
:::
:::
::::

:::{.fragment}
$z$ wird als **standardisierte Prüfgröße** bezeichnet, während der einfache Effekt $\Delta\bar{x}$ eine **unstandardisierte Prüfgröße** darstellte.
:::


<!----------------->
<!--- New slide --->
<!----------------->
## z-Test

Es gibt auch im Computerzeitalter noch Vorteile für diese Art der Standardisierung:

- Der resultierende z-Wert ist vergleichbar zwischen Studien, im Gegensatz zum Mittelwertsunterschied $\Delta \bar{x}$, der von der spezifischen Skala abhängt.
- Der z-Wert hat eine intuitive Interpretation: er gibt an, *wie viele Standardabweichungen der Effekt vom Mittelwert der angenommenen (Null-)Normalverteilung entfernt ist*.

:::: {.columns .fragment}
::: {.column width="65%"}


Mit dem Z-Wert als Prüfgröße benötigten wir also für alle Tests dieser Art nur noch eine einzige Verteilung &mdash; die Normalverteilung mit Mittelwert $0$ und Streuung $1$. Man bezeichnet sie als [**Standardnormalverteilung**]{color="navy"}:

<div class="vspace-small"></div>


$$
f(x)=\frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2}\quad\underset{\sigma=1}{\overset{\mu=0}{=}}\quad\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}}
$$

<!-- $$
\text{Standardnormalverteilung:}\qquad X \sim \mathcal{N}(0, 1)
$$ -->

:::
::: {.column width="34%"}
![](images/nulldist2e.png)
:::
::::

:::{.fragment}
Die Art der Berechnung des p-Wertes ändert sich nicht &mdash; wir berechnen in unserem Beispiel weiterhin die Fläche rechts von unserem Effekt, nur dass der "Effekt" jetzt standardisiert und als $z = \frac{\Delta\bar{x}}{se} = \frac{\bar{x}_\text{med}-\bar{x}_\text{psych}}{se}$ definiert ist. Der resultierende p-Wert ist derselbe.
:::




<!----------------->
<!--- New slide --->
<!----------------->
## Einschub: Das ABC der Normalverteilung

Aufgrund ihrer Bedeutung in der Statistik, haben sich für die (Standard)Normalverteilung bestimmte Bezeichnung eingebürgert, auf die wir ab jetzt zugreifen werden.

<!---  Table --->
|||
|-|-|
| **Normalverteilung mit Angabe des Mittelwertes $\mu$ und der Varianz $\sigma^2$** | $\mathcal{N}(\mu, \sigma^2)$ |
| **Standardnormalverteilung (Mittelwert 0, Varianz 1)** | $\mathcal{N}(0, 1)$ |
| **Dichtefunktion der Normalverteilung** | $f(x)=\frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2}$ |
| **Dichtefunktion der Standardnormalverteilung** | $\varphi(x)=\frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}x^2}$  (sprich "Klein Phi") \
Es gilt: $\quad f(x) = \frac{1}{\sigma}\varphi\left(\frac{x-\mu}{\sigma}\right)$ |
| **Verteilungsfunktion der Normalverteilung** | $F(x)=\frac{1}{\sigma\sqrt{2\pi}}\int_{-\infty}^x e^{-\frac{1}{2}\left(\frac{x'-\mu}{\sigma}\right)^2}dx\qquad$ |
| **Verteilungsfunktion der Standardnormalverteilung** | $\Phi(x)=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^x e^{-\frac{1}{2}x'^2}dx\qquad$ (sprich "Groß Phi") \
Es gilt: $\quad F(x) = \Phi\left(\frac{x-\mu}{\sigma}\right)$ |

: {tbl-colwidths="[47, 50]"}



<!----------------->
<!--- New slide --->
<!----------------->
## z-Test

:::: {.columns}
::: {.column width="66%"}

Berechnen wir nun den p-Wert im Nasenlängenbeispiel mithilfe des z-Tests. 

:::{.fragment}
Wir bestimmen die standardisierte Prüfgröße $z$:

$$
z = \frac{\Delta\bar{x}}{se} = \frac{0{,}2}{0{,}1} = 2
$$
:::

:::{.fragment}
Und berechnen die Fläche rechts von $z$:

$$
p=\int_{z}^{\infty}\varphi(x)dx = 1 - \Phi(Z) = 1 - \Phi(2) \overset{(Computer)}{=} 0{,}023
$$
:::

:::
::: {.column width="34%"}
![](images/nulldist2f.png)
:::
::::


:::{.fragment}
Beachte, dass wir hier statt $f(x)$ die Nomenklatur $\varphi(x)$ für die Dichte der Standardnormalverteilung verwenden, und statt $F(x)$ den Ausdruck $\Phi(x)$ für die Verteilungsfunktion der Standardnormalverteilung.
:::

<!----------------->
<!--- New slide --->
<!----------------->
## z-Test

Der Signifikanztest auf Basis der Standardnormalverteilung &mdash; und bei bekannten Streuungen in den relevanten Populationen &mdash; wird als [**z-Test**]{color="navy"} bezeichnet.

Der z-Test kann auf alle Arten von Mittelwertsvergleichen angewendet werden:

<!---  Table --->
|Fall|Z-Wert|Bekannt|Berechnung von $se$|
|-|-|:-:|-|
| **Einzelmessung:** Vergleich von $\bar{x}$ mit einem Referenzwert $\mu_0$ | $z=\frac{\bar{x}-\mu_0}{se}$ |$\sigma$|$se=\sigma_{\bar{x}}=\frac{\sigma}{\sqrt{n}}$|
| **Abhängige Messungen:** Vergleich der Mittelwerte $\bar{x}_A$ und $\bar{x}_B$ von *zwei Bedingungen A und B in einer Gruppe* | $z=\frac{\bar{x}_A-\bar{x}_B}{se}=\frac{\Delta \bar{x}}{se}$ |$\sigma_A, \sigma_B$<br>$\scriptsize{Cov(X_A,X_B)}$|$se=\sqrt{\frac{\sigma_A^2+\sigma_B^2-2\,Cov(X_A,X_B)}{n}}$|
| **Unabhängige Messungen:** Vergleich der Mittelwerte $\bar{x}_A$ und $\bar{x}_B$ von *zwei unabhängigen Gruppen A und B* |  $z=\frac{\bar{x}_A-\bar{x}_B}{se}=\frac{\Delta \bar{x}}{se}$  |$\sigma_A, \sigma_B$ |$se=\sqrt{\frac{\sigma_A^2}{n_A}+\frac{\sigma_B^2}{n_B}}$|

: {tbl-colwidths="[35, 22, 13, 30]"}
