{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Vorlesung 11: Signifikanztestung\"\n",
        "---"
      ],
      "id": "c2cb7983"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## {.blackslide .center}\n",
        "\n",
        "<div class=\"vspace-small\"></div>\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"68%\"}\n",
        "Kurze Zwischenbilanz: Sie haben Mittelwertsunterschiede zwischen Paradoxikern und Kontrollen sowohl für TikTok-Online-Zeit gefunden, als auch für Entzündungswerte (allerdings mit einer geringeren Effektstärke). Dazu gibt es einen mysteriösen Zusammenhang zwischen beiden abhängigen Variablen: mehr TikTok-Zeit = höherer Entzündungswert.\n",
        "\n",
        ":::\n",
        "::: {.column width=\"32%\"}\n",
        "::: {.content-hidden when-format=\"pdf\"}\n",
        "![](images/paradoxia_group_of_scientists.png){.hcenter-image height=200px style=\"margin-top:-20px !important\"}\n",
        "<!-- Source: Midjourney -->\n",
        ":::\n",
        ":::\n",
        "::::\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"62%\"}\n",
        "![](images/paradoxia_histogram_inflammation_mean_std.png){height=260px}\n",
        ":::\n",
        "::: {.column width=\"38%\"}\n",
        "![](images/paradoxia_histogram_correlation_paradoxiker.png){height=260px}\n",
        ":::\n",
        "::::\n",
        "\n",
        "<div class=\"vspace-medium\"></div>\n",
        "\n",
        "Die finale Frage lautet nun: welcher dieser Effekte ist [**statistisch signifikant**]{color=\"lightblue\"} und welcher Effekt ist vermutlich eher eine Zufallsbeobachtung?\n",
        "\n",
        "\n",
        "\n",
        "## Der Forschungsprozess {.hcenter-slide}\n",
        "\n",
        "```yaml { .animate src=\"images/scientific_process.svg\"}\n",
        "setup:\n",
        "    - element: \"#inference\"\n",
        "      modifier: function() { this.node.style.fill = 'green'; }\n",
        "    - element: \"#inferencebg\"\n",
        "      modifier: function() { this.node.style.fill = '#d8ffe2';}\n",
        "```\n",
        "\n",
        "\n",
        "## Theoretische Stichprobenverteilung\n",
        "\n",
        "<div class=\"vspace-small\"></div>\n",
        "\n",
        "\n",
        "Zurück zur **theoretischen Stichprobenverteilung**. Alle Erkenntnisse über die Normalverteilung lassen sich auch auf die theoretische Stichprobenverteilung übertragen. Dies wird uns bis zum Ende des Semesters zwei wesentliche Methoden der Inferenzstatistik eröffnen:\n",
        "\n",
        "- [**Hypothesentestung** bzw. **Signifikanztestung** (u.a. auch Idee des p-Wertes)]{color=\"navy\"}\n",
        "- **Konfidenzintervalle** (Verallgemeinerung des Standardfehlers)\n",
        "\n",
        "<div class=\"vspace-medium\"></div>\n",
        "\n",
        "![](images/stichprobenverteilung.png){height=350px}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Signifikanztestung{.center}\n",
        "\n",
        "<div class=\"vspace-medium\"></div>\n",
        "Ziel der **Signifikanztestung** ist zu klären, ob ein Effekt wahrscheinlich durch Zufall erklärt werden kann (und daher statistisch unbedeutsam ist) *oder* Zufall als alleinige Ursache unwahrscheinlich ist (und der Effekt daher statistisch bedeutsam &mdash; signifikant &mdash; ist).\n",
        "\n",
        "Signifikanztests bieten ein Kriterium, um wissenschaftliche **Hypothesen** zu überprüfen. Dabei unterscheidet man zwischen zwei Arten von Hypothesen &#9112;\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Nullhypothese und Alternativhypothese\n",
        "\n",
        "**Nullhypothese ($H_0$)**\n",
        "\n",
        "Besagt, dass ein bestimmter Effekt *nicht vorliegt*.\n",
        "\n",
        "- Die Häufigkeit des Haarschneidens und Haardichte **hängen nicht** zusammen.\n",
        "- Männer und Frauen **unterscheiden sich nicht** in ihrer emotionalen Intelligenz.\n",
        "\n",
        "**Alternativhypothese ($H_1$)**\n",
        "\n",
        "Besagt, dass ein bestimmter Effekt *vorliegt*.\n",
        "\n",
        "- Die Häufigkeit des Haarschneidens und Haardichte **hängen** zusammen.\n",
        "- Männer und Frauen **unterscheiden sich** in ihrer emotionalen Intelligenz.\n",
        "\n",
        "![](images/null-and-alternate-hypothesis.jpg)\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Nullhypothese und Alternativhypothese: Beispiel\n",
        "\n",
        "<div class=\"vspace-medium\"></div>\n",
        "\n",
        "![Bildnachweis^[https://www.majordifferences.com/2016/10/5-differences-between-null-and.html]](images/example_null_alternate.jpg)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Nullhypothesentestung nach Fisher\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"73%\"}\n",
        "\n",
        "- Betrachtet wird [ausschließlich]{.underline} die Nullhypothese.\n",
        "- Ziel ist es zu zeigen, dass das **Stichproben-Ergebnis unter der Annahme dieser Nullhypothese so unwahrscheinlich ist, dass man die Nullhypothese „verwerfen“ kann**.\n",
        "- Bei der Nullhypothesentestung wird kein Schluss in Bezug auf eine Alternativhypothese gezogen (sie der muss hier nicht einmal formuliert werden!).\n",
        "\n",
        ":::\n",
        "::: {.column width=\"27%\"}\n",
        "![Ronald Aylmer Fisher (1890-1962)](images/portrait_fisher.png)\n",
        "\n",
        ":::\n",
        "::::\n",
        "\n",
        "::: {.merke}\n",
        ":::: {.columns}\n",
        "::: {.column width=\"5%\"}\n",
        "::: {style=\"margin-top: 18px\"}\n",
        "![](images/merke.png){height=\"55px\"}\n",
        ":::\n",
        ":::\n",
        "::: {.column width=\"95%\"}\n",
        "Merke: bei Signifikanztests werden keine Wahrscheinlichkeiten für Hypothesen berechnet (weder $H_0$ noch $H_1$), sondern nur die Wahrscheinlichkeit von Daten unter einer Hypothese (bei Fisher: *unter der Nullhypothese*). \n",
        "\n",
        "Die Wahrscheinlichkeit von Daten, gegeben eine Hypothese, heißt auch **Likelihood**.\n",
        ":::\n",
        "::::\n",
        ":::\n",
        "\n",
        "<div class=\"vspace-medium\"></div>\n",
        "\n",
        "Wie kann diese \"Wahrscheinlichkeit der Daten unter der Nullhypothese\" bestimmt werden? \n",
        "\n",
        "&rarr; **p-Wert** &#9112;\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Nullhypothesentestung nach Fisher: p-Wert\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"80%\"}\n",
        "\n",
        "Sie überprüfen die Hypothese, dass Medizinstudierende längere Nasen haben als Psychologiestudierende (Lügen macht eine lange Nase und so ;-)). \n",
        "\n",
        "Die zugehörige Nullhypothese $H_0$ lautet also: *kein Unterschied in der (durchschnittlichen) Nasenlänge von Medizin- und Psychologiestudierenden.*\n",
        "\n",
        "Sie führen eine Studie durch ($N_\\text{med}=N_\\text{psych}=N=30$) und messen folgenden Gruppenunterschied: \n",
        "\n",
        "$$\n",
        "\\Delta \\bar{X} = \\bar{X}_\\text{med} - \\bar{X}_\\text{psych} = 0{,}2cm\n",
        "$$\n",
        "\n",
        "<div class=\"vspace-small\"></div>\n",
        "\n",
        ":::{style=\"margin-top: -20px\"}\n",
        "**Nach Fisher stellen wir nun folgende präzise Frage: **\n",
        ":::\n",
        "\n",
        ":::{style=\"font-family: monospace; margin-left: 30px; margin-right: 10px !important;font-size: 25px; margin-top: -5px\"}\n",
        "Angenommen, die Nasenlänge unterscheidet sich nicht zwischen den Gruppen ($H_0$). Wie wahrscheinlich ist unter diese Annahme das Ergebnis unserer Daten *oder ein noch extremeres Ergebnis*? \n",
        ":::\n",
        "\n",
        "**In kurz: **\n",
        "\n",
        ":::{style=\"font-family: monospace; margin-left: 30px; margin-right: 0px;;font-size: 25px; margin-top: -5px\"}\n",
        "Angenommen $H_0$ trifft zu und es gilt $\\Delta \\bar{X}=0$, wie wahrscheinlich ist es dennoch $\\Delta \\bar{X} \\ge 0{,}2cm$ zu messen?\n",
        ":::\n",
        "\n",
        ":::\n",
        "::: {.column width=\"20%\"}\n",
        "![](images/psych_med.png)\n",
        ":::\n",
        "::::\n",
        "\n",
        "<div class=\"vspace-xsmall\"></div>\n",
        "\n",
        "Diese Wahrscheinlichkeit wird als [**p-Wert**]{color=\"navy\"} bezeichnet (*p* für *probability*).\n",
        "\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## p-Wert und Konstruktion der Nullhypothese\n",
        "\n",
        "Wir definieren:\n",
        "\n",
        "::: {.definition}\n",
        "<!---  Definition--->\n",
        "|||\n",
        "|:-:|-|\n",
        "|||\n",
        "| ![](images/definition.svg){height=70px} | Der **p-Wert** ist die Wahrscheinlichkeit den Stichprobeneffekt *oder einen noch extremeren Effekt zu erhalten*, obwohl für die Population die Nullhypothese angenommen wird. | \n",
        "|||\n",
        ": {tbl-colwidths=\"[10, 90]\"}\n",
        ":::\n",
        "\n",
        "Um diese Wahrscheinlichkeit zu berechnen, benötigen wir die Wahrscheinlichkeitsverteilung aller verschiedenen möglichen Stichprobeneffekten *unter der Annahme der Nullhypothese*. &#9112;\n",
        "\n",
        "<div class=\"vspace-small\"></div>\n",
        "\n",
        "![](images/nulldist2b.png){height=350px}\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Konstruktion der Nullhypothese\n",
        "\n",
        "-  Das Ziel \"die Wahrscheinlichkeitsverteilung aller verschiedenen möglichen Stichprobeneffekten unter der Annahme der Nullhypothese\" zu finden, impliziert, dass wir auch hier eine Art von **Stichprobenverteilung** suchen.\n",
        "- Da wir mithilfe der Inferenzstatistik **Effekte** testen wollen, sind hier im Besonderen Stichprobenverteilung von Effekten gemeint.\n",
        "- Zu Beginn konzentrieren wir uns hier auf den Effekt des **Mittelwertsunterschiedes**.\n",
        "- Wichtig ist hier ein weiteres Mal die Feststellung, dass per zentralem Grenzwertsatz nicht nur die Stichprobenverteilung des Mittelwertes per se normalverteilt ist, sondern auch die Stichprobenverteilung von *Mittelwertsunterschieden* (die Differenz zweier normalverteilter Variablen ist normalverteilt).\n",
        "- \n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Konstruktion der Nullhypothese\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"66%\"}\n",
        "\n",
        "Wie schon bei der Konstruktion der Stichprobenverteilung, benötigen wir für die Konstruktion der Nullhypothesenverteilung drei Informationen: Form, Mittelwert und Streuung der Verteilung. \n",
        "\n",
        "- Für die **Form** können wir uns wieder auf den zentralen Grenzwertsatz beziehen und eine **Normalverteilung** annehmen.\n",
        "- Der **Mittelwert** ist auch klar, für die Nullhypothesenverteilung muss er **Null** sein (bzw. das, was als Nulleffekt definiert wird).\n",
        "- Bei der **Streuung** stoßen wir allerdings auf ein Problem: wir kennen nur die **Streuung unseres Effektes auf Basis Stichprobe** und wissen, dass dies eine **unpräzise Schätzung der Streuung in der Population** ist.\n",
        ":::\n",
        "::: {.column width=\"34%\"}\n",
        "![](images/nulldist2a.png)\n",
        "\n",
        "<div class=\"vspace-medium\"></div>\n",
        "\n",
        "$$\n",
        "f(x)=\\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^2}\n",
        "$$\n",
        "\n",
        "::: {.caption-style}\n",
        "Formel für die Dichtefunktion der **unstandardisierten Normalverteilung** mit Mittelwert $\\mu$ und Standardabweichung $\\sigma$.\n",
        ":::\n",
        "\n",
        ":::\n",
        "::::\n",
        "\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Vereinfachung: Populationsstreuungen $\\sigma$ bekannt\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"65%\"}\n",
        "\n",
        "Im ersten Schritt betrachten wir daher den vereinfachten (in der Praxis sehr seltenen) Fall, dass wir die Streuung $\\sigma_\\text{med}$ und $\\sigma_\\text{psych}$ in den beiden Populationen der Medizin und Psychologie kennen, und damit den Standardfehler $SE$ unseres Effektes $\\Delta X$: \n",
        "\n",
        "$$\n",
        "SE=\\sqrt{\\frac{\\sigma_\\text{med}^2+\\sigma_\\text{psych}^2}{N}}\n",
        "$$\n",
        "\n",
        "Hinweis: dies ist die Formel für den Standardfehler des Differenzeffektes $\\bar{x}_\\text{med}-\\bar{x}_\\text{psych}$. Nehmen wir an, der Standardfehler ergibt sich nach dieser Formel zu $SE=0{,}1$. \n",
        "\n",
        "Nun ist alles angerichtet und wir können unseren ersten p-Wert berechnen! Dazu muss die Fläche unter der Nullhypothesenverteilung [rechts]{.underline} von $\\Delta\\bar{x}=\\bar{x}_\\text{med}-\\bar{x}_\\text{psych}$ berechnet werden (Erinnerung: wir sind an der Wahrscheinlichkeit interessiert, dass die Daten unseren Effekt annehmen *oder einen noch größeren Effekt*).\n",
        "\n",
        ":::\n",
        "::: {.column width=\"34%\"}\n",
        "![](images/nulldist2c.png)\n",
        "<div class=\"vspace-medium\"></div>\n",
        "![](images/nulldist2d.png)\n",
        ":::\n",
        "::::\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Vereinfachung: Populationsstreuungen $\\sigma$ bekannt\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"65%\"}\n",
        "\n",
        "Die Fläche bzw. der p-Wert berechnet sich wie folgt:\n",
        "$$\n",
        "\\begin{aligned}\n",
        "p &= \\int_{\\Delta\\bar{x}}^{\\infty}f(x)dx = 1 - F(\\Delta\\bar{x}) = \\\\\n",
        "&= 1 - F(0{,}2) \\overset{(Computer)}{=} 0{,}023\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "wobei $f(x)$ bzw. $F(x)$ hier die Dichte bzw. Verteilunsfunktion der gebenen Normalverteilung $\\mathcal{N}(0, 0{,}1)$ ist.\n",
        "\n",
        "$F(x)$ berechnet die Fläche bis zum Punkt $x$, \"1 minus diese Fläche\" gibt uns also die Fläche rechts vom angebenen Punkt $x$ &mdash; im vorliegenden Fall die Fläche rechts von $\\Delta\\bar{x}=\\bar{x}_\\text{med}-\\bar{x}_\\text{psych}=0{,}2$.\n",
        "\n",
        "Der p-Wert ist 0,023. \n",
        "\n",
        ":::\n",
        "::: {.column width=\"34%\"}\n",
        "![](images/nulldist2d.png)\n",
        ":::\n",
        "::::\n",
        "\n",
        "\n",
        "In Worten können wir feststellen: die Wahrscheinlichkeit, dass unser Effekt $\\Delta\\bar{x}$ durch Zufall entstanden ist &mdash; also unter der Annahme, dass die Nullhypothese gilt &mdash; beträgt (nur) 2,3%.\n",
        "\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Standardfehler bei Mittelwertdifferenzen\n",
        "\n",
        "[**Messungen in unabhängigen Gruppen mit unterschiedlichen Varianzen**]{.underline}\n",
        "\n",
        "Sind die Standardabweichungen in beiden Gruppen unterschiedlich (Faustregel: um mehr als einen Faktor 2), kann keine gepoolte Standardabweichung für beide Gruppen berechnet werden, und die Standardfehler werden für beide Gruppen separat berechnet:\n",
        "\n",
        ":::{style=\"margin-top: -8px\"}\n",
        "$$\n",
        "SE_A = \\frac{\\sigma_A}{\\sqrt{N_A}}\\qquad\\qquad SE_B = \\frac{\\sigma_B}{\\sqrt{N_B}}\n",
        "$$\n",
        ":::\n",
        "\n",
        "Die Varianzen der Mittelwerte in beiden Gruppen sind gleich dem quadrierten Standardfehler der Mittelwerte:\n",
        "\n",
        ":::{style=\"margin-top: -40px\"}\n",
        "$$\n",
        "SE_A^2 = \\frac{\\sigma_A^2}{N_A}\\qquad\\qquad SE_B^2 = \\frac{\\sigma_B^2}{N_B}\n",
        "$$\n",
        ":::\n",
        "\n",
        "Nun sind wir ja an der Differenz der Mittelwerte $\\Delta\\bar{X}$ interessiert. Allgemein gilt, dass sich die Varianzen von Summen oder Differenz zweier unabhängiger Zufallsvariablen addieren:\n",
        "\n",
        "$$\n",
        "SE_{\\Delta\\bar{X}}^2 = \\frac{\\sigma_A^2}{N_A} + \\frac{\\sigma_A^2}{N_B}\n",
        "$$\n",
        "\n",
        "\n",
        "Daher gilt für den **Standardfehler der Mittelwertsdifferenz unabhängiger Gruppen A und B**:\n",
        "\n",
        "$$\n",
        "SE_{\\Delta\\bar{X}} = \\sqrt{\\frac{\\sigma_A^2}{N_A} + \\frac{\\sigma_A^2}{N_A}}\n",
        "$$\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Standardfehler bei Mittelwertdifferenzen\n",
        "\n",
        "[**Messungen in unabhängigen Gruppen mit ähnlichen Varianzen**]{.underline}\n",
        "\n",
        "Gilt $\\frac{1}{2}<\\frac{\\sigma_A}{\\sigma_B}<2$, die Standardabweichungen sind also ähnlich, wird der Standardfehler auf Basis der gepoolten Standardabweichung berechnet:\n",
        "\n",
        "$$\n",
        "SE_{\\Delta\\bar{X}} = \\sigma_\\text{pooled}\\sqrt{\\frac{1}{N_A} + \\frac{1}{N_B}}\\qquad\\text{mit}\\qquad \\sigma_\\text{pooled} = \\sqrt{\\frac{N_A\\sigma^2_A + N_B\\sigma^2_B}{N_A+N_B}}\n",
        "$$\n",
        "\n",
        "\n",
        "[**Messungen in abhängigen Bedingungen einer Gruppe**]{.underline}\n",
        "\n",
        "Zur Herleitung des Standardfehlers der Mittelwertdifferenz zweier abhängiger Messungen A und B *in einer Stichprobe* können wir die Variablen $X_A$ und $X_B$ im ersten Schritt direkt voneinander abziehen:\n",
        "\n",
        "$$\n",
        "\\Delta X = X_A - X_B\n",
        "$$\n",
        "\n",
        ".. und mit der Standardformel die Standardabweichung $\\sigma_\\Delta$ dieser Differenz berechnen. \n",
        "\n",
        "Der Standardfehler der Mittelwertsdifferenz abhängiger Bedingungen A und B ergibt sich daher bei einer Stichprobengröße $N$ als:\n",
        "\n",
        "$$\n",
        "SE_{\\Delta\\bar{X}} = \\frac{\\sigma_\\Delta}{\\sqrt{N}}\\qquad\\text{mit}\\qquad \\sigma_\\Delta=\\sqrt{\\frac{1}{N}\\sum\\left(\\Delta x_i-\\Delta\\bar{X}\\right)^2}\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Standardfehler bei Mittelwertdifferenzen: Cheat sheet\n",
        "\n",
        "<!---  Table --->\n",
        "|Fall|Berechnung des Standardfehlers $SE$|\n",
        "|-|-|\n",
        "| **Differenz des Mittelwertes [einer Gruppe]{.underline} und einem Referenzwert** $\\mu_0$  | $SE_{\\Delta\\bar{X}} = \\frac{\\sigma}{\\sqrt{N}}$ |\n",
        "| **Mittelwertdifferenz zweier Bedingungen A und B in [einer Gruppe]{.underline}** | $SE_{\\Delta\\bar{X}} = \\frac{\\sigma_\\Delta}{\\sqrt{N}}\\qquad\\text{mit}$ \\\n",
        "$\\scriptsize{\\sigma_\\Delta=\\sqrt{\\frac{1}{N}\\sum\\left(\\Delta x_i-\\Delta\\bar{X}\\right)^2}\\qquad\\text{oder}\\qquad \\sigma_\\Delta=\\sqrt{\\sigma_A^2+\\sigma_B^2-2\\,Cov(X_A,X_B)}}$ |\n",
        "| **Mittelwertdifferenz [zweier unabhängiger Gruppen]{.underline} A und B (ähnliche Varianzen)** | $SE_{\\Delta\\bar{X}} = \\sigma_\\text{pooled}\\sqrt{\\frac{1}{N_A} + \\frac{1}{N_B}}\\qquad\\text{mit}\\qquad \\sigma_\\text{pooled} = \\sqrt{\\frac{N_A\\sigma^2_A + N_B\\sigma^2_B}{N_A+N_B}}$ |\n",
        "| **Mittelwertdifferenz [zweier unabhängiger Gruppen]{.underline} A und B (unterschiedliche Varianzen)** | $SE_{\\Delta\\bar{X}} = \\sqrt{\\frac{\\sigma_A^2}{N_A} + \\frac{\\sigma_A^2}{N_A}}$ |\n",
        "\n",
        ":  {tbl-colwidths=\"[40, 50]\"}\n",
        "\n",
        "<div class=\"vspace-medium\"></div>\n",
        "\n",
        "::: {.merke}\n",
        ":::: {.columns}\n",
        "::: {.column width=\"5%\"}\n",
        "::: {style=\"margin-top: 18px\"}\n",
        "![](images/merke.png){height=\"55px\"}\n",
        ":::\n",
        ":::\n",
        "::: {.column width=\"95%\"}\n",
        "Dieses Cheat sheet gilt für den Fall, dass die **Varianzen $\\sigma_A^2$ bzw. $\\sigma_B^2$ in den Populationen bekannt sind**! Falls dies nicht der Fall ist, sehen die Formeln aufgrund der Besselkorrektur subtil anders aus (vgl. Vorlesung 12).\n",
        ":::\n",
        "::::\n",
        ":::\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Stichprobenverteilungen von Mittelwertdifferenzen\n",
        "\n",
        "<div class=\"vspace-small\"></div>\n",
        "![](images/stichprobenverteilung_diff.png)\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## z-Test\n",
        "\n",
        "In der Praxis wird die Berechnung von p-Werten um das Konzept der [**standardisierten Prüfgröße**]{color=\"navy\"} erweitert. \n",
        "\n",
        "- Um das Konzept zu verstehen, erinnern wir uns, dass wir im Beispiel eine Fläche unter der Normalverteilung $\\mathcal{N}(0, 0{,}1)$ berechnet haben. Für die nächste statistische Analyse müssten wir sehr wahrscheinlich die Fläche unter einer Normalverteilung mit einer anderen Streuung als $0{,}1$ berechnen.\n",
        "- Gerade im Vorcomputerzeitalter war die Berechnung von Flächen unter beliebigen Normalverteilungen eine Herausforderung.\n",
        "- Abhilfe schafft die **Standardisierung** des Effektes:\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"65%\"}\n",
        "\n",
        ":::{style=\"margin-top: -20px\"}\n",
        "$$\n",
        "Z = \\frac{\\Delta\\bar{X}}{SE}\n",
        "$$\n",
        ":::\n",
        "\n",
        "Nach Teilen von $\\Delta\\bar{X}$ durch die Streuung $SE$, hat die Nullverteilung nicht mehr die Streuung $SE$, sondern *immer* die Streuung $\\frac{SE}{SE}=1$!\n",
        "\n",
        ":::\n",
        "::: {.column width=\"34%\"}\n",
        "![](images/nulldist2e.png){style=\"margin-top:-80px !important\"}\n",
        ":::\n",
        "::::\n",
        "\n",
        "$Z$ wird als **standardisierte Prüfgröße** bezeichnet, während der einfache Effekt $\\Delta X$ eine **unstandardisierte Prüfgröße** darstellte.\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## z-Test\n",
        "\n",
        "Es gibt auch im Computerzeitalter noch Vorteile für diese Art der Standardisierung:\n",
        "\n",
        "- Der resultierende Z-Wert ist vergleichbar zwischen Studien, im Gegensatz zum Mittelwertsunterschied $\\Delta \\bar{X}$, der von der spezifischen Skala abhängt.\n",
        "- Der Z-Wert hat eine intuitive Interpretation: er gibt an, *wie viele Standardabweichungen der Effekt vom Mittelwert der angenommenen (Null-)Normalverteilung entfernt ist*.\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"65%\"}\n",
        "\n",
        "\n",
        "Mit dem Z-Wert als Prüfgröße benötigten wir also für alle Tests dieser Art nur noch eine einzige Verteilung &mdash; die Normalverteilung mit Mittelwert $0$ und Streuung $1$. Man bezeichnet sie als [**Standardnormalverteilung**]{color=\"navy\"}:\n",
        "\n",
        "<div class=\"vspace-small\"></div>\n",
        "\n",
        "\n",
        "$$\n",
        "f(x)=\\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^2}\\quad\\underset{\\sigma=1}{\\overset{\\mu=0}{=}}\\quad\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{x^2}{2}}\n",
        "$$\n",
        "\n",
        "<!-- $$\n",
        "\\text{Standardnormalverteilung:}\\qquad X \\sim \\mathcal{N}(0, 1)\n",
        "$$ -->\n",
        "\n",
        ":::\n",
        "::: {.column width=\"34%\"}\n",
        "![](images/nulldist2e.png)\n",
        ":::\n",
        "::::\n",
        "\n",
        "Die Art der Berechnung des p-Wertes ändert sich nicht &mdash; wir berechnen in unserem Beispiel weiterhin die Fläche rechts von unserem Effekt, nur dass der \"Effekt\" jetzt standardisiert und als $Z = \\frac{\\Delta\\bar{X}}{SE} = \\frac{\\bar{X}_\\text{med}-\\bar{X}_\\text{psych}}{SE}$ definiert ist. Der resultierende p-Wert ist derselbe.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Einschub: Das ABC der Normalverteilung\n",
        "\n",
        "Aufgrund ihrer Bedeutung in der Statistik, haben sich für die (Standard)Normalverteilung bestimmte Bezeichnung eingebürgert, auf die wir ab jetzt zugreifen werden.\n",
        "\n",
        "<!---  Table --->\n",
        "|||\n",
        "|-|-|\n",
        "| **Normalverteilung mit Angabe des Mittelwertes $\\mu$ und der Varianz $\\sigma^2$** | $\\mathcal{N}(\\mu, \\sigma^2)$ |\n",
        "| **Standardnormalverteilung (Mittelwert 0, Varianz 1)** | $\\mathcal{N}(0, 1)$ |\n",
        "| **Dichtefunktion der Normalverteilung** | $f(x)=\\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^2}$ |\n",
        "| **Dichtefunktion der Standardnormalverteilung** | $\\varphi(x)=\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{1}{2}x^2}$  (sprich \"Klein Phi\") \\\n",
        "Es gilt: $\\quad f(x) = \\frac{1}{\\sigma}\\varphi\\left(\\frac{x-\\mu}{\\sigma}\\right)$ |\n",
        "| **Verteilungsfunktion der Normalverteilung** | $F(x)=\\frac{1}{\\sigma\\sqrt{2\\pi}}\\int_{-\\infty}^x e^{-\\frac{1}{2}\\left(\\frac{x'-\\mu}{\\sigma}\\right)^2}dx\\qquad$ |\n",
        "| **Verteilungsfunktion der Standardnormalverteilung** | $\\Phi(x)=\\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^x e^{-\\frac{1}{2}x'^2}dx\\qquad$ (sprich \"Groß Phi\") \\\n",
        "Es gilt: $\\quad F(x) = \\Phi\\left(\\frac{x-\\mu}{\\sigma}\\right)$ |\n",
        "\n",
        ": {tbl-colwidths=\"[47, 50]\"}\n",
        "\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## z-Test\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"66%\"}\n",
        "\n",
        "Berechnen wir nun den p-Wert im Nasenlängenbeispiel mithilfe des z-Tests. \n",
        "\n",
        "Wir bestimmen die standardisierte Prüfgröße $Z$:\n",
        "\n",
        "$$\n",
        "Z = \\frac{\\Delta\\bar{X}}{SE} = \\frac{0{,}2}{0{,}1} = 2\n",
        "$$\n",
        "\n",
        "Und berechnen die Fläche rechts von $Z$:\n",
        "\n",
        "$$\n",
        "p=\\int_{Z}^{\\infty}\\varphi(x)dx = 1 - \\Phi(Z) = 1 - \\Phi(2) \\overset{(Computer)}{=} 0{,}023\n",
        "$$\n",
        ":::\n",
        "::: {.column width=\"34%\"}\n",
        "![](images/nulldist2f.png)\n",
        ":::\n",
        "::::\n",
        "\n",
        "\n",
        "Beachte, dass wir hier statt $f(x)$ die Nomenklatur $\\varphi(x)$ für die Dichte der Standardnormalverteilung verwenden, und statt $F(x)$ den Ausdruck $\\Phi(x)$ für die Verteilungsfunktion der Standardnormalverteilung.\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## z-Test\n",
        "\n",
        "Der Signifikanztest auf Basis der Standardnormalverteilung &mdash; und bei bekannten Streuungen in den relevanten Populationen &mdash; wird als [**Z-test**]{color=\"navy\"} bezeichnet.\n",
        "\n",
        "Der Z-Test kann auf alle Arten von Mittelwertsvergleichen angewendet werden:\n",
        "\n",
        "<!---  Table --->\n",
        "|Fall|Z-Wert|Bekannt|Berechnung von $SE$|\n",
        "|-|-|:-:|-|\n",
        "| **Einzelmessung:** Vergleich von $\\bar{X}$ mit einem Referenzwert $\\mu_0$ | $Z=\\frac{\\bar{X}-\\mu_0}{SE}$ |$\\sigma$|$SE=\\sigma_{\\bar{X}}=\\frac{\\sigma}{\\sqrt{N}}$|\n",
        "| **Abhängige Messungen:** Vergleich der Mittelwerte $\\bar{X}_A$ und $\\bar{X}_B$ von *zwei Bedingungen A und B in einer Gruppe* | $Z=\\frac{\\bar{X}_A-\\bar{X}_B}{SE}=\\frac{\\Delta \\bar{X}}{SE}$ |$\\sigma_A, \\sigma_B$<br>$\\scriptsize{Cov(X_A,X_B)}$|$SE=\\sqrt{\\frac{\\sigma_A^2+\\sigma_B^2-2\\,Cov(X_A,X_B)}{N}}$|\n",
        "| **Unabhängige Messungen:** Vergleich der Mittelwerte $\\bar{X}_A$ und $\\bar{X}_B$ von *zwei unabhängigen Gruppen A und B* |  $Z=\\frac{\\bar{X}_A-\\bar{X}_B}{SE}=\\frac{\\Delta \\bar{X}}{SE}$  |$\\sigma_A, \\sigma_B$ |$SE=\\sqrt{\\frac{\\sigma_A^2}{N_A}+\\frac{\\sigma_B^2}{N_B}}$|\n",
        "\n",
        ": {tbl-colwidths=\"[35, 22, 13, 30]\"}\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Einstichprobentest versus Zweistichprobentest\n",
        "\n",
        "Statistische Tests, die sich auf eine Stichprobe beziehen (Einzelmessung oder Vergleich zweier abhängiger Messungen) werden auch als [**Einstichprobentest**]{color=\"navy\"} bezeichnet.\n",
        "\n",
        "Beispielhypothesen für den Einstichprobentest:\n",
        "\n",
        "- Einzelmessung: Psychologiestudierende sind überdurchschnittlich intelligent &numsp;($\\overline{IQ} > 100$)\n",
        "    - Nullhypothese: $\\overline{IQ} = 100$\n",
        "    - Beachte: $\\mu_0$ ist in diesem Fall 100 und nicht 0!\n",
        "- Vergleich zweier abhängiger Messungen: Psychologiestudierende sind morgens intelligenter als abends &numsp;($\\overline{IQ}_\\text{Morgen} > \\overline{IQ}_\\text{Abend}$)\n",
        "    - Nullhypothese: $\\overline{IQ}_\\text{Morgen} - \\overline{IQ}_\\text{Abend} = \\Delta \\overline{IQ} = 0$\n",
        "\n",
        "Demgegenüber werden statistische Tests, die sich auf zwei unabhängige Stichproben beziehen als [**Zweistichprobentest**]{color=\"navy\"} bezeichnet:\n",
        "\n",
        "Beispielhypothese für den Zweistichprobentest:\n",
        "\n",
        "- Studierende der HMU sind intelligenter als Studierende der MSB &numsp;($\\overline{IQ}_\\text{HMU} > \\overline{IQ}_\\text{MSB}$)\n",
        "    - Nullhypothese: $\\overline{IQ}_\\text{HMU} - \\overline{IQ}_\\text{MSB} = \\Delta \\overline{IQ} = 0$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Signifikanzniveau ($p < \\alpha$ ?)\n",
        "\n",
        "Bislang haben wir die Berechnung des p-Wertes besprochen, aber noch nicht, wie klein der p-Wert sein sollte, um die Nullhypothese abzulehnen (und im Umkehrschluss den Effekt als signifikant zu werten).\n",
        "\n",
        "Um diese Entscheidung zu treffen, legen wir ein [**Signifikanzniveau**]{color=\"navy\"} $\\alpha$ fest. **Unterschreitet der p-Wert das Signifikanzniveau $\\alpha$**, **lehnen wir die Nullhypothese ab** und werten den **Effekt als statistisch signifikant**.\n",
        "\n",
        "Der Wert $\\alpha$ wird auch als [**Irrtumswahrscheinlichkeit**]{color=\"navy\"} bezeichnet. Ist beispielsweise $\\alpha=0{,}1$ so wären wir bereit einen p-Wert von $p<0.1$ als signifikant zu werten, gehen dabei aber ein 10%-iges Risiko ein, dass die Nullhypothese in Wahrheit doch korrekt ist. D.h. wir nehmen in Kauf, dass wir uns mit 10% Wahrscheinlichkeit irren und fälschlicherweise die Nullhypothese ablehnen.\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"50%\"}\n",
        "\n",
        "Auf welchen Wert das Signifikanzniveau festgelegt werden sollte ist seit langer Zeit Gegenstand von kontroversen Debatten in der Psychologie. Als de facto Standard-Signifikanzniveau hat sich jedoch der [**Wert $\\color{navy}{\\alpha=0{,}05}$**]{color=\"navy\"} eingebürgert.\n",
        "\n",
        "\n",
        ":::\n",
        "::: {.column width=\"50%\"}\n",
        "![](images/significance_level.png){style=\"margin-top:-45px !important\"}\n",
        ":::\n",
        "::::\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Ein- und zweiseitiges Testen\n",
        "\n",
        "- Im Nasenlängenbeispiel haben wir bislang eine [**gerichtete Hypothese betrachtet**]{color=\"navy\"}, indem wir bei der Hypothese festgelegt haben, welche der beiden Gruppen durchschnittlich eine längere Nase hat (Med-Nasenlänge > Psych-Nasenlänge oder $\\Delta\\bar{X}>0$).\n",
        "- Wir hätten auch die **umgekehrte gerichtete Hypothese** betrachten können:<br>Med-Nasenlänge < Psych-Nasenlänge oder $\\Delta\\bar{X}<0$\n",
        "- Eine [**ungerichtete Hypothese**]{color=\"navy\"} gibt dagegen keine Richtung vor, d.h. die Hypothese würde schlicht lauten: Med-Nasenlängen und Psych-Nasenlängen sind **unterschiedlich**.\n",
        "\n",
        "Dies wirkt sich auf die Flächen unter der Nullverteilung aus, die wir betrachten:\n",
        "\n",
        "<div class=\"vspace-small\"></div>\n",
        "\n",
        "![](images/nulldist2g.png)\n",
        "\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Ein- und zweiseitiges Testen\n",
        "\n",
        "<div class=\"vspace-small\"></div>\n",
        "\n",
        "![](images/nulldist2g.png)\n",
        "\n",
        "Wie sehen folgende Zusammenhänge:\n",
        "\n",
        "- Die **p-Werte der beiden gerichteten Hypothesen** (\"größere als\" oder \"kleiner als\") sind genau **invers**:\n",
        "\n",
        ":::{style=\"margin-top: -20px\"}\n",
        "$$\n",
        "p(\\bar{X}_\\text{med} > \\bar{X}_\\text{psych}) = 1 - p(\\bar{X}_\\text{med} < \\bar{X}_\\text{psych})\n",
        "$$\n",
        ":::\n",
        "\n",
        "- Der **p-Wert der ungerichteten Hypothese** (\"unterschiedlich\") ist gleich **2 x der kleinere p-Wert der beiden gerichteten Hypothesen**:\n",
        "\n",
        "$$\n",
        "p(\\bar{X}_\\text{med} \\neq \\bar{X}_\\text{psych}) = 2 \\times min\\left(p(\\bar{X}_\\text{med} > \\bar{X}_\\text{psych}), p(\\bar{X}_\\text{med} < \\bar{X}_\\text{psych})\\right)\n",
        "$$\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Ein- und zweiseitiges Testen\n",
        "\n",
        "<div class=\"vspace-small\"></div>\n",
        "\n",
        "![](images/nulldist2g.png)\n",
        "\n",
        "Der p-Wert der ungerichteten Hypothese ist damit immer größer (doppelt so groß) wie der kleinere p-Wert der gerichteten Hypothesen.\n",
        "\n",
        "**Intuition:** bei der ungericheteten Hypothese legen wir uns weniger fest, denn unsere Hypothese wäre sowohl erfüllt wenn $\\bar{X}_\\text{med}$ signifikant **größer** ist als $\\bar{X}_\\text{psych}$, als auch wenn $\\bar{X}_\\text{med}$ signifikant **kleiner** ist als $\\bar{X}_\\text{psych}$. Wir machen uns das Leben (bzw. unsere Vorhesagen) also \"einfacher\". \n",
        "\n",
        "Genauer gesagt verdoppeln wir unsere Chance, mit der Hypothese richtig zu liegen, da a priori beide ungerichtete Hypothesen gleich wahrscheinlich sind. Die Verdopplung des p-Wertes kompensiert dies (man könnte auch sagen \"bestraft unsere schwammige Vorhersage\") &mdash; nun wird es schwieriger für p das Signifikanzniveau zu unterschreiten.\n",
        "\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Ein- und zweiseitiges Testen\n",
        "\n",
        "Es ist zusätzlich gewinnbringend, sich den Vergleich von gerichteten und ungerichteten Hypothesen aus der Perspektive des Signifikanzniveaus $\\alpha$ zu betrachten:\n",
        "\n",
        "![](images/significance_level2.png)\n",
        "\n",
        "Beim zweiseitigen Test verteilt sich die Irrtumswahrscheinlichkeit (im Bild 5%) *auf beide Flanken* der Nullverteilung. Es wird damit auf beiden Seiten schwieriger für unseren Effekt einen noch extremeren Wert aufzuweisen, als durch die Irrtumswahrscheinlichkeit vorgegeben.\n",
        "\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## p-Wert versus Stichprobengröße\n",
        "\n",
        "<div class=\"vspace-small\"></div>\n",
        "\n",
        "![Getestet wird, ob der IQ der betrachteten Population (hier $102{,}5$) größer ist, als der Referenzwert $\\mu_0=100$, der idealerweise den durchschnittlichen IQ aller Menschen darstellt. Im Bild ist zu sehen, dass die betrachtete Population (z.B. alle Brandenburger:innen) tatsächlich einen etwas höheren Mittelwert als 100 aufweisen, was sich auch im Stichprobenmittelwert niederschlägt. **Wie verändert sich der p-Wert abhängig davon, ob die Stichprobe $N=10$ oder $N=100$ umfasst?** **Schritt 1:** der Standardfehler $SE$ ist bei der höheren Stichprobenzahl wesentlich kleiner (aufgrund von $\\hat{\\sigma}/\\sqrt{N}$) und damit die Stichprobenverteilung bei $N=100$ wesentlich schmaler. **Schritt 2:** der kleinere Standardfehler wirkt sich auf den z-Wert $z=\\frac{102{,}5}{SE}$ aus: kleinerer Standardfehler bedeutet größerer z-Wert. **Schritt 3:** größerer z-Wert bedeutet kleinerer p-Wert, da kleinere Fläche rechts von z.](images/pwert_fallzahl_annot.png)\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## p-Wert versus Stichprobengröße/Populationsstreuung\n",
        "\n",
        "<div class=\"vspace-medium\"></div>\n",
        "\n",
        "**Gibt es den untersuchten Effekt in der Population tatsächlich (Alternativhypothese wahr), gilt:**\n",
        "\n",
        "- Größere Stichprobengrößen führen im Schnitt zu kleineren p-Werten.\n",
        "- Kleinere Populationsstreuungen führen zu kleineren p-Werten.\n",
        "\n",
        "**Gibt es den untersuchten Effekt in der Population nicht (Nullhypothese wahr), gilt:**\n",
        "\n",
        "- Größere Stichprobengrößen haben keine Auswirkung auf den p-Wert.\n",
        "- Kleinere Populationsstreuungen haben keine Auswirkung auf den p-Wert.\n",
        "- Alle p-Werte sind gleich wahrscheinlich (d.h. p-Werte haben eine uniforme Verteilung auf dem Intervall [0; 1])\n",
        "\n",
        "\n",
        "\n",
        "# Binäres Entscheidungskonzept von Neyman und Pearson\n",
        "\n",
        "## Idee\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"75%\"}\n",
        "\n",
        "- **Alternatives Framework zur Hypothesentestung** von Jerzy Neyman und Egon Pearson\n",
        "- Argument: man ist i.d.R. nicht spezifisch an der Nullhypothese interessiert, sondern möchte einen **Test der zwischen der Nullhypothese $H_0$ und der Alternativhypothese $H_1$ „entscheidet“**.\n",
        "- Im einfachsten Fall legt man dafür eine **minimale Effektstärke** $d_1$ fest, bei der die Alternativhypothese $H_1$ noch praktische oder konzeptionelle Relevanz hätte.\n",
        "\n",
        "![](images/neyman_pearson1.png){height=300px}\n",
        "\n",
        ":::\n",
        "::: {.column width=\"25%\"}\n",
        "\n",
        "![Egon Sharpe Pearson (1895-1980), Sohn von Karl Pearson](images/portrait_pearson_egon.png){width=200px}\n",
        "\n",
        "![Jerzy Neyman (1894-1981)](images/portrait_neyman.jpg){width=200px}\n",
        "\n",
        ":::\n",
        "::::\n",
        "\n",
        "\n",
        "## Idee\n",
        "\n",
        "- Durch das Aufstellen der Alternativhypothese gibt es nun zwei Möglichkeiten sich zu irren:\n",
        "    - Die Nullhypothese ist wahr und man entscheidet sich irrtümlich für die Alternativhypothese<br>(Fehler \"erster Art\" oder α-Fehler).\n",
        "    - Die Alternativhypothese ist wahr und man entscheidet sich irrtümlich für die Nullhypothese<br>(Fehler \"zweiter Art\" oder β-Fehler).\n",
        "- Nehmen wir an, wir legen zur Entscheidung zwischen $H_0$ und $H_1$ einen kritischen Entscheidungswert $z_\\text{crit}$ fest, d.h.\n",
        "    - Entscheidung für $H_0$ und gegen $H_1$ wenn $z\\le z_\\text{crit}$\n",
        "    - Entscheidung gegen $H_0$ und für $H_1$ wenn $z>z_\\text{crit}$\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"50%\"}\n",
        "- ..dann können beide Fehler als Flächen unter den Hypothesenverteilungen eingetragen werden.\n",
        "- α und β sind also Flächeninhalte!\n",
        ":::\n",
        "::: {.column width=\"50%\"}\n",
        "![](images/neyman_pearson2.png)\n",
        ":::\n",
        "::::\n",
        "\n",
        "## Fehler erster und zweiter Art\n",
        "\n",
        "<div class=\"vspace-medium\"></div>\n",
        "\n",
        "![](images/neyman_pearson_table.png)\n",
        "\n",
        "## Fisher versus Neyman/Pearson\n",
        "\n",
        "- Nullhypothesenframework nach Fisher:\n",
        "    - Betrachtet wird nur eine Nullhypothese\n",
        "    - Fokus: p-Wert\n",
        "    - p stellt ein **kontinuierliche** Evidenzmaß dar (je kleiner, desto mehr Evidenz)\n",
        "    - Signifikanztests nach Fisher sind **Ablehnungstests** [(Nullhypothese wird abgelehnt oder nicht, nie angenommen)]{style=\"font-size: 22px !important\"}\n",
        "- Framework nach Neyman und Pearson:\n",
        "    - Betrachtet wird sowohl eine Null- als auch eine Alternativhypothese\n",
        "    - Fokus: liegt die Prüfgröße rechts oder links von der kritischen Prüfgröße $z_\\text{crit}$? (bzw. allgemeiner $T_\\text{crit}$ für die kritische Testgröße, da nicht immer ein z-Test verwendet wird).\n",
        "    - Binäres Entscheidungskonzept (Entscheidung für $H_0$ oder $H_1$); zwar wird auch ein z-Wert (und assoziierter p-Wert) berechnet, diese dienen aber nur zur Entscheidungsfindung und nicht als kontinuierliches Evidenzmaß.\n",
        "    - Signifikanztests nach Neyman/Pearson sind **Akzeptanztests** (wir entscheiden uns *für* $H_0$ oder *für* $H_1$)\n",
        "\n",
        "::: {.merke style=\"font-size: 23px !important\"}\n",
        ":::: {.columns}\n",
        "::: {.column width=\"5%\"}\n",
        "::: {style=\"margin-top: 18px\"}\n",
        "![](images/merke.png){height=\"55px\"}\n",
        ":::\n",
        ":::\n",
        "::: {.column width=\"95%\"}\n",
        "**Beachte:** auch bei Neyman & Pearson wird nur die **Nullhypothese** getestet und wie bei Fisher die Wahrscheinlichkeit (p-Wert) überprüft, dass der Effekt (oder ein noch extremerer Effekt) unter der Nullhypothese $H_0$ entstanden ist. Die **Alternativhypothese** spielt bei der Testprozedur selbst keine Rolle. Sie kommt an zwei Stellen ins Spiel: bei der Power-Berechnung *vor Beginn der Studie* (s. nächste Folien) und bei der wissenschaftlichen Entscheidung *nach der Testprozedur* (Entscheidung für $H_1$ falls $T>T_\\text{crit}$).\n",
        ":::\n",
        "::::\n",
        ":::\n",
        "\n",
        "\n",
        "## Fehler erster und zweiter Art\n",
        "\n",
        "<div class=\"vspace-medium\"></div>\n",
        "\n",
        "**Merkregel auf Basis der Fabel \"Der Hirtenjunge und der Wolf\":**\n",
        "\n",
        "<div class=\"vspace-medium\"></div>\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"75%\"}\n",
        "\n",
        "> Die Hauptperson der Fabel ist ein Hirtenjunge, der aus Langeweile beim Schafehüten laut „Wolf!“ brüllt. Als ihm daraufhin Dorfbewohner aus der Nähe zu Hilfe eilen, finden sie heraus, dass falscher Alarm gegeben wurde und sie ihre Zeit verschwendet haben (**Fehler erster Art**). Als der Junge nach einiger Zeit wirklich einem Rudel Wölfe begegnet, nehmen die Dorfbewohner die Hilferufe nicht mehr ernst und bleiben bei ihrem Tagwerk (**Fehler zweiter Art**). Die Wölfe fressen die ganze Herde und in manchen Versionen der Fabel auch den Jungen.\n",
        "\n",
        "[Quelle: Wikipedia^[https://de.wikipedia.org/wiki/Der_Hirtenjunge_und_der_Wolf]]{.quote-citation}\n",
        ":::\n",
        "::: {.column width=\"25%\"}\n",
        "![](images/The_Boy_Who_Cried_Wolf_-_Project_Gutenberg_etext_19994.jpg){height=350px}\n",
        ":::\n",
        "::::\n",
        "\n",
        "<div class=\"vspace-medium\"></div>\n",
        "\n",
        "Die Fabel stammt von Äsop, einem griechischen Dichter (6.Jhd. v. Chr.).\n",
        "\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Relevanz für Berechnung der Stichprobengröße\n",
        "\n",
        "- Die häufigste Anwendung findet das Neyman-Pearson-Framework bei der Planung der Stichprobengröße.\n",
        "- Der Vorteil des Frameworks ist, dass es nicht wie bei Fisher nur die Irrtumswahrscheinlichkeit $\\alpha$ für die $H_0$ berücksichtigt (\"Wahrscheinlichkeit das Ergebnis als signifikant zu werten obwohl $H_0$ gilt\"), sondern auch die Irrtumswahrscheinlichkeit $\\beta$ für die $H1$ (\"Wahrscheinlichkeit das Ergebnis als nicht signifikant zu werten obwohl $H_1$ gilt\").\n",
        "\n",
        "::: {style=\"margin-top: -20px\"}\n",
        ":::: {.columns}\n",
        "::: {.column width=\"58%\"}\n",
        "- Beide Fehlerarten sollten gegeneinander abgewogen werden (welcher Fehler ist wichtiger/fataler?)\n",
        "    - Konvention ist es, die Hypothese als $H_0$ festzulegen, die mit geringerer Wahrscheinlichkeit fälschlich abgelehnt werden soll (das impliziert $\\alpha<\\beta$).\n",
        "- Im Kontext der Stichprobenberechnung wird statt der Irrtumswahrscheinlichkeit $\\beta$ häufig $1-\\beta$ betrachtet.\n",
        "    - $1-\\beta$ entspricht der Wahrscheinlichkeit die (wahre) Alternativhypothese zu bestätigen, d.h. einen vorhandenen Effekt auch tatsächlich zu finden.\n",
        "    - Diese Wahrscheinlichkeit wird als [**Teststärke**]{color=\"navy\"} oder [**Power**]{color=\"navy\"} bezeichnet und die Prozedur daher auch [**Power-Berechnung**]{color=\"navy\"}.\n",
        ":::\n",
        "::: {.column width=\"42%\"}\n",
        "\n",
        "<div class=\"vspace-medium\"></div>\n",
        "\n",
        "![](images/neyman_pearson3.png)\n",
        "\n",
        "<div class=\"vspace-medium\"></div>\n",
        "\n",
        "::: {.notabene style=\"margin-left: 25px !important;margin-right: 25px !important;\"}\n",
        ":::: {.columns}\n",
        "::: {.column width=\"14%\"}\n",
        "::: {style=\"margin-top: 10px\"}\n",
        "![](images/notabene2.png){height=\"55px\"}\n",
        ":::\n",
        ":::\n",
        "::: {.column width=\"86%\"}\n",
        "Eine häufige Wahl für die Teststärke/Power ist 80% (entspricht $\\beta=0.2$).\n",
        ":::\n",
        "::::\n",
        ":::\n",
        "\n",
        ":::\n",
        "::::\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Relevanz für Berechnung der Stichprobengröße\n",
        "\n",
        "Im Kontext der Stichprobenberechnung, gibt das Neyman-Pearson-Framework eine Antwort auf folgende Frage:\n",
        "\n",
        "::: {.colorbox .fragment}\n",
        "Meine Studie soll einen **Fehler erster Art von höchstens $\\alpha$** haben. Ich erwarte, dass mein Effekt eine **Effektstärke $d_1$** aufweist. Wie groß muss ich meine **Fallzahl $N$** wählen, damit ich mit einer **Wahrscheinlichkeit von $1-\\beta$ (=Teststärke/Power)** einen tatsächlich vorhandenen Effekt finden würde?\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Teststärke (Power)\n",
        "\n",
        "**Drei Größen beeinflussen die Wahrscheinlichkeit, ein signifikantes Ergebnis zu finden (d.h. $H_0$ abzulehnen):**\n",
        "\n",
        "- Effektstärke von $H_1$ (hängt ab von $μ_1$ und $\\sigma$)\n",
        "- Stichprobengröße $N$\n",
        "- Fehlerrate erster Art $\\alpha$\n",
        "\n",
        "![](images/neyman_pearson_power.png)\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## [Relevanz für Berechnung der Stichprobengröße]{color=\"darkred\"}\n",
        "\n",
        "<div class=\"vspace-small\"></div>\n",
        "\n",
        "![Die Abbildung zeigt den optimalen $\\alpha$-Wert für verschiedene Stichprobengrößen und verschiedene Verhältnisse von Fehler 1. und 2. Art (in der Legende bedeutet z.B. $C_{I/II}=1/4$, dass die Fehlerrate $\\beta$ zweiter Art 4x so klein sein soll, wie die Fehlerrate $\\alpha$ erster Art). Die \"Optimalität\" des $\\alpha$-Wertes bezieht sich darauf, dass die Summe der Fehlerraten minimal ist (unter Berücksichtigung des Verhältnisses). Aus der Abbildung ist ersichtlich, dass die Konvention $\\alpha=0{,}05$ nicht aus der Luft gegriffen ist, sondern bei typischen Stichprobengrößen in der Nähe des optimalen Wertes liegt.^[Wulff J, Taylor L (2023) How and Why Alpha Should Depend on Sample Size: A Bayesian-frequentist Compromise. Academy of Management Annual Meeting Proceedings 2023:12131.]](images/samplesize_alpha.png)\n",
        "\n",
        "![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=110px}\n",
        "\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Veränderung der Stichprobengröße $N$\n",
        "\n",
        "![](images/demo_neyman_pearson_N30_std15_delta8_zcrit2.png)\n",
        "\n",
        "![](images/demo_neyman_pearson_N15_std15_delta8_zcrit2.png)\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Veränderung der Populationsstreuung $\\sigma$\n",
        "\n",
        "![](images/demo_neyman_pearson_N30_std15_delta8_zcrit2.png)\n",
        "\n",
        "![](images/demo_neyman_pearson_N30_std30_delta8_zcrit2.png)\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Veränderung des Mittelwertsunterschiedes $\\Delta\\overline{IQ}$\n",
        "\n",
        "![](images/demo_neyman_pearson_N30_std15_delta8_zcrit2.png)\n",
        "\n",
        "![](images/demo_neyman_pearson_N30_std15_delta15_zcrit2.png)\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Veränderung des kritischen Entscheidungswertes $z_\\text{crit}$\n",
        "\n",
        "![](images/demo_neyman_pearson_N30_std15_delta8_zcrit2.png)\n",
        "\n",
        "![](images/demo_neyman_pearson_N30_std15_delta8_zcrit1.png)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "##\n",
        ":::: {.columns}\n",
        "::: {.column width=\"9%\"}\n",
        "::: {style=\"margin-top:-15px\"}\n",
        "![](images/summary.png)\n",
        ":::\n",
        ":::\n",
        "::: {.column width=\"91%\"}\n",
        "::: {.summary}\n",
        "\n",
        "- Signifikanztests prüfen die Wahrscheinlichkeit, mit der ein experimentelles Ergebnis (oder ein extremeres) auch zufällig zustande gekommen sein kann, obwohl die Nullhypothese gilt.\n",
        "- Signifikanztests nach Fisher basieren auf der Stichprobenverteilung um den Wert der Nullhypothese\n",
        "- Bei Signifikanztests nach Neyman und Pearson muss zudem die Stichprobenverteilung um einen vom Forscher festgelegten Wert der Alternativhypothese betrachtet werden.\n",
        "- Signifikanztests treffen Entscheidungen für oder gegen eine Hypothese basierend auf dem berechneten p-Wert und dem festgelegten Signifikanzniveau $\\alpha$\n",
        ":::\n",
        ":::\n",
        "::::\n",
        "\n",
        "\n",
        "## {.blackslide .center}\n",
        "\n",
        "::: {.content-hidden when-format=\"pdf\"}\n",
        "![](images/paradoxia_group_of_scientists.png){.hcenter-image height=300px}\n",
        "<!-- Source: Midjourney -->\n",
        "<div class=\"vspace-small\"></div>\n",
        ":::\n",
        "\n",
        "Nach kurzer Beratung in der Task Force sind Sie sich einig, dass die Voraussetzungen für einen z-Test nicht optimal sind. Die Populationsstreuung lässt sich nicht aus vorhergehenden Studien ableiten, da die untersuchten Phänomene brandneu sind. Da die Fallzahl von $N=50$ gemäß der Faustregel \"$N\\ge 30$\" aber ausreichend wäre, rechnen Sie aus reiner Neugier dennoch z-Tests für die Gruppenvergleiche.\n",
        "\n",
        "\n",
        "## {.blackslide .center}\n",
        "\n",
        "<div class=\"vspace-small\"></div>\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"68%\"}\n",
        "Sie erstellen sich eine Tabelle mit den relevanten Parametern für den z-Test:\n",
        "\n",
        "<!---  Table --->\n",
        "|[TikTok]{.underline}|Fallzahl $N$ |Mittelwert $\\bar{x}$|Standardabweichung $\\sigma$|\n",
        "|-|-|-|-|\n",
        "| Kontroll | 50 | $1{,}02$ | ${0,55}$ |\n",
        "| Paradoxia | 50 |$1{,}60$ | ${0,68}$ |\n",
        "\n",
        ": {tbl-colwidths=\"[20, 20, 20, 33]\"}\n",
        "\n",
        "<div class=\"vspace-medium\"></div>\n",
        "\n",
        "<!---  Table --->\n",
        "|[Entzündung]{.underline}|Fallzahl $N$ |Mittelwert $\\bar{x}$|Standardabweichung $\\sigma$|\n",
        "|-|-|-|-|\n",
        "| Kontroll | 50 | $0{,}123$ | $0{,}068$ |\n",
        "| Paradoxia | 50 |$0{,}148$ | $0{,}078$ |\n",
        "\n",
        ": {tbl-colwidths=\"[20, 20, 20, 33]\"}\n",
        "\n",
        ":::\n",
        "::: {.column width=\"32%\"}\n",
        "::: {.content-hidden when-format=\"pdf\"}\n",
        "![](images/paradoxia_group_of_scientists.png){.hcenter-image height=200px style=\"margin-top:-20px !important\"}\n",
        "<!-- Source: Midjourney -->\n",
        ":::\n",
        ":::\n",
        "::::\n",
        "\n",
        "<div class=\"vspace-medium\"></div>\n",
        "\n",
        "![](images/paradoxia_histogram_inflammation_mean_std.png){height=260px}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## {.blackslide .center}\n",
        "\n",
        "<div class=\"vspace-small\"></div>\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"68%\"}\n",
        "Um den z-Wert zu bestimmen, benötigen Sie den Standardfehler. Da es sich um unabhängige Messungen in zwei Gruppen handelt, verwenden Sie die Formel, die auf der mittleren Varianz beider Gruppen basiert:\n",
        "\n",
        "$$\n",
        "SE=\\sqrt{\\frac{\\sigma_\\text{control}^2}{N_\\text{control}}+\\frac{\\sigma_\\text{paradox}^2}{N_\\text{paradox}}}\n",
        "$$\n",
        "\n",
        ":::\n",
        "::: {.column width=\"32%\"}\n",
        "::: {.content-hidden when-format=\"pdf\"}\n",
        "![](images/paradoxia_group_of_scientists.png){.hcenter-image height=200px style=\"margin-top:-20px !important\"}\n",
        "<!-- Source: Midjourney -->\n",
        ":::\n",
        ":::\n",
        "::::\n",
        "\n",
        "\n",
        "Sie erhalten:\n",
        "\n",
        "$$\n",
        "\\scriptsize{\n",
        "\\text{TikTok:}\\quad\\; SE=\\sqrt{\\frac{0{,55}^2}{50}+\\frac{0{,}68^2}{50}}=0{,}12\\qquad \\Delta\\bar{x} = \\bar{x}_\\text{paradox} - \\bar{x}_\\text{control} = 1{,}60-1{,}02 = 0{,}58 \\\\\n",
        "\\text{Entzündung:}\\quad\\; SE=\\sqrt{\\frac{0{,}068^2}{50}+\\frac{0{,}078^2}{50}}=0{,}015\\qquad \\Delta\\bar{x} = \\bar{x}_\\text{paradox} - \\bar{x}_\\text{control} = 0{,}123-0{,}148 = 0{,}025\n",
        "}\n",
        "$$\n",
        "\n",
        "\n",
        "## {.blackslide .center}\n",
        "\n",
        "<div class=\"vspace-small\"></div>\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"68%\"}\n",
        "Der z-Wert ergibt sich als das Verhältnis aus dem \"Effekt\" (hier $\\Delta\\bar{x}$) und dem Standardfehler:\n",
        "\n",
        "$$\n",
        "\\text{TikTok:}\\qquad z=\\frac{\\Delta\\bar{x}}{SE} = \\frac{0{,}58}{0{,}12} = 4{,}83\\\\\n",
        "\\text{Entzündung:}\\qquad z=\\frac{\\Delta\\bar{x}}{SE} = \\frac{0{,}025}{0{,}015} = 1{,}67\n",
        "$$\n",
        "\n",
        ":::\n",
        "::: {.column width=\"32%\"}\n",
        "::: {.content-hidden when-format=\"pdf\"}\n",
        "![](images/paradoxia_group_of_scientists.png){.hcenter-image height=200px style=\"margin-top:-20px !important\"}\n",
        "<!-- Source: Midjourney -->\n",
        ":::\n",
        ":::\n",
        "::::\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"60%\"}\n",
        "In beiden Fällen haben Sie eine **gerichtete** Hypothese, nämlich dass Pardoxiker höhere Werte als Kontrollen aufweisen. Der p-Wert entspricht also der Fläche unter der Standardnormalverteilung *rechts* vom z-Wert und damit dem Integral:\n",
        "\n",
        "$$\n",
        "p=\\int_{z}^{\\infty}\\varphi(x)dx = 1 - \\Phi(z)\n",
        "$$\n",
        ":::\n",
        "::: {.column width=\"40%\"}\n",
        "![](images/paradoxia_nulldist.png)\n",
        ":::\n",
        "::::\n",
        "\n",
        "\n",
        "## {.blackslide .center}\n",
        "\n",
        "<div class=\"vspace-small\"></div>\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"68%\"}\n",
        "\n",
        "Die Spannung steigt, als Sie nun zum ersten Mal die Signifikanz Ihrer Ergebnisse beurteilen können. Sie erhalten folgende p-Werte:\n",
        "\n",
        "<div class=\"vspace-small\"></div>\n",
        "\n",
        "$$\n",
        "\\text{TikTok:}\\qquad p= 1 - \\Phi(4{,}83) = 0{,}0000007\n",
        "$$\n",
        "\n",
        "<div class=\"vspace-small\"></div>\n",
        "\n",
        "$$\n",
        "\\text{Entzündung:}\\qquad p= 1 - \\Phi(1{,}67) = 0{,}047\n",
        "$$\n",
        "\n",
        ":::\n",
        "::: {.column width=\"32%\"}\n",
        "::: {.content-hidden when-format=\"pdf\"}\n",
        "![](images/paradoxia_group_of_scientists.png){.hcenter-image height=200px style=\"margin-top:-20px !important\"}\n",
        "<!-- Source: Midjourney -->\n",
        ":::\n",
        ":::\n",
        "::::\n",
        "\n",
        "\n",
        "Dieser erste Signifikanztest ergibt also, dass die TikTok-Hypothese mit überwältigender Signifikanz bestätigt wird. Aber auch die Entzündungs-Hypothese wird mit einem p-Wert von $0{,}047$  &mdash; und einem Signifikanzniveau von $\\alpha=0{,}05$ &mdash; um Haaresbreite bestätigt. \n",
        "\n",
        "Noch genießen Sie die Ergebnisse aber mit Vorsicht, da Ihnen bewusst ist, dass der z-Test nicht der ideale Test für Ihre Studie ist.\n",
        "\n",
        "<div class=\"vspace-small\"></div>\n",
        "\n",
        "![](images/paradoxia_histogram_inflammation_mean_std.png){height=250px style=\"margin-top: -60px !important; margin-left: 400px !important\"}"
      ],
      "id": "cd2ce631"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "import seaborn as sns\n",
        "\n",
        "np.random.seed(0)\n",
        "root = '/home/matteo/OneDrive/lehre/Statistik/stats1_lecture/book/'\n",
        "\n",
        "fontsize = 15\n",
        "\n",
        "df = pd.read_csv(os.path.join(root, 'data', 'paradoxia.csv'))\n",
        "# print(df.head())\n",
        "\n",
        "data_tiktok_control = df[df.group == 1]['hours_tiktok_per_day'].values\n",
        "data_tiktok_paradoxia = df[df.group == 2]['hours_tiktok_per_day'].values\n",
        "data_inflam_control = df[df.group == 1]['inflammation'].values\n",
        "data_inflam_paradoxia = df[df.group == 2]['inflammation'].values\n",
        "\n",
        "print(f'Mean TikTok Control: {np.mean(data_tiktok_control):.2f}')\n",
        "print(f'Mean TikTok Paradoxia: {np.mean(data_tiktok_paradoxia):.2f}')\n",
        "print(f'Mean Inflam Control: {np.mean(data_inflam_control):.2f}')\n",
        "print(f'Mean Inflam Paradoxia: {np.mean(data_inflam_paradoxia):.2f}')\n",
        "\n",
        "plt.style.use('dark_background')\n",
        "plt.figure(figsize=(6, 2.5))\n",
        "ax = plt.subplot(121)\n",
        "plt.gca().set_facecolor('#eee')\n",
        "sns.stripplot(data=df, x='group', y='hours_tiktok_per_day', color='#bbb', jitter=0.25)\n",
        "color = 'k'\n",
        "plt.errorbar([0], [np.mean(data_tiktok_control)], yerr=[np.std(data_tiktok_control)], fmt='o', markersize=5, capsize=10, capthick=2, elinewidth=2, ecolor=color, mfc=color, mec=color, zorder=3)\n",
        "plt.errorbar([1], [np.mean(data_tiktok_paradoxia)], yerr=[np.std(data_tiktok_paradoxia)], fmt='o', markersize=5, capsize=10, capthick=2, elinewidth=2, ecolor=color, mfc=color, mec=color, zorder=3)\n",
        "plt.text(0.25, 0.85, r'$\\bar{x}=' + f'{np.mean(data_tiktok_control):.2f}$'.replace('.', '{,}'), ha='center', color='k', fontsize=fontsize-1, transform=ax.transAxes)\n",
        "plt.text(0.75, 0.85, r'$\\bar{x}=' + f'{np.mean(data_tiktok_paradoxia):.2f}$'.replace('.', '{,}'), ha='center', color='k', fontsize=fontsize-1, transform=ax.transAxes)\n",
        "\n",
        "plt.xticks([0, 1], ['Kontroll', 'Paradoxia'], fontsize=fontsize)\n",
        "plt.yticks(fontsize=fontsize-2)\n",
        "plt.ylabel('Stunden TikTok / 24h', fontsize=fontsize)\n",
        "plt.xlabel('')\n",
        "# plt.xlim(-0.5, 1.5)\n",
        "plt.ylim(0, 1.1*max(data_tiktok_control.max(), data_tiktok_paradoxia.max()))\n",
        "\n",
        "\n",
        "ax = plt.subplot(122)\n",
        "plt.gca().set_facecolor('#eee')\n",
        "sns.stripplot(data=df, x='group', y='inflammation', color='#bbb', jitter=0.25)\n",
        "color = 'k'\n",
        "plt.errorbar([0], [np.mean(data_inflam_control)], yerr=[np.std(data_inflam_control)], fmt='o', markersize=5, capsize=10, capthick=2, elinewidth=2, ecolor=color, mfc=color, mec=color, zorder=3)\n",
        "plt.errorbar([1], [np.mean(data_inflam_paradoxia)], yerr=[np.std(data_inflam_paradoxia)], fmt='o', markersize=5, capsize=10, capthick=2, elinewidth=2, ecolor=color, mfc=color, mec=color, zorder=3)\n",
        "plt.text(0.25, 0.85, r'$\\bar{x}=' + f'{np.mean(data_inflam_control):.2f}$'.replace('.', '{,}'), ha='center', color='k', fontsize=fontsize-1, transform=ax.transAxes)\n",
        "plt.text(0.75, 0.85, r'$\\bar{x}=' + f'{np.mean(data_inflam_paradoxia):.2f}$'.replace('.', '{,}'), ha='center', color='k', fontsize=fontsize-1, transform=ax.transAxes)\n",
        "\n",
        "plt.xticks([0, 1], ['Kontroll', 'Paradoxia'], fontsize=fontsize)\n",
        "plt.yticks(fontsize=fontsize-2)\n",
        "plt.ylabel('Entzündungswert', fontsize=fontsize)\n",
        "plt.xlabel('')\n",
        "plt.xlim(-0.5, 1.5)\n",
        "plt.ylim(0, 1.1*max(data_inflam_control.max(), data_inflam_paradoxia.max()))\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.savefig('images/paradoxia_histogram_inflammation_mean_std.png', bbox_inches='tight')"
      ],
      "id": "7ac590ad",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}