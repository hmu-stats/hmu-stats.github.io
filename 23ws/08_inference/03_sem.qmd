
<!----------------->
<!--- New slide --->
<!----------------->
## Streuung der theoretischen Stichprobenverteilung


Bleibt die Frage nach dem Streuungsparameter $\sigma_\text{SV}$: woher wissen wir, wie die Ergebnisse von hypothetischen Stichproben streuen würden?

:::: {.columns .fragment }
::: {.column width="32%"}
Gehen wir dazu zu unserem Gedankenexperiment zurück:
:::
::: {.column width="68%"}
![](images/inference1_annot.png)
:::
::::

:::{.fragment}
**Was würde die Streuung der möglichen Ergebnisse verkleinern?**
:::

1. Wir ziehen nicht 3 Personen in unserer Studie, sondern 6<br>&xrarr; damit lägen fast alle Stichproben näher am wahren Mittelwert!

2. Wir hätten in der Population grundsätzlich eine geringere Streuung der Werte<br>&xrarr; damit würden auch die Mittelwerte einzelner Studien weniger streuen.

:::{.fragment}
Der Streuungsparameter $\sigma_\text{SV}$ der theoretischen Stichprobenverteilung muss also eine Funktion der Stichprobengröße $n$ und der Streuung $\sigma$ in der Population sein. 
:::

<div class="vspace-xsmall"></div>

:::{.fragment}
$$
\hat{\sigma}_\text{SV} = \hat{se} = f(n, \sigma)
$$
:::

<div class="vspace-xsmall"></div>

:::{.fragment}
Als Begriff für die Streuung der Stichprobenverteilung hat sich [**Standardfehler**]{color="navy"} (engl. *standard error*) eingebürgert.
:::


<!----------------->
<!--- New slide --->
<!----------------->
## Beispiel: Standardfehler des Mittelwertes

:::: {.columns}
::: {.column width="68%"}

:::{.nonincremental}
- Ein für Statistik 1 besonders wichtiger Standardfehler ist der Standardfehler des Kennwertes *Mittelwert*.
- Er wird als **Standardfehler des Mittelwertes** oder engl. *standard error of the mean* (*SEM*) bezeichnet.
- Er berechnet sich als die Standardabweichung der Population $\sigma$ geteilt durch die Wurzel aus der Stichprobengröße $n$ ("Wurzel-N-Gesetz"):
:::

:::
::: {.column width="32%"}
![](images/stichprobenverteilung.png)
:::
::::


::: {.fragment style="margin-top: -5px"}
$$
\text{Standardfehler des Mittelwertes:}\qquad\hat{\sigma}_\text{SV} = \hat{se} = \frac{\hat{\sigma}}{\sqrt{n}}
$$
:::

- Da der wahre Streuungsparameter $\sigma$ der Population unbekannt ist, verwenden wir die Schätzung $\hat{\sigma}$ auf Basis der Streuung der Stichprobendaten (&rarr; dazu kommen wir gleich noch einmal).
- Intuitiv sagt der Standardfehler des Mittelwertes aus, wie sicher wir uns bei der Bestimmung des Mittelwertes sein können
    - Großer Standardfehler: Gemessener Mittelwert ist eher unsicher
    - Kleiner Standardfehler: Gemessener Mittelwert ist eher sicher

<!----------------->
<!--- New slide --->
<!----------------->
## Beispiel: Standardfehler des Mittelwertes


::: {.merke .vcenter}
:::: {.columns}
::: {.column width="5%"}
::: {style="margin-top: 18px"}
![](images/merke.png){height="55px"}
:::
:::
::: {.column width="95%"}
**Beachte:** der Standardfehler des Mittelwertes allein sagt nichts über die tatsächliche Streubreite des Merkmals. Der Standardfehler kann klein sein, obwohl die Standardabweichung $\sigma$ des gemessenen Merkmals groß ist, wenn im Gegenzug die Stichprobengröße $n$ groß ist. Umgekehrt kann ein Standardfehler groß sein, obwohl die Standardabweichung $\sigma$ klein ist, wenn $n$ klein ist.
:::
::::
:::

<!----------------->
<!--- New slide --->
<!----------------->
## [Herleitung des Standardfehlers]{color="darkred"}

![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=130px}

:::{.nonincremental}
- Der Standardfehler ist ein Maß für die **Variabilität der Stichprobenmittelwerte** $\bar{x}$ &mdash; dies können wir zunächst über die Varianz zum Ausdruck bringen:
:::

$$
se^2 = Var(\bar{x})
$$

:::{.nonincremental}
- Wir wissen, dass $\bar{x} = \frac{1}{n}\sum X_i$, also:
:::

$$
se^2 = Var(\bar{x}) = Var\left(\frac{1}{n}\sum X_i\right)
$$

:::{.nonincremental}
- Um das $\frac{1}{n}$ aus der Varianz herausziehen zu können, versichern wir uns einer kleinen Rechenregel:
:::

$$
Var(aX) = \frac{1}{n}\left(aX_i-a\bar{x}\right)^2 = \frac{a^2}{n}\left(X_i-\bar{x}\right)^2 = a^2Var(X)
$$

:::{.nonincremental}
- Daraus folgt:
:::

$$
se^2 = \frac{1}{n^2}Var\left(\sum X_i\right)
$$


<!----------------->
<!--- New slide --->
<!----------------->
## [Herleitung des Standardfehlers]{color="darkred"}

![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=130px}

$$
\text{Zwischenergebnis}\qquad se^2 = \frac{1}{n^2}Var\left(\sum X_i\right) 
$$

:::{.nonincremental}
- Die Summe in der Varianz stört noch. Glücklicherweise gilt, dass die Varianz der Summe von unabhängigen Zufallsvariablen $X_i$ gleich der Summe der Varianzen ist, d.h. 
:::

$$
Var\left(\sum X_i\right)=\sum Var(X_i)
$$

:::{.nonincremental}
- Daraus folgt:
:::

$$
se^2 = \frac{1}{n^2}\sum Var(X_i) = \frac{1}{n^2}\big(n\cdot Var(X_i)\big) = \frac{1}{n}Var(X_i)
$$

:::{.nonincremental}
- Nun sind wir fast am Ziel. Da die Varianz der $X_i$ nichts anderes als die quadrierte Standardabweichung $\sigma^2$ ist, gilt:
:::

$$
se^2 = \frac{\sigma^2}{n} \qquad \text{bzw.} \qquad se = \frac{\sigma}{\sqrt{n}}
$$


<!----------------->
<!--- New slide --->
<!----------------->
## [Übersicht Standardfehler]{color="darkred"}

![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=110px}


<!---  Table --->
|Maß|Standardfehler|Einschränkung|
|-|-|-|
| Mittelwert | $\hat{se}(\bar{x}) = \frac{\hat{\sigma}}{\sqrt{n}}$ |  |
| Median | $\hat{se}(\tilde{x}) = \sqrt{\frac{\pi}{2}}\frac{\hat{\sigma}}{\sqrt{n}}$ | Annahme: Normalverteilung von $X$|
| Varianz | $\hat{se}(s^2) = \sqrt{\frac{2}{n-1}}\hat{\sigma}^2$ | Annahme: Normalverteilung von $X$ |
| Standardabweichung | $\hat{se}(s) = \frac{\hat{\sigma}}{\sqrt{2(n-1)}}$ | Näherung; Annahme: Normalverteilung von $X$ |
|Korrelation|$\hat{se}(r) = \sqrt{\frac{1-r^2}{n-2}}$|Näherung; Hinweis: laut neuerer Forschung ist $\hat{se}(r) = \sqrt{\frac{1-r^2}{n-3}}$ sogar ein noch besserer Schätzer^[Gnambs T. A Brief Note on the Standard Error of the Pearson Correlation. https://psyarxiv.com/uts98/]|
|Cohen's d (abhängige Messungen)|$\hat{se}(d) = \sqrt{\frac{1}{n}+\frac{d^2}{2n}}$|Näherung|
|Cohen's d (unabhängige Messungen)|$\hat{se}(d) = \sqrt{\frac{n_1+n_2}{n_1n_2}+\frac{d^2}{2(n_1+n_2)}}$|Näherung; Quelle^[n^[https://stats.stackexchange.com/questions/495015/what-is-the-formula-for-the-standard-error-of-cohens-d]:]|
: {tbl-colwidths="[25, 20, 55]"}

Nützliches Paper^[Harding B, Tremblay C, Cousineau D (2014) Standard errors: A review and evaluation of standard error estimators using Monte Carlo simulations. TQMP 10:107–123.]

<!----------------->
<!--- New slide --->
<!----------------->
## Zwischenfazit

::: {.colorbox .fragment style="margin-bottom:15px"}
Die theoretische Stichprobenverteilung folgt einer **Normalverteilung** (falls n groß genug) mit einem **Mittelwert, der dem statistischen Kennwert entspricht**, und einer Standardabweichung, die sich aus der Populationsstreuung $\sigma$ und der Stichprobengröße $n$ berechnet (der sog. **Standardfehler**).
:::

- Der Standardfehler gibt darüber Auskunft, wie verlässlich unsere Schätzung des statistischen Kennwertes ist.
- Wie wir noch sehen werden umfasst $1 \hat{se}$ die mittleren 68% der möglichen Ergebnisse in der theoretischen Stichprobenverteilung.

<!---  Example --->
::: {.example .fragment}
:::: {.columns}
::: {.column width="10%"}
::: {style="margin-top: 10px"}
![](images/example.png){height=70px}
:::
:::
::: {.column width="55%"}
Nehmen wir an, die Nasenlängen der Männer in unserer Studie weisen eine durchschnittliche Länge von $6cm$ auf und einen Standardfehler (des Mittelwertes) von $0{,}5cm$. 

Wir können damit sagen, dass der Bereich

$$
\bar{x}\pm\hat{se} = 6\pm 0{,}5 = [5{,}5; 6{,}5]
$$

68% der Stichprobenverteilung umfasst. 

[In Vorlesung 12 werden wir noch feststellen, dass wir (leider) [nicht]{.underline} schlussfolgern können, dass der wahre Populationsmittelwert $\mu$ mit 68% Wahrscheinlichkeit in diesem Intervall liegt.]{style="font-size: 18px"}


:::
::: {.column width="35%"}
![](images/sem_example.png){height=280px}
:::
::::
:::




<!----------------->
<!--- New slide --->
<!----------------->
## Interpretation des Standardfehlers

<div class="vspace-medium"></div>

**Wie kann man den Wert eines Standardfehlers interpretieren?**

- Lässt sich pauschal nicht beantworten, da der Standardfehler von der Messskala abhängt
    - Er ist keine standardisierte Größe wie z.B. der Korrelationskoeffizient.
- Prinzipiell gilt: je kleiner, desto besser (d.h. desto präziser ist unsere Kennwertschätzung)
- Anhaltspunkt: Vergleich/Verhältnis zur Skala (besonders einfach bei Ratingskalen wie 1-10) oder zur Standardabweichung in der Stichprobe:

<div class="vspace-large"></div>

<!---  Example --->
::: {.example .fragment}
:::: {.columns}
::: {.column width="10%"}
::: {style="margin-top: 10px"}
![](images/example.png){height=70px}
:::
:::
::: {.column width="90%"}
Nehmen wir wieder unser Nasenlängen-Beispiel mit $\bar{x}=6cm$ und $\hat{se}=0{,}5cm$, und nehmen wir an, die Standard*abweichung* von Nasenlängen in der Stichprobe betrug $5cm$. In diesem Fall hätten wir den Mittelwert mit einer Präzision von 10% der Streubreite in der Stichprobe geschätzt, was einer recht guten/präzisen Schätzung entspricht.

(Als kleine Übung: wie hoch müsste in diesem Beispiel die Stichprobenzahl gewesen sein? (Antwort: $n=100$)
:::
::::
:::

<!----------------->
<!--- New slide --->
<!----------------->
## Verwendung des Standardfehlers in der Praxis

- Im Text wird der Standardfehler des Mittelwertes oft in folgender Form angegeben: $M = 3 \pm 0,6 \,\,(\text{SEM})$. 
    - Wichtig: es sollte prinzipiell immer angegeben werden, um was für ein Streuungsmaß es sich handelt (SEM ist hier die geläufige englische Abkürzung für *standard error of the mean*).
- In Abbildungen wird der Standardfehler ähnlich wie die Standardabweichung häufig in Form von Fehlerbalken dargestellt:

<div class="vspace-small"></div>

:::{.fragment}
![](images/sem_praxis.png){height=270px}
:::

- Ist das Hauptinteresse ob sich Experimentalbedingungen **in ihrem Mittelwert unterscheiden**, ist der **Standardfehler aussagekräftiger** als die Varianz oder Standardabweichung
    - Aus diesem Grund ist der Standardfehler des Mittelwertes das vielleicht häufigste Streuungsmaß in der Psychologie



<!----------------->
<!--- New slide --->
<!----------------->
## Schätzung der Standardabweichung in der Population

- Beim Mittelwert gilt, dass der Mittelwert $\bar{x}$ der Stichprobe die beste Schätzung $\hat{\mu}$ für den wahren Mittelwertsparameter $\mu$ der Population ist:

:::{.fragment}
$$
\text{Schätzung des Populationsmittelwertes:}\qquad\hat{\mu} = \bar{x}
$$
:::

- Bei der Varianz/Standardabweichung gilt dies nur (näherungsweise) für große Stichproben. Für kleinere Stichproben gilt leider nicht $\hat{\sigma}^2 = s^2$.
- Grund: um die Streuung in der Population zu schätzen, müsste eigentlich die Streuung der $x_i$ **um den wahren Mittelwert $\mu$** berechnet werden.
-  Das wahre $\mu$ kennen wir aber nicht, sondern lediglich unsere Schätzung $\bar{x}$.
- Es stellt sich heraus, dass die Streuung der $x_i$ um den Mittelwert $\bar{x}$ der Stichprobe immer etwas kleiner ist, als es die Streuung der $x_i$ um den wahren Wert $\mu$ wäre.
    - Das ist durchaus intuitiv, da der Mittelwert $\bar{x}$ *aus den* $x_i$ *selbst* bestimmt wird.
- Dies führt zur **Besselkorrektur** &#x2398;



<!----------------->
<!--- New slide --->
<!----------------->
## Besselkorrektur

:::: {.columns}
::: {.column width="70%"}
:::{.nonincremental}
- Der deutsche Naturwissenschaftler Friedrich Wilhelm Bessel zeigte, dass für eine Schätzung $\hat{\sigma}^2$ der Populationsstreuung auf Basis der Stichprobenstreuung $s^2$, der Faktor $\frac{1}{n}$ in der Varianzformel durch $\frac{1}{n-1}$ ersetzt werden muss:
:::

$$
\text{Schätzung der Populationsvarianz:}\\
\hat{\sigma}^2 = \frac{n}{n-1}s = \frac{1}{n\color{darkgreen}{-1}}\sum\left(x_i-\bar{x}\right)^2
$$

:::
::: {.column width="30%"}
![Friedrich Wilhelm Bessel (1748-1846)^[http://www.digiporta.net/index.php?id=658493715]](images/portrait_bessel.png)
:::
::::

- Wir bezeichnen $\hat{\sigma}^2$ als **Schätzung der Populationsvarianz auf Basis der Stichprobe** oder kurz [**biaskorrigierte Stichprobenvarianz**]{color="navy"}.
- Intution: die Varianz wird im Fall von $\frac{1}{n-1}$ *durch weniger geteilt* als beim ursprünglichen Faktor $\frac{1}{n}$, d.h. die resultierende Varianz wird *zu einem größeren Wert hin* korrigiert.
- Die "$n-1$"-Korrektur für Stichproben wird als [**Besselkorrektur**]{color="navy"} bezeichnet.
- Ab ca. $n=30$ spielt die Besselkorrektur kaum eine Rolle mehr ($\frac{1}{30}=0.033$ vs. $\frac{1}{29}=0.034$)


<!----------------->
<!--- New slide --->
<!----------------->
## [Herleitung des Faktors $\frac{1}{n-1}$]{color="darkred"}

![](images/kein_klausurstoff.png){.absolute bottom=60 right=0 height=110px}

:::{.nonincremental}
- Der Ausgangspunkt der Besselkorrektur die Beobachtung, dass die (unkorrigierte) Varianz $s^2$ der Stichprobe die Varianz $\sigma^2$ der Population systematisch unterschätzt.
- Der Grund ist liegt im Stichprobenmittelwert $\bar{x}$: er ist keine perfekte Schätzung für den wahren Mittelwert $\mu$ ist &mdash; er streut um das "wahre" $\mu$.
- Diese Streuung haben wir gerade kennengelernt &mdash; es ist der Standardfehler $\hat{se}=\frac{\hat{\sigma}}{\sqrt{n}}$. Als Varianz formuliert:
:::

::: {style="margin-top:-50px !important"}
$$
\hat{se}^2 = \frac{\hat{\sigma}^2}{n}
$$
:::

:::{.nonincremental}
- Für die Schätzung der Populationsvarianz $\hat{\sigma}^2$ muss nun die *zusätzliche* Variabilität $\hat{se}^2$ aufgrund der Unsicherheit des Mittelwertes auf die Stichprobenvarianz $s^2$ addiert werden:
:::

::: {style="margin-top:-20px"}
$$
\hat{\sigma}^2 = s^2 + \hat{se}^2 = s^2 + \frac{\hat{\sigma}^2}{n}\quad \longrightarrow\quad \hat{\sigma}^2 - \frac{\hat{\sigma}^2}{n} = s^2
$$
:::

:::{.nonincremental}
- Linke Seite umformen:
:::

::: {style="margin-top:-20px !important"}
$$
\hat{\sigma}^2 - \frac{\hat{\sigma}^2}{n} = \hat{\sigma}^2\left(1 - \frac{1}{n}\right) = \hat{\sigma}^2\frac{n-1}{n} \overset{!}{=} s^2 \;\;\longrightarrow\;\; \hat{\sigma}^2 = \frac{n}{n-1}s^2
$$
:::

<!----------------->
<!--- New slide --->
<!----------------->
## [Herleitung des Faktors $\frac{1}{n-1}$]{color="darkred"}

![](images/kein_klausurstoff.png){.absolute bottom=30 right=0 height=110px}

$$
\text{Zwischenergebnis:}\qquad \hat{\sigma}^2 = \frac{n}{n-1}s^2
$$

:::{.nonincremental}
- Die unkorrigierte Varianz $s^2$ lautet:
:::

::: {style="margin-top:-25px"}
$$
s^2 = \frac{1}{n}\sum\left(x_i-\bar{x}\right)^2
$$
:::

:::{.nonincremental}
- Einsetzen:
:::

:::{style="margin-top: -30px !important"}
$$
\hat{\sigma}^2 = \frac{n}{n-1}s^2 = \frac{n}{n-1}\frac{1}{n}\sum\left(x_i-\bar{x}\right)^2 = \color{navy}{\frac{1}{n-1}}\sum\left(x_i-\bar{x}\right)^2
$$
:::

:::{.nonincremental}
- Nun haben wir unseren Faktor $\color{navy}{\frac{1}{n-1}}$. 
- Für die korrigierte Standardabweichung der Stichprobe wird häufig analog angenommen:
:::

$$
\hat{\sigma} = \sqrt{\color{navy}{\frac{1}{n-1}}\sum\left(x_i-\bar{x}\right)^2}
$$

:::{.nonincremental}
- Diese analoge Korrektur für die Standardabweichung ist nicht 100% gültig^[https://en.wikipedia.org/wiki/Unbiased_estimation_of_standard_deviation] &mdash; für alle<br>praktischen Zwecke reicht sie aber aus.
:::




<!----------------->
<!--- New slide --->
<!----------------->
##
:::: {.columns}
::: {.column width="9%"}
::: {style="margin-top:-15px"}
![](images/summary.png){width=60px}
:::
:::
::: {.column width="91%"}
::: {.summary}
- Im Zuge der Inferenzstatistik wird untersucht, wie gut **Schätzungen von Parametern in der Population** auf Basis von **Stichprobenkennwerten** sind.
- Es geht also um die **Verallgemeinerbarkeit** von Stichprobendaten auf die Population
- Generelle Idee: Was würde passieren, wenn die Studie immer wieder durchgeführt und der Kennwert bestimmt würde?
- Diese Idee wird durch die **theoretische Stichprobenverteilung** repräsentiert.
- Die Stichprobenverteilung von Kennwerten ist laut dem Zentralen Grenzwertsatz **normalverteilt**.
- Die Standardabweichung dieser Stichprobenverteilung wird **Standardfehler** genannt.
:::
:::
::::



<!----------------->
<!--- New slide --->
<!----------------->
## {.center}

![Bildnachweis^[http://www.peaya.com/peaya.php?comicsid=1005]](images/peaya_sem.png)

