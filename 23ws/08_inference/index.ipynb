{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Vorlesung 09: Inferenzstatistik\"\n",
        "---"
      ],
      "id": "fb4107f6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Der Forschungsprozess {.hcenter-slide}\n",
        "\n",
        "```yaml { .animate src=\"images/scientific_process.svg\"}\n",
        "setup:\n",
        "    - element: \"#inference\"\n",
        "      modifier: function() { this.node.style.fill = 'green'; }\n",
        "    - element: \"#inferencebg\"\n",
        "      modifier: function() { this.node.style.fill = '#d8ffe2';}\n",
        "```\n",
        "\n",
        "## Was ist Inferenzstatistik?\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"45%\"}\n",
        "<div class=\"vspace-small\"></div>\n",
        "![Die statistische Prozess in der Psychologie auf einen Blick: eine Teilmenge von Versuchspersonen wird aus der Population gezogen &mdash; die Stichprobe. In der Stichprobe werden Daten $(x_1, x_2, ..., x_n)$ eines Merkmals gemessen. Mit Methoden der deskriptiven Statistik werden **Kennwerte** in der Stichprobe beschrieben $(\\bar{X}, s^2, s)$. Letztendlich ist das Ziel ein Rückschluss auf die wahren **Parameter** der Population $(\\mu, \\sigma^2, \\sigma)$ und das Testen von Hypothesen über die Population. Bildnachweis^[https://stats.libretexts.org/Bookshelves/Introductory_Statistics/Introductory_Statistics_(Shafer_and_Zhang)/01%3A_Introduction_to_Statistics/1.01%3A_Basic_Definitions_and_Concepts]](images/grand_picture_of_statistics_update.png)\n",
        ":::\n",
        "::: {.column width=\"55%\"}\n",
        "- In den vergangenen Vorlesungen haben wir kennengelernt, wie Merkmale in Stichproben quantitativ beschrieben werden können &mdash; wir haben **deskriptive Statistik** betrieben.\n",
        "- In den meisten Fällen ist das Ziel in der Psychologie allerdings nicht die Beschreibung der spezifischen Stichprobe, sondern ein Rückschluss &ndash; eine Inferenz, eine Verallgemeinerung &ndash; auf die Population.\n",
        "- Die Mathematik hinter diesem Inferenzprozess ist Gegenstand der [**Inferenzstatistik**]{color=\"navy\"}.\n",
        ":::\n",
        "::::\n",
        "\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Was ist Inferenzstatistik?\n",
        "\n",
        "<div class=\"vspace-medium\"></div>\n",
        "\n",
        "![](images/population_sample_schaefer.png)\n",
        "\n",
        "**Zentrale Frage:** Ist das Ergebnis meiner Studie eine gute Schätzung für die wahren Verhältnisse in der Population?\n",
        "\n",
        "\n",
        "# Das Gesetz der großen Zahlen\n",
        "\n",
        "<div class=\"vspace-medium\"></div>\n",
        "\n",
        "Was passiert wenn meine Stichprobe immer größer wird ($n\\longrightarrow\\infty$)?&nbsp;&nbsp;&nbsp;\n",
        "\n",
        "## Das Gesetz der großen Zahlen\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"73%\"}\n",
        "\n",
        "**Beispiel: gezinkter Würfel**\n",
        "\n",
        "- Sie wollen überprüfen, ob ein Würfel zu Ihrem Nachteil gezinkt ist, so dass die \"Eins\" überproportional häufig kommt. Dazu führen Sie eine Reihe von Probewürfen durch.\n",
        "- Sollte der Würfel *nicht gezinkt* sein, sollte die Wahrscheinlichkeit einer \"Eins\" genau $\\frac{1}{6}$ ist.\n",
        "- Sie zählen die Häufigkeit einer \"Eins\" nach 10, 100, 1000 und 10000 Würfen.\n",
        ":::\n",
        "::: {.column width=\"27%\"}\n",
        "![](images/gezinkter_wuerfel.png)\n",
        ":::\n",
        "::::\n",
        "\n",
        "<!-- <div class=\"vspace-small\"></div> -->\n",
        "\n",
        ":::{style=\"margin-top: -10px\"}\n",
        "[Ergebnis:]{.underline}\n",
        ":::\n",
        "\n",
        "<!---  Table --->\n",
        "||||||\n",
        "|-|:-:|:-:|:-:|:-:|\n",
        "|  | 10 Würfe | 100 Würfe | 1000 Würfe | 10000 Würfe |\n",
        "| Anzahl Einsen | 3 | 20 | 172 | 1669 |\n",
        "| Relative Häufigkeit | $\\frac{3}{10}=0.3$ | $\\frac{20}{100}=0.2$ | $\\frac{172}{1000}=0.172$ | $\\frac{1669}{10000}=0.1669$ |\n",
        ": {tbl-colwidths=\"[20, 20, 20, 20, 20]\"}\n",
        "\n",
        "<div class=\"vspace-small\"></div>\n",
        "\n",
        "- Mit zunehmender Zahl der Würfe nähert sich also Ihre gemessene Wahrscheinlichkeit der erwarteten Wahrscheinlichkeit $\\frac{1}{6}=0{,}1666..\\;$ an &mdash; dies ist das [**Gesetz der großen Zahlen**]{color=\"navy\"}!\n",
        "\n",
        ":::{style=\"margin-top: -15px\"}\n",
        "(&rArr; ... und offenkundig ist der Würfel nicht gezinkt!)\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Das Gesetz der großen Zahlen\n",
        "\n",
        "::: {.vcenter}\n",
        "\n",
        "<!---  Definition--->\n",
        "|||\n",
        "|:-:|-|\n",
        "|||\n",
        "| ![](images/definition.svg){height=70px} | **Gesetz der großen Zahlen:** Die gemessene relative Häufigkeit eines Zufallsereignisses nähert sich immer weiter an die tatsächliche Wahrscheinlichkeit dieses Ereignisses an, je häufiger das Zufallsexperiment durchgeführt wird. | \n",
        "|||\n",
        ": {tbl-colwidths=\"[10, 90]\"}\n",
        "\n",
        "<div class=\"vspace-medium\"></div>\n",
        "\n",
        "Das Gesetz der großen Zahlen ist ein mathematischer **Grenzwertsatz**, weil er das Verhalten einer Größe in einem Grenzfall ($\\text{Anzahl Zufallsexperimente }\\rightarrow \\infty$) beschreibt.\n",
        "\n",
        ":::\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Das Gesetz der großen Zahlen\n",
        "\n",
        "Im nächsten Schritt übertragen wir das ganze auf **Verteilungen**:\n",
        "\n",
        "- Im Würfelbeispiel haben wir bislang die relative Häufigkeit einer *einzelnen* Merkmalsausprägung (Würfelzahl 1) betrachtet\n",
        "- Natürlich gilt das Gesetz der großen Zahlen aber für alle Merkmalsausprägungen &ndash; im Würfelbeispiel also auch für die Zahlen 2 bis 5.\n",
        "- Die relative Häufigkeit *aller* Merkmalsausprägungen einer Zufallsvariablen X wird auch als die **Wahrscheinlichkeitsverteilung von X** bezeichnet.\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"60%\"}\n",
        "- Im Würfelbeispiel ist die Zufallsvariable die gewürfelte Zahl. Wir erwarten, dass alle Zahlen 1-6 gleich wahrscheinlich sind, oder mit anderen Worten: wir erwarten dass die Zufallsvariable \"gewürfelte Zahl\" eine **uniforme Verteilung** aufweist:\n",
        ":::\n",
        "::: {.column width=\"40%\"}\n",
        "![](images/dices_uniform.png){height=250px}\n",
        ":::\n",
        "::::\n",
        "\n",
        "\n",
        "## Das Gesetz der großen Zahlen\n",
        "\n",
        "- Analog nähert sich hier mit steigender Zahl von Würfen die gemessene Häufigkeitsverteilung der erwarteten Häufigkeitsverteilung an:\n",
        "\n",
        "![](images/dices_experiment.png){height=350px}\n",
        "\n",
        "<div class=\"vspace-medium\"></div>\n",
        "\n",
        "Das Gesetz der großen Zahlen kann deshalb auch auf Verteilungen bezogen werden:\n",
        "\n",
        "<!---  Definition--->\n",
        "|||\n",
        "|:-:|-|\n",
        "|||\n",
        "| ![](images/definition.svg){height=70px} | **Gesetz der großen Zahlen (2):** Die gemessene relative Häufigkeits*verteilung* (=Wahrscheinlichkeitsverteilung) einer Zufallsvariablen nähert sich immer weiter an die tatsächliche Wahrscheinlichkeitverteilung der Variable an, je häufiger das Zufallsexperiment durchgeführt wird. | \n",
        "|||\n",
        ": {tbl-colwidths=\"[9, 91]\"}\n",
        "\n",
        "<!-- ```{python}\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "fontsize = 14\n",
        "\n",
        "mu = 5\n",
        "std = 1.5\n",
        "x = np.linspace(0, 10, 100)\n",
        "\n",
        "N = 8000\n",
        "s = np.random.normal(mu, std, N)\n",
        "bins = np.arange(0, 10.1, 1)\n",
        "counts = np.histogram(s, bins=bins)[0]\n",
        "\n",
        "plt.figure(figsize=(6.5, 2.5))\n",
        "plt.subplot(121)\n",
        "plt.bar(bins[:-1]+0.5, 8e7*norm.pdf(bins[:-1]+0.5, mu, std), width=1, ec='w', fc='#999')\n",
        "plt.xlabel('Nasenlänge (cm)', fontsize=fontsize)\n",
        "plt.ylabel('Absolute Häufigkeit', fontsize=fontsize)\n",
        "plt.xticks(bins[::2], fontsize=fontsize-2)\n",
        "plt.yticks(plt.yticks()[0], [f\"{np.round(y/1e6):.0f} Mio.\" for y in plt.yticks()[0]], fontsize=fontsize-2)\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.bar(bins[:-1]+0.5, norm.pdf(bins[:-1]+0.5, mu, std), width=1, ec='w', fc='#999')\n",
        "plt.xlabel('Nasenlänge (cm)', fontsize=fontsize)\n",
        "plt.ylabel('Relative Häufigkeit', fontsize=fontsize)\n",
        "plt.xticks(bins[::2], fontsize=fontsize-2)\n",
        "plt.yticks(fontsize=fontsize-2)\n",
        "plt.ylim(0, 0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('images/noselength_normal.png', bbox_inches='tight')\n",
        "\n",
        "plt.figure(figsize=(3, 2.5))\n",
        "plt.bar(bins[:-1]+0.5, counts/N, width=1, ec='w', fc='#783c00')\n",
        "for i, (x, y) in enumerate(zip(bins[:-1], counts/N)):\n",
        "    plt.annotate(text='', xy=(x-0.15,y+0.005), xytext=(x+1.15,y+0.005), arrowprops=dict(arrowstyle='<->'))\n",
        "plt.annotate(text='Kategorien-\\nbreite $d$', xy=(6.3, 0.165), xytext=(6.5,0.21), arrowprops=dict(arrowstyle='->'))\n",
        "plt.xlabel('Nasenlänge (cm)', fontsize=fontsize)\n",
        "plt.ylabel('Relative Häufigkeit', fontsize=fontsize)\n",
        "plt.xticks(bins[::2], fontsize=fontsize-2)\n",
        "plt.yticks(fontsize=fontsize-2)\n",
        "plt.savefig('images/noselength_normal_relative.png', bbox_inches='tight')\n",
        "``` -->\n",
        "\n",
        "\n",
        "<!-- ```{python}\n",
        "\n",
        "``` -->\n",
        "<!-- ```{python}\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "fontsize = 14\n",
        "\n",
        "mu = 5\n",
        "std = 1.5\n",
        "fig = plt.figure(figsize=(10, 2.3))\n",
        "\n",
        "for i, w in enumerate([2, 1, 0.5, 0.2]): \n",
        "    x = np.arange(w/2, 10, w)\n",
        "    y = norm.pdf(x, mu, std)\n",
        "    y /= np.sum(y)\n",
        "    plt.subplot(1, 4, i+1)\n",
        "    plt.bar(x, y, width=w, ec='w', fc='#783c00')\n",
        "    plt.plot(x, y, 'k-')\n",
        "    plt.plot(x, y, 'ko', markersize=4)\n",
        "    if i == 0:\n",
        "        plt.ylabel('Relative Häufigkeit', fontsize=fontsize)\n",
        "    plt.xticks(np.arange(0,10.1,2), fontsize=fontsize-2)\n",
        "    plt.yticks(fontsize=fontsize-2)\n",
        "    plt.title(f'Kategorienbreite $d={w}cm$', fontsize=fontsize-2)\n",
        "\n",
        "fig.text(0.5, -0.03, 'Nasenlänge (cm)', fontsize=fontsize, ha='center')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('images/probability_density_demo.png', bbox_inches='tight')\n",
        "\n",
        "``` -->\n",
        "\n",
        "<!-- ```{python}\n",
        "\n",
        "``` -->\n",
        "\n",
        "<!-- ```{python}\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "fontsize = 13\n",
        "\n",
        "mu = 5\n",
        "std = 1.5\n",
        "fig = plt.figure(figsize=(3, 2.7))\n",
        "y = norm.pdf(x, mu, std)\n",
        "y /= np.sum(y)\n",
        "plt.plot(x, y, 'k-', color='#777', lw=2)\n",
        "plt.xlabel('Nasenlänge (cm)', fontsize=fontsize)\n",
        "plt.ylabel('Wahrscheinlichkeitsdichte', fontsize=fontsize)\n",
        "plt.xticks(np.arange(0,10.1,2), fontsize=fontsize-2)\n",
        "plt.yticks(fontsize=fontsize-2)\n",
        "plt.ylim(0, 0.029)\n",
        "\n",
        "plt.savefig('images/noselength_probability_density.png', bbox_inches='tight')\n",
        "\n",
        "``` -->"
      ],
      "id": "7816501d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!-- ```{python}\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "fontsize = 14\n",
        "\n",
        "mu = 5\n",
        "std = 1.5\n",
        "x = np.linspace(0, 10, 100)\n",
        "\n",
        "N = 40\n",
        "s = np.random.normal(mu, std, N)\n",
        "bins = np.arange(0, 10.1, 1)\n",
        "counts = np.histogram(s, bins=bins)[0]\n",
        "\n",
        "plt.figure(figsize=(6.5, 2.5))\n",
        "plt.subplot(121)\n",
        "plt.bar(bins[:-1]+0.5, counts, width=1, ec='w', fc='#783c00')\n",
        "plt.xlabel('Nasenlänge (cm)', fontsize=fontsize)\n",
        "plt.ylabel('Absolute Häufigkeit', fontsize=fontsize)\n",
        "plt.xticks(bins[::2], fontsize=fontsize-2)\n",
        "plt.yticks(fontsize=fontsize-2)\n",
        "# plt.title(\"$n=40$\")\n",
        "plt.subplot(122)\n",
        "plt.bar(bins[:-1]+0.5, counts/N, width=1, ec='w', fc='#783c00')\n",
        "plt.xlabel('Nasenlänge (cm)', fontsize=fontsize)\n",
        "plt.ylabel('Relative Häufigkeit', fontsize=fontsize)\n",
        "plt.xticks(bins[::2], fontsize=fontsize-2)\n",
        "plt.yticks(fontsize=fontsize-2)\n",
        "# plt.title(\"$n=40$\")\n",
        "plt.tight_layout()\n",
        "plt.savefig('images/noselength_sample.png', bbox_inches='tight')\n",
        "``` -->\n",
        "\n",
        "## Das Gesetz der großen Zahlen in der Psychologie\n",
        "\n",
        "- Im Kontext der Psychologie begegnet uns das Gesetz der großen Zahlen, wenn wir die **relative Häufigkeitsverteilung eines Merkmals in der Stichprobe** betrachten.\n",
        "\n",
        "<!---  Example --->\n",
        "::: {.example}\n",
        "|||\n",
        "|:-:|-|\n",
        "| ![](images/example.png){height=70px} | Sie messen die Nasenlänge in ihrer Kohorte. Von jeder Person notieren Sie die \\\n",
        "Nasenlänge und tragen diese in einem Histogramm auf. ![](images/noselength.png){height=75px style=\"float:right; margin-top:-33px !important\"} |\n",
        ": {tbl-colwidths=\"[10, 90]\"}\n",
        ":::\n",
        "\n",
        "\n",
        "<!---  Table --->\n",
        "||||\n",
        "|-|-|-|\n",
        "| | Ihr Ergebnis in Ihrer Stichprobe sieht folgendermaßen aus: | ![](images/noselength_sample.png) |\n",
        "|  ![](images/tengumask.png) | Der Gott der Nasen hat uns zum Vergleich die **tatsächliche** Häufigkeitssverteilung von Nasenlängen in Deutschland(=Population) anvertraut:| ![](images/noselength_normal.png) |\n",
        "|  |  | |\n",
        "\n",
        ": {tbl-colwidths=\"[12, 44, 44]\"}\n",
        "\n",
        "::: {style=\"margin-top: -2px\"} \n",
        "- Auch hier würden wir erwarten, dass sich die Verteilung des Merkmals in der Stichprobe an die tatsächliche Verteilung in der Population annähert, je größer die Stichprobe ist.\n",
        ":::\n",
        " \n",
        "<!-- ```{python}\n",
        " \n",
        "``` -->\n",
        "\n",
        "<!-- ```{python}\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "fontsize = 14\n",
        "\n",
        "mu = 5\n",
        "std = 1.5\n",
        "x = np.linspace(0, 10, 100)\n",
        "\n",
        "N = [40, 400, 4000, 40000]\n",
        "bins = np.arange(0, 10.1, 1)\n",
        "\n",
        "plt.figure(figsize=(11, 2.5))\n",
        "\n",
        "for i, n in enumerate(N):\n",
        "    plt.subplot(1,4,i+1)\n",
        "    s = np.random.normal(mu, std, n)\n",
        "    counts = np.histogram(s, bins=bins)[0]\n",
        "    plt.bar(bins[:-1]+0.5, norm.pdf(bins[:-1]+0.5, mu, std), width=1, ec='#999', fc='#999')\n",
        "    plt.bar(bins[:-1]+0.5, counts/n, width=1, ec='w', fc='#783c00', alpha=0.33)\n",
        "    plt.xlabel('Nasenlänge (cm)', fontsize=fontsize)\n",
        "    if i == 0:\n",
        "        plt.ylabel('Relative Häufigkeit', fontsize=fontsize)\n",
        "    plt.xticks(bins[::2], fontsize=fontsize-2)\n",
        "    plt.yticks(fontsize=fontsize-2)\n",
        "    plt.title(rf\"$n={n}$\")\n",
        "    plt.ylim(0, 0.31)\n",
        "plt.tight_layout()\n",
        "plt.savefig('images/noselength_limit.png', bbox_inches='tight')\n",
        "``` -->\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Gesetz der großen Zahlen in der Psychologie\n",
        "\n",
        "- Jede zusätzliche Versuchsperson entspricht einem neuen **Zufallsexperiment** (\"Würfelwurf\").\n",
        "    - Annahme: Versuchspersonen werden *zufällig* aus der Population gezogen.\n",
        "- Wir können die Annäherung der Stichprobenverteilung an die Populationverteilung mit $n\\rightarrow n_\\text{tot}$ simulieren ($n_\\text{tot}$ = 80 Mio. Deutsche in diesem Beispiel):\n",
        "\n",
        "![Die Stichprobenverteilungen sind in braun schattiert, die (gleichbleibende) Häufigkeitsverteilung der Population in grau, die in diesem Fall alle 80 Mio. Deutsche umfasst. Beachte, dass in diesem Fall die *relative* Häufigkeit dargestellt ist.](images/noselength_limit.png)\n",
        "\n",
        "- Ähnlich wie beim Würfelwurf nähert sich die Verteilung des Merkmals in der Stichprobe an die tatsächliche Verteilung in der Population an.\n",
        "\n",
        "\n",
        "\n",
        "# Theoretische Stichprobenverteilung\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Theoretische Stichprobenverteilung\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"69%\"}\n",
        "\n",
        "**Zur Erinnerung:**\n",
        "\n",
        "- Bei der **Metaanalyse** ging es um die Verlässlichkeit der Schätzung von Parametern in Bezug auf die Population\n",
        "- Das gemittelte, gewichtete Ergebnis vieler Studien liefert eine bessere Schätzung, als die Ergebnisse einzelner Studien.\n",
        "- Die Metaanalyse basiert auf der **empirischen Stichprobenverteilung**.\n",
        "\n",
        "**Die Idee der Inferenzstatistik ist ähnlich:**\n",
        "\n",
        "- Ich habe nur *eine* Studie, aber überlege, was theoretisch passieren würde, wenn ich diese Studie immer wieder wiederholen würde.\n",
        "- Dieser Ansatz führt zur [**theoretischen Stichprobenverteilung**]{color=\"navy\"}.\n",
        "\n",
        "**Zentrale Idee:**\n",
        "Die theoretische Stichprobenverteilung erlaubt uns eine Einschätzung darüber, wie stabil unser Ergebnis bei einer (hypothetischen) Wiederholung der Studie sein würde.\n",
        ":::\n",
        "::: {.column width=\"31%\"}\n",
        "\n",
        "![Die empirische Stichprobenverteilung besteht aus tatsächlich erhobenen Studien. Die Verteilung empirischer Stichprobenkenn-<br>werte folgt im Idealfall (u.a. kein Publikationsbias, großes N pro Stichprobe) einer Normalverteilung.](images/stichprobenverteilung_empirisch.png){style=\"margin-top:-35px\"}\n",
        "\n",
        "![Die theoretische Stichprobenverteilung ist durch eine Funktion gegeben. Ist die Stichprobengröße N, für die die theoretische Stichprobenverteilung angenommen wird, groß, folgt die Stichprobenverteilung einer Normalverteilung.](images/stichprobenverteilung_theoretisch.png)\n",
        "\n",
        ":::\n",
        "::::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Theoretische Stichprobenverteilung: Beispiel\n",
        "\n",
        "<div class=\"vspace-medium\"></div>\n",
        "\n",
        "**Was würde passieren, wenn ich meine Studie ganz oft wiederholen würde?**\n",
        "\n",
        "- Gehen wir das Problem zunächst mit einem Gedankenexperiment (Simulation) an und tun so, als ob wir die wahren Verhältnisse in der Grundgesamtheit kennen.\n",
        "\n",
        "**Gedankenexperiment:** wir interessieren uns für die durchschnittliche Nasenlängen von Männern. Wir nehmen an, die Grundgesamtheit besteht nur aus 9 Männern:\n",
        "\n",
        "<div class=\"vspace-small\"></div>\n",
        "\n",
        "![](images/inference1_annot.png)\n",
        "\n",
        "<div class=\"vspace-small\"></div>\n",
        "\n",
        "&rArr; Der wahre Mittelwert (d.h. der Mittelwert der Population) in diesem Beispiel also $\\mu = 6cm$.\n",
        "\n",
        "<div class=\"vspace-small\"></div>\n",
        "\n",
        "Wir nehmen weiterhin an, dass wir in unserer Studie 3 Männer untersuchen, d.h. wir ziehen eine **Stichprobe $N=3$** mit Zufallsauswahl aus der Grundgesamtheit.\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Theoretische Stichprobenverteilung: Beispiel\n",
        "\n",
        "<div class=\"vspace-medium\"></div>\n",
        "\n",
        "![](images/inference2_annot.png)\n",
        "\n",
        "<!-- ```{python}\n",
        "\n",
        "``` -->\n",
        "\n",
        "<!-- ```{python}\n",
        "from itertools import combinations\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "fontsize=15\n",
        "\n",
        "ls = [7, 5, 9, 3, 5, 4, 6, 8, 7]\n",
        "\n",
        "means = [np.mean(l) for l in list(combinations(ls, 3))]\n",
        "\n",
        "plt.figure(figsize=(4, 3))\n",
        "plt.hist(means, width=0.5, bins=np.arange(int(min(means)), int(np.ceil(max(means)))+0.5, 0.5), facecolor='#783c00', ec='w')\n",
        "for i in range(0, 23):\n",
        "    plt.plot([4, 8], [i, i], 'w')\n",
        "\n",
        "plt.xlabel('Nasenlänge (cm)', fontsize=fontsize)\n",
        "plt.ylabel('Absolute Häufigkeit', fontsize=fontsize)\n",
        "plt.xticks(fontsize=fontsize-2)\n",
        "plt.yticks(fontsize=fontsize-2)\n",
        "plt.savefig('images/noselength_example.png', bbox_inches='tight')\n",
        "\n",
        "``` -->\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Theoretische Stichprobenverteilung: Beispiel\n",
        "\n",
        "<div class=\"vspace-medium\"></div>\n",
        "\n",
        "![](images/inference3_annot.png)\n",
        "\n",
        "... und so weiter\n",
        "\n",
        "<div class=\"vspace-small\"></div>\n",
        "\n",
        "Es gibt insgesamt 84 Möglichkeiten aus dieser Grundgesamtheit von 9 Männern zufällig drei Männer auszuwählen.\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"70%\"}\n",
        "&rarr;&nbsp;Jeder Mittelwert wäre eine Schätzung für den wahren Populationswert.\n",
        "\n",
        "&rarr;&nbsp;Die Abbilung rechts zeigt die Verteilung aller möglichen 84 Mittelwerte.\n",
        ":::\n",
        "::: {.column width=\"30%\"}\n",
        "![](images/noselength_example.png)\n",
        ":::\n",
        "::::\n",
        "\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Theoretische Stichprobenverteilung: Beispiel\n",
        "\n",
        "<div class=\"vspace-medium\"></div>\n",
        "\n",
        "**Was lernen wir aus dieser Verteilung?**\n",
        "\n",
        "- Obwohl es nur einen *wahren Mittelwer*t gibt, weichen die *einzelnen Studienergebnisse* mehr oder weniger davon ab.\n",
        "- Die Studienergebnisse haben also eine *Bandbreite*, in der offensichtlich eine Aussage über die Genauigkeit der Schätzung (von einer einzelnen Stichprobe auf die Population) steckt.\n",
        "- Die Stichprobenergebnisse *schwanken zufällig* um den wahren Wert (siehe auch Metaanalyse).\n",
        "\n",
        "![](images/noselength_example.png){height=300px}\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Theoretische Stichprobenverteilung\n",
        "\n",
        "<div class=\"vspace-medium\"></div>\n",
        "\n",
        "**Übertragen wir nun das Gedankenexperiment auf die Realität:**\n",
        "\n",
        "- Grundgesamtheit seien nun **alle Männer in Deutschland**.\n",
        "- Sie haben eine einzelne Studie durchgeführt (also eine Stichprobe aus der Population gezogen).\n",
        "\n",
        "![](images/noselength_sample_absolute.png){height=300px}\n",
        "\n",
        "- Ihnen ist nun klar, dass das Ergebnis der Studie nur *eines von vielen möglichen Ergebnissen* ist.\n",
        "- Beim Wiederholen derselben Studie würde also – rein zufallsbedingt – ein etwas anderes Ergebnis herauskommen.\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Theoretische Stichprobenverteilung\n",
        "\n",
        "<div class=\"vspace-small\"></div>\n",
        "Wie sieht die zu erwartende Stichprobenverteilung aus, wenn ich, anders als im Gedankenexperiment, die Grundgesamtheit *nicht kenne*?\n",
        "\n",
        "Dies führt uns zur [**theoretischen Stichprobenverteilung**]{color=\"navy\"}. Wie sich herausstellt, können wir tatsächlich anhand einer einzelnen Studie Aussagen darüber machen, wie die Verteilung von Stichprobenkennwerten erwartbar aussehen würde, würden wir die Studie &ndash; rein hypothetisch &ndash; **unendlich oft wiederholen**.\n",
        "\n",
        "<div class=\"vspace-medium\"></div>\n",
        "\n",
        "![](images/inference6.png)\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Theoretische Stichprobenverteilung\n",
        "\n",
        "<div class=\"vspace-medium\"></div>\n",
        "\n",
        "Wie gelangt man zu dieser theoretischen Stichprobenverteilung (obwohl man ja meist nur eine einzige Studie durchgeführt hat)?\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"58%\"}\n",
        "\n",
        "Dazu benötigen wir drei Informationen:\n",
        "\n",
        "1. Wie sieht die **Form** der Verteilung aus?\n",
        "2. Was ist der **Mittelwert** der Verteilung?\n",
        "3. Was ist die Breite (**Streuung**) der Verteilung?\n",
        "\n",
        ":::\n",
        "::: {.column width=\"42%\"}\n",
        "![](images/stichprobenverteilung_theoretisch.png)\n",
        ":::\n",
        "::::\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Form der theoretischen Stichprobenverteilung\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"77%\"}\n",
        "- Wir haben bereits den **zentralen Grenzwertsatz** kennengelernt, demzufolge viele Merkmale in der Psychologie normalverteilt sind, weil sie sich aus einer Summe von Zufallseffekten (Genetik, Umwelt, Erziehung, usw.) zusammensetzen.\n",
        "- Eine wesentliche Erkenntnis ist, dass statistische Kennwerte wie Mittel-<br>wert oder Varianz ebenfalls auf Summen von Zufallseffekten basieren.\n",
        ":::\n",
        "::: {.column width=\"23%\"}\n",
        "<div class=\"vspace-large\"></div>\n",
        "\n",
        "Beispiel Mittelwert: \n",
        "\n",
        "$$\n",
        "\\quad\\bar{X} = \\frac{1}{N}\\sum x_i\n",
        "$$\n",
        ":::\n",
        "::::\n",
        "\n",
        "\n",
        ":::{style=\"margin-top: -15px\"}\n",
        "Mit anderen Worten: ziehen wir sehr viele Stichproben aus der Grundgesamtheit, berechnen für jede Stichprobe einen statistischen Kennwert (in Bezug auf die betrachtete Merkmalsvariable), so sind diese Kennwerte **normalverteilt** &mdash; und zwar unabhängig von der Verteilung der ursprünglichen Merkmalsvariable in der Population!\n",
        ":::\n",
        "<div class=\"vspace-small\"></div>\n",
        "\n",
        "\n",
        "![](images/central_limit_theorem_average.png)\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## [Form der theoretischen Stichprobenverteilung: Würfelexperiment]{style=\"font-size: 39px\"}\n",
        "\n",
        "\n",
        "Jeder Student bringt einen Würfel mit. \n",
        "\n",
        "Runde 1: alle würfeln, Mittelwert wird notiert\n",
        "\n",
        "Runde 2: \"\"\n",
        "\n",
        "...\n",
        "\n",
        "Runde n\n",
        "\n",
        "Alle Mittelwerte werden als Histogramm aufgetragen -> Normalverteilung?\n",
        "\n",
        "(Beachte: die originale Verteilung ist uniform!)\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Form der theoretischen Stichprobenverteilung\n",
        "\n",
        "<div class=\"vspace-small\"></div>\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"65%\"}\n",
        "Die Form der theoretischen Stichprobenverteilung (SV) ist also geklärt:\n",
        "\n",
        "$$\n",
        "X \\sim \\mathcal{N}(\\mu_\\text{SV},\\,\\sigma_\\text{SV})\n",
        "$$\n",
        "\n",
        "[(in Worten: *wir nehmen an, dass unser Merkmal $X$ aus einer Normalverteilung mit Mittelwert $\\mu_\\text{SV}$ und Standardabweichung $\\sigma_\\text{SV}$ gezogen ist*)]{style=\"font-size: 20px\"}\n",
        "\n",
        ":::\n",
        "::: {.column width=\"35%\"}\n",
        "![](images/inference7_annot.png)\n",
        ":::\n",
        "::::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<div class=\"vspace-medium\"></div>\n",
        "\n",
        "::: {.merke style=\"font-size: 21px !important\"}\n",
        ":::: {.columns}\n",
        "::: {.column width=\"5%\"}\n",
        "::: {style=\"margin-top: 18px\"}\n",
        "![](images/merke.png){height=\"55px\"}\n",
        ":::\n",
        ":::\n",
        "::: {.column width=\"95%\"}\n",
        "Auch wenn wir in den Beispielen vornehmlich den Mittelwert als Stichprobenkennwert betrachten, sind alle statistischen Kennwerte, die wir bis jetzt kennengelernt haben ($\\bar{X}$, $s$, $r$, usw), im Grenzfall $N\\rightarrow\\infty$ normalverteilt. Als Faustregel wird häufig vorgeschlagen, dass ab einer Stichprobengröße von ca. $N=30$ von einer Normalverteilung ausgegangen werden kann.\n",
        ":::\n",
        "::::\n",
        ":::\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Mittelwert der theoretischen Stichprobenverteilung\n",
        "\n",
        "Die beste Schätzung $\\hat{\\mu}_\\text{SV}$ für den wahren Mittelwertsparameter $\\mu_\\text{SV}$ der Stichprobenverteilung ist...\n",
        "\n",
        "... der statistische Kennwert unserer Studie (z.B. $\\bar{X}, s$)!\n",
        "\n",
        "<div class=\"vspace-xlarge\"></div>\n",
        "\n",
        "::: {.example style=\"font-size: 25px !important\"}\n",
        ":::: {.columns}\n",
        "::: {.column width=\"10%\"}\n",
        "::: {style=\"margin-top: 10px\"}\n",
        "![](images/example.png){height=70px}\n",
        ":::\n",
        ":::\n",
        "::: {.column width=\"50%\"}\n",
        "\n",
        "**Beispiel Mittelwert.** Ist der Mittelwert der betrachtete statistische Stichprobenkennwert, so gilt: \n",
        "\n",
        "$$\n",
        "\\hat{\\mu}_\\text{SV} = \\bar{X}\n",
        "$$\n",
        "\n",
        "&xrarr; Die theoretische Stichprobenverteilung wird also in diesem Fall um den Stichprobenmittelwert $\\bar{X}$ herum konstruiert.\n",
        "\n",
        ":::\n",
        "::: {.column width=\"40%\"}\n",
        "![](images/inference8_annot.png){height=200px}\n",
        ":::\n",
        "::::\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Streuung der theoretischen Stichprobenverteilung\n",
        "\n",
        "\n",
        "Bleibt die Frage nach dem Streuungsparameter $\\sigma_\\text{SV}$: woher wissen wir, wie die Ergebnisse von hypothetischen Stichproben streuen würden?\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"32%\"}\n",
        "Gehen wir dazu zu unserem Gedankenexperiment zurück:\n",
        ":::\n",
        "::: {.column width=\"68%\"}\n",
        "![](images/inference1_annot.png)\n",
        ":::\n",
        "::::\n",
        "\n",
        "**Was würde die Streuung der möglichen Ergebnisse verkleinern?**\n",
        "\n",
        "1. Wir ziehen nicht 3 Personen in unserer Studie, sondern 6<br>&xrarr; damit lägen fast alle Stichproben näher am wahren Mittelwert!\n",
        "2. Wir hätten in der Grundgesamtheit grundsätzlich eine geringere Streuung der Werte<br>&xrarr; damit würden auch die Mittelwerte einzelner Studien weniger streuen.\n",
        "\n",
        "Der Streuungsparameter $\\sigma_\\text{SV}$ der theoretischen Stichprobenverteilung muss also eine Funktion der Stichprobengröße $N$ und der Streuung $\\sigma$ in der Grundgesamtheit sein. \n",
        "\n",
        "<div class=\"vspace-xsmall\"></div>\n",
        "\n",
        "$$\n",
        "\\hat{\\sigma}_\\text{SV} = SE = f(N, \\sigma)\n",
        "$$\n",
        "\n",
        "<div class=\"vspace-xsmall\"></div>\n",
        "\n",
        "Als Begriff für die Streuung der Stichprobenverteilung hat sich [**Standardfehler**]{color=\"navy\"} (engl. *standard error*; *SE*) eingebürgert.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Beispiel: Standardfehler des Mittelwertes\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"68%\"}\n",
        "\n",
        "- Ein für Statistik 1 besonders wichtiger Standardfehler ist der Standardfehler des Kennwertes *Mittelwert*.\n",
        "- Er wird als **Standardfehler des Mittelwertes** oder engl. *standard error of the mean* (*SEM*) bezeichnet.\n",
        "- Er berechnet sich als die Standardabweichung der Grundgesamtheit $\\sigma$ geteilt durch die Wurzel aus der Stichprobengröße $N$ (\"Wurzel-N-Gesetz\"):\n",
        ":::\n",
        "::: {.column width=\"32%\"}\n",
        "![](images/stichprobenverteilung.png)\n",
        ":::\n",
        "::::\n",
        "\n",
        "\n",
        "::: {style=\"margin-top: -5px\"}\n",
        "$$\n",
        "\\text{Standardfehler des Mittelwertes:}\\qquad\\hat{\\sigma}_\\text{SV} = SEM = \\frac{\\hat{\\sigma}}{\\sqrt{N}}\n",
        "$$\n",
        ":::\n",
        "\n",
        "- Da der wahre Streuungsparameter $\\sigma$ der Grundgesamtheit unbekannt ist, verwenden wir die Schätzung $\\hat{\\sigma}$ auf Basis der Streuung der Stichprobendaten (&rarr; dazu kommen wir gleich noch einmal).\n",
        "- Intuitiv sagt der Standardfehler des Mittelwertes aus, wie sicher wir uns bei der Bestimmung des Mittelwertes sein können\n",
        "    - Großer Standardfehler: Gemessener Mittelwert ist eher unsicher\n",
        "    - Kleiner Standardfehler: Gemessener Mittelwert ist eher sicher\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Beispiel: Standardfehler des Mittelwertes\n",
        "\n",
        "\n",
        "::: {.merke .vcenter}\n",
        ":::: {.columns}\n",
        "::: {.column width=\"5%\"}\n",
        "::: {style=\"margin-top: 18px\"}\n",
        "![](images/merke.png){height=\"55px\"}\n",
        ":::\n",
        ":::\n",
        "::: {.column width=\"95%\"}\n",
        "**Beachte:** der Standardfehler des Mittelwertes allein sagt nichts über die Streubreite des Merkmals. Der Standardfehler kann klein sein, obwohl die Standardabweichung $\\sigma$ des gemessenen Merkmals groß ist, wenn im Gegenzug die Stichprobengröße $N$ auch groß ist. Umgekehrt kann ein Standardfehler groß sein, obwohl die Standardabweichung $\\sigma$ klein ist, wenn $N$ klein ist.\n",
        ":::\n",
        "::::\n",
        ":::\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## [Herleitung des Standardfehlers]{color=\"darkred\"}\n",
        "\n",
        "![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=130px}\n",
        "\n",
        "- Der Standardfehler ist ein Maß für die **Variabilität der Stichprobenmittelwerte** $\\bar{X}$ &mdash; dies können wir zunächst über die Varianz zum Ausdruck bringen:\n",
        "\n",
        "$$\n",
        "\\text{Variabilität der Stichprobenmittelwerte} = Var(\\bar{X})\n",
        "$$\n",
        "\n",
        "- Wir wissen, dass $\\bar{X} = \\frac{1}{N}\\sum X_i$, also:\n",
        "\n",
        "$$\n",
        "Var(\\bar{X}) = Var\\left(\\frac{1}{N}\\sum X_i\\right)\n",
        "$$\n",
        "\n",
        "- Um das $\\frac{1}{N}$ aus der Varianz herausziehen zu können, versichern wir uns einer kleinen Rechenregel:\n",
        "$$\n",
        "Var(aX) = \\frac{1}{N}\\left(aX_i-a\\bar{X}\\right)^2 = \\frac{a^2}{N}\\left(X_i-\\bar{X}\\right)^2 = a^2Var(X)\n",
        "$$\n",
        "\n",
        "- Daraus folgt:\n",
        "\n",
        "$$\n",
        "Var(\\bar{X}) = \\frac{1}{N^2}Var\\left(\\sum X_i\\right)\n",
        "$$\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## [Herleitung des Standardfehlers]{color=\"darkred\"}\n",
        "\n",
        "![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=130px}\n",
        "\n",
        "$$\n",
        "\\text{Zwischenergebnis}\\qquad Var(\\bar{X}) = \\frac{1}{N^2}Var\\left(\\sum X_i\\right) \n",
        "$$\n",
        "\n",
        "- Die Summe in der Varianz stört noch. Glücklicherweise gilt, dass die Varianz der Summe von unabhängigen Zufallsvariablen $X_i$ gleich der Summe der Varianzen ist, d.h. \n",
        "\n",
        "$$\n",
        "Var\\left(\\sum X_i\\right)=\\sum Var(X_i)\n",
        "$$\n",
        "\n",
        "- Daraus folgt:\n",
        "\n",
        "$$\n",
        "Var(\\bar{X}) = \\frac{1}{N^2}\\sum Var(X_i) = \\frac{1}{N^2}\\big(N\\cdot Var(X_i)\\big) = \\frac{1}{N}Var(X_i)\n",
        "$$\n",
        "\n",
        "- Nun sind wir fast am Ziel. Wir ersetzen $Var$ jeweis durch $\\sigma^2$:\n",
        "\n",
        "$$\n",
        "\\sigma_\\bar{X}^2 = \\frac{\\sigma^2}{N} \\qquad \\text{bzw.} \\qquad \\sigma_\\bar{X} = \\frac{\\sigma}{\\sqrt{N}} = SEM\n",
        "$$\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## [Weitere Standardfehler]{color=\"darkred\"}\n",
        "\n",
        "![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=110px}\n",
        "\n",
        "\n",
        "<!---  Table --->\n",
        "|Maß|Standardfehler|Kommentar|\n",
        "|-|-|-|\n",
        "| Median | $SE(MD) = \\sqrt{\\frac{\\pi}{2}}\\frac{s}{\\sqrt{n}}$ | Annahme: Normalverteilung |\n",
        "| Varianz | $SE(s^2) = \\sqrt{\\frac{2}{n-1}}s^2$ | Annahme: Normalverteilung |\n",
        "| Standardabweichung | $SE(s) = \\frac{s}{\\sqrt{2(n-1)}}$ | Näherung; Annahme: Normalverteilung |\n",
        "|Korrelation|$SE(r) = \\sqrt{\\frac{1-r^2}{N-2}}$|Näherung; Hinweis: laut neuerer Forschung ist $SE(r) = \\sqrt{\\frac{1-r^2}{N-3}}$ sogar ein noch besserer Schätzer^[Gnambs T. A Brief Note on the Standard Error of the Pearson Correlation. https://psyarxiv.com/uts98/]|\n",
        "|Cohen's d (abhängige Messungen)|$SE(d) = \\sqrt{\\frac{1}{N}+\\frac{d^2}{2N}}$|Näherung|\n",
        "|Cohen's d (unabhängige Messungen)|$SE(d) = \\sqrt{\\frac{N_1+N_2}{N_1N_2}+\\frac{d^2}{2(N_1+N_2)}}$|Näherung; Quelle^[n^[https://stats.stackexchange.com/questions/495015/what-is-the-formula-for-the-standard-error-of-cohens-d]:]|\n",
        ": {tbl-colwidths=\"[25, 20, 55]\"}\n",
        "\n",
        "Nützliches Paper^[Harding B, Tremblay C, Cousineau D (2014) Standard errors: A review and evaluation of standard error estimators using Monte Carlo simulations. TQMP 10:107–123.]\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Zwischenfazit\n",
        "\n",
        "::: {.colorbox .fragment style=\"margin-bottom:15px\"}\n",
        "Die theoretische Stichprobenverteilung folgt einer **Normalverteilung** (falls N groß genug) mit einem **Mittelwert**, der dem **statistischen Kennwert** entspricht, und einer Standardabweichung, die sich aus der Populationsstreuung $\\sigma$ und der Stichprobengröße $N$ berechnet (der sog. **Standardfehler**).\n",
        ":::\n",
        "\n",
        "- Der **zentrale Parameter** der theoretischen Stichprobenverteilung ist der **Standardfehler**: er gibt Auskunft darüber wie verlässlich unsere Schätzung des statistischen Kennwertes ist.\n",
        "- Wie wir noch sehen werden umfasst $1 SE$ die mittleren 68% der möglichen Ergebnisse in der theoretischen Stichprobenverteilung.\n",
        "\n",
        "<!---  Example --->\n",
        "::: {.example}\n",
        ":::: {.columns}\n",
        "::: {.column width=\"10%\"}\n",
        "::: {style=\"margin-top: 10px\"}\n",
        "![](images/example.png){height=70px}\n",
        ":::\n",
        ":::\n",
        "::: {.column width=\"55%\"}\n",
        "Nehmen wir an, die Nasenlängen der Männer in unserer Studie weisen eine durchschnittliche Länge von $6cm$ auf und einen Standardfehler (des Mittelwertes) von $0{,}5cm$. \n",
        "\n",
        "**Wir können damit sagen, dass sich der wahre Mittelwert der Grundgesamtheit mit 68% Wahrscheinlichkeit in dem Intervall** \n",
        "\n",
        "$$\n",
        "[\\bar{X}-SEM; \\bar{X}+SEM] = [6-0{,}5; 6+0{,}5] = [5{,}5; 6{,}5]\n",
        "$$\n",
        "\n",
        "**befinden wird**.\n",
        "\n",
        "\n",
        ":::\n",
        "::: {.column width=\"35%\"}\n",
        "![](images/sem_example.png){height=280px}\n",
        ":::\n",
        "::::\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Interpretation des Standardfehlers\n",
        "\n",
        "<div class=\"vspace-medium\"></div>\n",
        "\n",
        "**Wie kann man den Wert eines Standardfehlers interpretieren?**\n",
        "\n",
        "- Lässt sich pauschal nicht beantworten, da der Standardfehler von der Messskala abhängt\n",
        "    - Er ist keine standardisierte Größe wie z.B. der Korrelationskoeffizient.\n",
        "- Prinzipiell gilt: je kleiner, desto besser (d.h. desto präziser ist unsere Kennwertschätzung)\n",
        "- Anhaltspunkt: Vergleich/Verhältnis zur Skala (besonders einfach bei Ratingskalen wie 1-10) oder zur Standardabweichung in der Stichprobe:\n",
        "\n",
        "<div class=\"vspace-large\"></div>\n",
        "\n",
        "<!---  Example --->\n",
        "::: {.example}\n",
        ":::: {.columns}\n",
        "::: {.column width=\"10%\"}\n",
        "::: {style=\"margin-top: 10px\"}\n",
        "![](images/example.png){height=70px}\n",
        ":::\n",
        ":::\n",
        "::: {.column width=\"90%\"}\n",
        "Nehmen wir wieder unser Nasenlängen-Beispiel mit $\\bar{X}=6cm$ und $SEM=0{,}5cm$, und nehmen wir an, die Standard*abweichung* von Nasenlängen in der Stichprobe betrug $5cm$. In diesem Fall hätten wir den Mittelwert mit einer Präzision von 10% der Streubreite in der Stichprobe geschätzt, was einer recht guten/präzisen Schätzung entspricht.\n",
        "\n",
        "(Als kleine Übung: wie hoch müsste in diesem Beispiel die Stichprobenzahl gewesen sein? Spoiler: $N=100$)\n",
        ":::\n",
        "::::\n",
        ":::\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Verwendung des Standardfehlers in der Praxis\n",
        "\n",
        "- Im Text wird der Standardfehler des Mittelwertes oft in folgender Form angegeben: $M = 3 \\pm 0,6 (SEM)$. \n",
        "    - Wichtig: es sollte immer angegeben werden, dass es sich beim Streuungsmaß um den Standardfehler handelt.\n",
        "- In Abbildungen wird der Standardfehler ähnlich wie die Standardabweichung häufig in Form von Fehlerbalken dargestellt:\n",
        "\n",
        "<div class=\"vspace-small\"></div>\n",
        "\n",
        "![](images/sem_praxis.png)\n",
        "\n",
        "- Ist das Hauptinteresse ob sich Experimentalbedingungen **in ihrem Mittelwert unterscheiden**, ist der **Standardfehler aussagekräftiger** als die Varianz oder Standardabweichung\n",
        "    - Aus diesem Grund ist der Standardfehler des Mittelwertes das vielleicht häufigste Streuungsmaß in der Psychologie\n",
        "\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Schätzung der Standardabweichung in der Grundgesamtheit\n",
        "\n",
        "- Beim Mittelwert gilt, dass der Mittelwert $\\bar{X}$ der Stichprobe die beste Schätzung $\\hat{\\mu}$ für den wahren Mittelwertsparameter $\\mu$ der Grundgesamtheit ist:\n",
        "\n",
        "$$\n",
        "\\text{Schätzung des Populationsmittelwertes:}\\qquad\\hat{\\mu} = \\bar{X}\n",
        "$$\n",
        "\n",
        "- Bei der Varianz/Standardabweichung gilt dies nur (näherungsweise) für große Stichproben. Für kleinere Stichproben gilt leider nicht $\\hat{\\sigma}^2 = s^2$.\n",
        "- Grund: um die Streuung in der Grundgesamtheit zu schätzen, müsste eigentlich die Streuung der $x_i$ **um den wahren Mittelwert $\\mu$** berechnet werden.\n",
        "    -  $\\mu$ kennen wir aber nicht, sondern lediglich $\\bar{X}$.\n",
        "- Es stellt sich heraus, dass die Streuung der $x_i$ um den Mittelwert $\\bar{X}$ der Stichprobe immer etwas kleiner ist, als es die Streuung der $x_i$ um den wahren Wert $\\mu$ wäre.\n",
        "    - Das ist durchaus intuitiv, da der Mittelwert $\\bar{X}$ *aus den* $x_i$ *selbst* bestimmt wird.\n",
        "- Dies führt zur **Besselkorrektur** &#x2398;\n",
        "\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Besselkorrektur\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"70%\"}\n",
        "- Der deutsche Naturwissenschaftler Friedrich Wilhelm Bessel zeigte, dass für eine Schätzung $\\hat{\\sigma}^2$ der Populationsstreuung auf Basis der Stichprobenstreuung $s^2$, der Faktor $\\frac{1}{N}$ in der Varianzformel durch $\\frac{1}{N-1}$ ersetzt werden muss:\n",
        "\n",
        "$$\n",
        "\\text{Schätzung der Populationsvarianz:}\\\\\n",
        "\\hat{\\sigma}^2 = \\frac{N}{N-1}s = \\frac{1}{N\\color{darkgreen}{-1}}\\sum\\left(x_i-\\bar{X}\\right)^2\n",
        "$$\n",
        "\n",
        ":::\n",
        "::: {.column width=\"30%\"}\n",
        "![Friedrich Wilhelm Bessel (1748-1846)^[http://www.digiporta.net/index.php?id=658493715]](images/portrait_bessel.png)\n",
        ":::\n",
        "::::\n",
        "\n",
        "- Wir bezeichnen $\\hat{\\sigma}^2$ als **Schätzung der Populationsvarianz auf Basis der Stichprobe** oder kurz [**biaskorrigierte Stichprobenvarianz**]{color=\"navy\"}.\n",
        "- Intution: die Varianz wird im Fall von $\\frac{1}{N-1}$ *durch weniger geteilt* als beim ursprünglichen Faktor $\\frac{1}{N}$, d.h. die resultierende Varianz wird *zu einem größeren Wert hin* korrigiert.\n",
        "- Die \"$N-1$\"-Korrektur für Stichproben wird als [**Besselkorrektur**]{color=\"navy\"} bezeichnet.\n",
        "- Ab ca. $N=30$ spielt die Besselkorrektur kaum eine Rolle mehr ($\\frac{1}{30}=0.033$ vs. $\\frac{1}{29}=0.034$)\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## [Herleitung des Faktors $\\frac{1}{N-1}$]{color=\"darkred\"}\n",
        "\n",
        "![](images/kein_klausurstoff.png){.absolute bottom=60 right=0 height=110px}\n",
        "\n",
        "- Der Ausgangspunkt der Besselkorrektur die Beobachtung, dass die (unkorrigierte) Varianz der Stichprobe die Varianz der Grundgesamtheit systematisch unterschätzt.\n",
        "- Der Grund ist, dass der empirische Mittelwert $\\bar{X}$ keine perfekte Schätzung für den wahren Mittelwert $\\mu$ ist &mdash; er streut um $\\mu$.\n",
        "- Diese Streuung haben wir gerade kennengelernt &mdash; es ist der Standardfehler $\\sigma_\\bar{X} = \\frac{\\sigma}{\\sqrt{N}}$. Als Varianz formuliert:\n",
        "\n",
        "::: {style=\"margin-top:-15px\"}\n",
        "$$\n",
        "\\sigma_\\bar{X}^2 = \\frac{\\sigma^2}{N}\\quad\\text{bzw.}\\quad \\sigma_\\bar{X}^2 = \\frac{s^2}{N}\\quad\\scriptsize{\\text{(da wir die Varianz in der Stichprobe bestimmen: $\\sigma^2\\rightarrow s^2$)}}\n",
        "$$\n",
        ":::\n",
        "\n",
        "- Aufgrund der *zusätzlichen* Variabilität durch die Unsicherheit des Mittelwertes, muss die Varianz des Mittelwertes $\\sigma_\\bar{X}^2$  auf die (unkorrigierte) Varianz der Stichprobe addiert werden:\n",
        "\n",
        "::: {style=\"margin-top:-20px\"}\n",
        "$$\n",
        "s^2 = s_{unkorrigiert}^2 + \\sigma_\\bar{X}^2 = s_{unkorrigiert} + \\frac{s^2}{N}\\quad \\longrightarrow\\quad s^2 - \\frac{s^2}{N} = s_{unkorrigiert}\n",
        "$$\n",
        ":::\n",
        "\n",
        "- Linke Seite umformen:\n",
        "\n",
        "::: {style=\"margin-top:-15px\"}\n",
        "$$\n",
        "s^2 - \\frac{s^2}{N} = s^2\\left(1 - \\frac{1}{N}\\right) = s^2\\frac{N-1}{N} = s_{unkorrigiert}^2 \\;\\;\\longrightarrow\\;\\; s^2 = \\frac{N}{N-1}s_{unkorrigiert}^2\n",
        "$$\n",
        ":::\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## [Herleitung des Faktors $\\frac{1}{N-1}$]{color=\"darkred\"}\n",
        "\n",
        "![](images/kein_klausurstoff.png){.absolute bottom=30 right=0 height=110px}\n",
        "\n",
        "$$\n",
        "\\text{Zwischenergebnis:}\\qquad s^2 = \\frac{N}{N-1}s_{unkorrigiert}^2\n",
        "$$\n",
        "\n",
        "- Die unkorrigierte Varianz $s_{unkorrigiert}^2$ lautet:\n",
        "\n",
        "::: {style=\"margin-top:-25px\"}\n",
        "$$\n",
        "s_{unkorrigiert}^2 = \\frac{1}{N}\\sum\\left(x_i-\\bar{X}\\right)^2\n",
        "$$\n",
        ":::\n",
        "\n",
        "- Einsetzen:\n",
        "\n",
        "$$\n",
        "s^2 = \\frac{N}{N-1}s_{unkorrigiert}^2 = \\frac{N}{N-1}\\frac{1}{N}\\sum\\left(x_i-\\bar{X}\\right)^2 = \\color{navy}{\\frac{1}{N-1}}\\sum\\left(x_i-\\bar{X}\\right)^2\n",
        "$$\n",
        "\n",
        "- Nun haben wir unseren Faktor $\\color{navy}{\\frac{1}{N-1}}$. \n",
        "- Für die korrigierte Standardabweichung der Stichprobe wird häufig analog angenommen:\n",
        "\n",
        "$$\n",
        "s = \\sqrt{\\color{navy}{\\frac{1}{N-1}}\\sum\\left(x_i-\\bar{X}\\right)^2}\n",
        "$$\n",
        "\n",
        "- Diese analoge Korrektur für die Standardabweichung ist nicht 100% gültig^[https://en.wikipedia.org/wiki/Unbiased_estimation_of_standard_deviation] &mdash; für alle<br>praktischen Zwecke reicht sie aber aus.\n",
        "\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "##\n",
        ":::: {.columns}\n",
        "::: {.column width=\"9%\"}\n",
        "::: {style=\"margin-top:-15px\"}\n",
        "![](images/summary.png)\n",
        ":::\n",
        ":::\n",
        "::: {.column width=\"91%\"}\n",
        "::: {.summary}\n",
        "- Im Zuge der Inferenzstatistik wird untersucht, wie gut **Schätzungen von Parametern in der Grundgesamtheit** auf Basis von **Stichprobenkennwerten** sind.\n",
        "- Es geht also um die **Verallgemeinerbarkeit** von Stichprobendaten auf die Grundgesamtheit\n",
        "- Generelle Idee: Was würde passieren, wenn die Studie immer wieder durchgeführt und der Kennwert bestimmt würde?\n",
        "- Diese Idee wird durch die **theoretische Stichprobenverteilung** repräsentiert.\n",
        "- Die Stichprobenverteilung von Kennwerten ist laut dem Zentralen Grenzwertsatz **normalverteilt**.\n",
        "- Die Standardabweichung dieser Stichprobenverteilung wird **Standardfehler** genannt.\n",
        ":::\n",
        ":::\n",
        "::::\n",
        "\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## {.center}\n",
        "\n",
        "![Bildnachweis^[http://www.peaya.com/peaya.php?comicsid=1005]](images/peaya_sem.png)\n"
      ],
      "id": "516926f7"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}