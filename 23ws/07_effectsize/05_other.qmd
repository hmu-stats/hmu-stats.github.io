<!----------------->
<!--- New slide --->
<!----------------->
## Absolute Risikoreduktion (ARR)

Sind beide Variablen dichotom, sind weder der Korrelationskoeffizient noch Cohen's d intuitive Effektmaße. 

<!---  Example --->
::: {.example .fragment}
|||
|:-:|-|
| ![](images/example.png){height=70px} | Sie untersuchen, ob ein neues Medikament die Heilungsrate (Erfolgsrate) einer Krankheit verbessert. Die Treatmentgruppe erhält das Medikament, die Kontrollgruppe Placebo.
: {tbl-colwidths="[10, 90]"}
:::

:::{.fragment}
Eine sinnnvolles Effektmaß ist hier, *um wie viel* die Erfolgsrate in der Treatmentgruppe die Erfolgsrate in der Kontrollgruppe übersteigt. Dies lässt sich einfach aus einer Vierfeldertafel ableiten:
:::

:::: {.columns .fragment}
::: {.column width="50%"}
![](images/vierfeldertafel3.png)
:::
::: {.column width="50%"}
![](images/arr.png)

:::
::::

- $ARR$ ist die [**Absolute Risikoreduktion**]{color="navy"}.

<!----------------->
<!--- New slide --->
<!----------------->
## Numbers Needed to Treat (NNT)

- Noch gängiger als die Absolute Risikoreduktion ist die inverse Größe, die als [**Numbers Needed to Treat (NNT)**]{color="navy"} bezeichnet wird.

::: {.definition .fragment}
<!---  Definition--->
|||
|:-:|-|
|||
| ![](images/definition.svg){height=70px} | **Number Needed to Treat:** Anzahl der Personen, die behandelt werden müssten, damit eine zusätzliche Person einen Nutzen hat. | 
|||
: {tbl-colwidths="[10, 90]"}

:::

:::{.fragment}
Mathematisch ist $NNT$ das Inverse der $ARR$:

$$
NNT = \frac{1}{ARR}
$$
:::

- Da es um Personen geht, wird die NNT immer aufgerundet.

<!---  Example --->
::: {.example .fragment style="border-width: 0 !important"}
||||
|:-:|-|-|
||||
| ![](images/example.png){height=60px} | ![](images/vierfeldertafel_numbers.png) | $ARR = \frac{90}{90+10} - \frac{35}{35+35}=0{,}9-0{,}5=0{,}4\quad\rightarrow\quad NRR=\frac{1}{0{,}4}=2{,}5$ \
&rArr; Drei weitere Personen müssten behandelt werden, damit eine zusätzliche Person einen Nutzen hat (d.h. die andernfalls nicht geheilt würde).|
||||
: {tbl-colwidths="[10, 30, 60]"}

:::


<!----------------->
<!--- New slide --->
<!----------------->
## Numbers Needed to Treat (NNT)

:::{.nonincremental}
- Auch wenn das Ziel von $NNT$ eine einfache laienverständliche Kommunikation der Treatmenteffizienz ist, darf angezweifelt werden, ob dies immer der Fall ist, wie durch folgendes Beispiel demonstriert^[Andrade C (2015) The Numbers Needed to Treat and Harm (NNT, NNH) Statistics: What They Tell Us and What They Do Not: (Practical Psychopharmacology). J Clin Psychiatry 76:e330–e333.
]:
:::

![](images/quote_NNT.png)



<!----------------->
<!--- New slide --->
<!----------------->
## Odds Ratio (OR)

:::{.nonincremental}
- Das [**Odds Ratio**]{color="navy"} ($OR$) vergleicht das *Heilerfolgsverhältnis in der Treatmentgruppe* zum *Heilerfolgsverhältnis in der Kontrollgruppe*:
:::

:::: {.columns}
::: {.column width="50%"}
![](images/vierfeldertafel3.png){height=200px}

:::
::: {.column width="50%"}
$$
\text{OR} = \frac{\frac{a}{b}}{\frac{c}{d}} = \frac{a\cdot c}{b\cdot d}
$$

[Beachte: Als Heilerfolgsverhältnis wird hier das Verhältnis der Zahl der geheilten Patienten gegenüber der Zahl der nicht geheilten Patienten verstanden.]{style="font-size: 20px; line-height: 1.05 !important; display: block; margin-top: 40px; color:#777"}

:::
::::

- Hat das Treatment keine Auswirkung, so sind die Heilerfolgsverhältnisse in beiden Gruppen gleich, d.h. $OR=1$.
- Ist das Treatment erfolgreich, ist das Heilerfolgsverhältnis in der Treatmentgruppen höher als in der Kontrollgruppe, d.h. $OR>1$.
- Ist das Treatment sogar nachteilig, ist das Heilerfolgsverhältnis in der Treatmentgruppen *kleiner* als in der Kontrollgruppe, d.h. $OR<1$.

::: {.notabene .fragment}
:::: {.columns}
::: {.column width="7%"}
::: {style="margin-top: 10px"}
![](images/notabene2.png){height="65px"}

:::
:::
::: {.column width="93%"}
Als kleine Übung kann man das Odds Ratio für die beiden hypothetischen Beispiele auf der vorherigen Folie berechnen. Spoiler: das Odds Ratio ist für beide Fälle gleich ($OR=13.5$)!

:::
::::
:::

## Übersicht Effektmaße

<div class="vspace-medium"></div>

![](images/overview_effectsizes.png){height=600px}


<!----------------->
<!--- New slide --->
<!----------------->
## [Referenz]{color="darkred"}

![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=110px}

Empfehlungen nach Lakens (2013)^[Lakens D (2013) Calculating and reporting effect sizes to facilitate cumulative science: a practical primer for t-tests and ANOVAs. Frontiers in Psychology 4 Available at: https://www.frontiersin.org/articles/10.3389/fpsyg.2013.00863]:

![](images/effectsizes_recommendation_lakens2013.png)

<!----------------->
<!--- New slide --->
<!----------------->
## [Standardisierte Effektstärken für Mittelwertunterschiede: aktuelle Forschung]{style="font-size:33px; color: darkred"}

![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=110px}

Ein Problem der vorgestellten Effektmaße für abhängige Messungen, ist, dass sie nicht vergleichbar sind mit Effektmaßen für unabhängige Messungen. Es sind streng genommen **unterschiedliche Skalen**.

Eine aktuelle Forschungsarbeit^[Cousineau D (2020) Approximating the distribution of Cohen’s d_p in within-subject designs. TQMP 16:418–421.] bietet dafür eine Lösung mit folgender (komplizierterer) Formel:

$$
d = \sqrt{\frac{2(1-r)}{n}}\cdot t'_\nu(\lambda)\quad\text{mit}\quad \lambda = \sqrt{\frac{n}{2(1-r)}}\cdot\frac{\bar{x}_A - \bar{x}_B}{\hat{\sigma}}
$$

wobei $r$ die Pearson-Korrelation zwischen den beiden abhängigen Messungen ist und $t'$ die nichtzentrale *t*-Verteilung mit $\nu = 2(n − 1)/(1 + r^2)$ Freiheitsgraden. Zu beachten ist, dass die Formel nur gilt, falls gleiche Standardabweichungen in den beiden Bedingungen angenommen werden können($\sigma=\sigma_A=\sigma_B$).

Laut dem Autor der Forschungsarbeit ist diese Formel sowohl auf abhängige als auch unabhängige Messungen anwendbar.

Weiterer nützlicher Link: ^[http://jakewestfall.org/blog/index.php/2016/03/25/five-different-cohens-d-statistics-for-within-subject-designs/]





<!-- ```{python}
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import os
import seaborn as sns

np.random.seed(0)
root = '/home/matteo/OneDrive/lehre/Statistik/stats1_lecture/book/'

fontsize = 15
color = 'k'

N = 50

df = pd.read_csv(os.path.join(root, 'data', 'paradoxia.csv'))
# print(df.head())

data_tiktok_control = df[df.group == 1]['hours_tiktok_per_day'].values
data_tiktok_paradoxia = df[df.group == 2]['hours_tiktok_per_day'].values
data_inflam_control = df[df.group == 1]['inflammation'].values
data_inflam_paradoxia = df[df.group == 2]['inflammation'].values

d_tiktok = (np.mean(data_tiktok_paradoxia) - np.mean(data_tiktok_control)) / np.sqrt((np.var(data_tiktok_paradoxia)+np.var(data_tiktok_control))/(2*(1-1/N)))
d_inflam = (np.mean(data_inflam_paradoxia) - np.mean(data_inflam_control)) / np.sqrt((np.var(data_inflam_paradoxia)+np.var(data_inflam_control))/(2*(1-1/N)))

# Formula from https://stats.stackexchange.com/questions/495015/what-is-the-formula-for-the-standard-error-of-cohens-d
d_se_tiktok = (8+d_tiktok**2)/(4*N)
d_se_inflam = (8+d_inflam**2)/(4*N)

plt.style.use('dark_background')
plt.figure(figsize=(3, 2.5))
plt.gca().set_facecolor('#eee')
plt.errorbar([0], [d_tiktok], yerr=[d_se_tiktok], fmt='o', markersize=4, capsize=10, capthick=2, elinewidth=2, ecolor=color, mfc=color, mec=color, zorder=3)
plt.errorbar([1], [d_inflam], yerr=[d_se_inflam], fmt='o', markersize=4, capsize=10, capthick=2, elinewidth=2, ecolor=color, mfc=color, mec=color, zorder=3)
plt.text(0, 0.07, r'$d=' + f'{d_tiktok:.2f}'.replace('.', '{,}') + '$', ha='center', color='k', fontsize=fontsize-2)
plt.text(1, 0.07, r'$d=' + f'{d_inflam:.2f}'.replace('.', '{,}') + '$', ha='center', color='k', fontsize=fontsize-2)

plt.xticks([0, 1], ['TikTok', 'Entzündung'], fontsize=fontsize)
plt.yticks(fontsize=fontsize-2)
plt.ylabel("Cohen's $d$", fontsize=fontsize)
plt.xlabel('')
plt.xlim(-0.5, 1.5)
plt.ylim(0, 1.6)
plt.grid(True, color='#e2e2e2')


plt.savefig('images/paradoxia_cohensd.png', bbox_inches='tight')

``` -->

## {.blackslide .center}

<div class="vspace-medium"></div>

:::: {.columns}
::: {.column width="65%"}
Sie berechnen nun Cohen's d für die beiden Gruppenunterschiede hinsichtlich der TikTok-Zeit und Entzündungswerte:
:::
::: {.column width="35%"}
::: {.content-hidden when-format="pdf"}
![](images/paradoxia_group_of_scientists.png){.hcenter-image height=200px style="margin-top:-100px !important"}
<!-- Source: Midjourney -->

:::
:::
::::

:::: {.columns}
::: {.column width="70%"}
<div class="vspace-large"></div>
![](images/paradoxia_cohensd.png){height=300px}
:::
::: {.column width="30%"}
::: {.caption-style style="margin-top:250px !important; margin-left:-180px"}
Hinweis: in der Abbildung wurde nicht nur die Effektstärke selbst aufgetragen, sondern auch ein Streuungsmaß der Effektstärke (Standardfehler der Effektstärke). Dazu kommen wir in Vorlesung 08.
:::
:::
::::

Langsam schärft sich das Bild: während die Entzündungswerte höchstens eine mittlere Effektstärke aufweisen ($d=0{,}33$), ist der TikTok-Effekt beeindruckend groß: $\;d=0{,}93$.