{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Vorlesung 07: Effektstärke\"\n",
        "---"
      ],
      "id": "13d86ad9"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## {.blackslide .center}\n",
        "\n",
        "<div class=\"vspace-small\"></div>\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"68%\"}\n",
        "Sie sinnieren weiterehin über das Ergebnis Ihrer Beobachtungsstudie. Paradoxiker verbringen sowohl mehr Zeit auf TikTok, als auch weisen sie höhere Entzündungswerte auf. Zwar ist der Mittelwertsunterschied bei der TikTok-Zeit größer, aber Sie wissen, dass TikTok-Zeit und Entzündungswerte völlig unterschiedliche Skalen und daher nicht vergleichbar sind. \n",
        "\n",
        ":::\n",
        "::: {.column width=\"32%\"}\n",
        "::: {.content-hidden when-format=\"pdf\"}\n",
        "![](images/paradoxia_group_of_scientists.png){.hcenter-image height=200px style=\"margin-top:-20px !important\"}\n",
        "<!-- Source: Midjourney -->\n",
        ":::\n",
        ":::\n",
        "::::\n",
        "\n",
        "<div class=\"vspace-medium\"></div>\n",
        "![](images/paradoxia_histogram_inflammation_mean_std.png){height=300px}\n",
        "\n",
        "Die Frage lautet: wie kann man die beiden Gruppenunterschiede bezüglich TikTok-Zeit und Entzündungsparametern vergleichbar machen? Wie können wir eine Aussage treffen, welcher der beiden Effekte [stärker]{.underline} ist?\n",
        "\n",
        "\n",
        "# Effektstärke\n",
        "\n",
        "\n",
        "## Der Forschungsprozess {.hcenter-slide}\n",
        "\n",
        "```yaml { .animate src=\"images/scientific_process.svg\"}\n",
        "setup:\n",
        "    - element: \"#results\"\n",
        "      modifier: function() { this.node.style.fill = 'green'; }\n",
        "    - element: \"#resultsbg\"\n",
        "      modifier: function() { this.node.style.fill = '#d8ffe2';}\n",
        "```\n",
        "\n",
        "## Effektstärke\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"60%\"}\n",
        "\n",
        "::: {.nonincremental}\n",
        "- In psycholgischer Forschung untersuchen wir in den meisten Fällen die Auswirkung von Variablen $X_i$ auf Variablen $Y_i$.\n",
        "- Diese Auswirkung ist entweder als **Unterschied** (z.B. wenn $X$ die Gruppenzugehörigkeit angibt) oder als **Zusammenhang** (wenn $X$ und $Y$ metrische Variablen mit einer vermuteten kausalen Wechselwirkung sind) messbar &mdash; man spricht auch von [**Effekten**]{color=\"navy\"}.\n",
        ":::\n",
        "\n",
        "\n",
        ":::{style=\"margin-top: -14px\"}\n",
        "- Wie kann die Aussagekraft bzw. Bedeutsamkeit von Effekten bestimmt und kommuniziert werden?\n",
        "    - &rArr; **praktische Signifikanz** (heutiges Thema): ist die Stärke des Effektes *in der Praxis bedeutsam*?\n",
        "    - &rArr; **statistische Signifikanz** (ab Vorlesung 10): kann ein Effekt *allein durch Zufall erklärt werden*?    \n",
        ":::\n",
        "\n",
        ":::\n",
        "::: {.column width=\"40%\"}\n",
        "![Beispiel: Studie zum Wohlbefinden in Regionen mit und ohne Corona-Kontaktsperre](images/mittelwertunterschied.png)\n",
        ":::\n",
        "::::\n",
        "\n",
        "- Die Stärke eines Effektes im Sinne der praktischen Signifikanz wird als [**Effektstärke**]{color=\"navy\"} oder [**Effektgröße**]{color=\"navy\"} bezeichnet. Wir werden nachfolgend den Begriff **Effektstärke** verwenden.\n",
        "- Unterschiedlichen Maße für die Effektstärke werden als [**Effektmaße**]{color=\"navy\"} bezeichnet.\n",
        "\n",
        "## Unstandardisierte und standardisierte Effektstärken\n",
        "\n",
        ":::{.nonincremental}\n",
        "- Mittelwertsdifferenzen, Kovarianzen und Regressionskoeffizienten sind [**unstandardisierte Effektstärken**]{color=\"navy\"}, weil sie in den Rohwerten der Messung vorliegen.\n",
        ":::\n",
        "\n",
        "<!---  Example --->\n",
        "::: {.example .fragment}\n",
        "|||\n",
        "|:-:|-|\n",
        "| ![](images/example.png){height=70px} | **Beispiel Mittelwertunterschied:** der durchschnittliche Größenunterschied von erwachsenen Männern und Frauen in Deutschland beträgt 16**cm**^[https://www.laenderdaten.info/durchschnittliche-koerpergroessen.php]. |\n",
        ": {tbl-colwidths=\"[10, 90]\"}\n",
        ":::\n",
        "\n",
        "<div class=\"vspace-small\"></div>\n",
        "\n",
        "<!---  Example --->\n",
        "::: {.example .fragment}\n",
        "|||\n",
        "|:-:|-|\n",
        "| ![](images/example.png){height=70px} | **Beispiel unstandardisierter Regressionskoeffizient:** je 0,1 Verbesserung in der **Abiturnote** steigt das monatliche Einstiegseinkommen um durschnittlich 70 **Euro**^[Arbeitsberichte Dresdner Soziologie Nr. 21, https://tud.qucosa.de/api/qucosa%3A24622/attachment/ATT-0/]. |\n",
        ": {tbl-colwidths=\"[10, 90]\"}\n",
        ":::\n",
        "\n",
        "- In den beiden genannten Beispielen haben die Effektstärken sinnvolle und interpretierbare Einheiten und wären vergleichbar zwischen Studien.\n",
        "- Gerade in der Psychologie ist dies aber nicht immer gegeben:\n",
        "    - Fragebögen: Punktzahlen hängen willkürlich vom Kodierungsschema und der Zahl der Items ab\n",
        "    - Ratingskalen: Ratingskalen unterscheiden sich häufig (Wohlbefinden auf einer Skala von 0 bis 100%, Wohlbefinden auf einer Skala von -5 bis 5, usw.)\n",
        "- Falls die Skala (z.B. der verwendete Fragebogen) neu oder wenig bekannt ist, wie soll dann der Effekt interpretiert werden? Wann kann er als groß und wann als klein gelten?    \n",
        "\n",
        "## Standardisierte Effektstärken\n",
        "\n",
        "- Um Effektstärken unabhängig von der verwendeten Skala zu vergleichen, werden Effektstärken **standardisiert**.\n",
        "- Die Transformation der **Standardisierung** haben wir bereits bei Variablen kennengelernt (Teilen durch die Standardabweichung $s_X$) &mdash; sie lässt sich analog auch auf Effekte beziehen.\n",
        "- Im Fall von Zusammenhangsanalysen haben wir eine standardisierte Effektstärke bereits kennengelernt: der **Korrelationskoeffizient** ($r$, $r_s$, $\\tau$, $\\phi$). Beispiel Pearson-Korrelation:\n",
        "\n",
        ":::{.fragment}\n",
        "$$\n",
        "r = \\frac{Cov(X,Y)}{s_X s_Y}\n",
        "$$\n",
        "\n",
        ":::\n",
        "- Der Nenner $s_X s_Y$ stellt hier die Standardisierung dar.\n",
        "- Der Korrelationskoeffizient $r$ ist **standardisiert**, da er einheitslos und somit vergleichbar zwischen verschiedenen Variablen oder Skalen ist.\n",
        "\n",
        "::: {.merke .fragment}\n",
        ":::: {.columns}\n",
        "::: {.column width=\"5%\"}\n",
        "::: {style=\"margin-top: 18px\"}\n",
        "![](images/merke.png){height=\"55px\"}\n",
        ":::\n",
        ":::\n",
        "::: {.column width=\"95%\"}\n",
        "Alle Korrelationskoeffizienten ($r$, $r_s$, $\\tau$, $\\phi$) sind bereits Effektstärken.\n",
        ":::\n",
        "::::\n",
        ":::\n",
        "\n",
        "## Die Varianz von Mittelwertunterschieden\n",
        "\n",
        "Bevor wir uns der Standardisierung von Effektstärken bei Mittelwertsunterschieden widmen, lohnt es sich einen Blick darauf zu werfen, wie Varianzen verschiedener Bedingungen in einer Stichprobe (abhängige Messungen) oder verschiedener Stichproben (unabhängige Messungen) miteinander kombiniert werden können.\n",
        "\n",
        ":::{.fragment}\n",
        "***Abhängige* Messungen in *einer* Stichprobe**\n",
        ":::\n",
        "\n",
        ":::{.fragment}\n",
        "Beispiel: Sie messen die Merkfähigkeit einer Stichprobe vor (Bedingung A) und nach (Bedingung B) einer Schlafphase.\n",
        ":::\n",
        "\n",
        "- In diesem Fall können wir die zwei Messwerte $x_{A,i}$ und $x_{B,i}$ auf Versuchspersonenebene direkt voneinander abziehen: $\\;\\;\\Delta x_i = x_{A,i}-x_{B,i}$\n",
        "\n",
        ":::{.fragment}\n",
        "[Die Frage lautet hier:]{.underline} wie groß ist die Variabilität von $\\Delta x_i$?\n",
        ":::\n",
        "\n",
        ":::{.fragment}\n",
        "Wir können diese Variabilität mit der gewohnten Formel berechnen, nur dass wir statt $x_i$  die $\\Delta x_i$ einsetzen:\n",
        "\n",
        "$$\n",
        "\\hat{\\sigma}^2_\\Delta = \\frac{1}{n-1}\\sum \\left(\\Delta x_i - \\Delta \\bar{x}\\right)^2 \\quad bzw.\\quad \\hat{\\sigma}_{\\Delta} = \\sqrt{\\frac{1}{n-1}\\sum \\left(\\Delta x_i - \\Delta \\bar{x}\\right)^2}\n",
        "$$\n",
        ":::\n",
        "\n",
        "::: {.notabene .fragment}\n",
        ":::: {.columns}\n",
        "::: {.column width=\"7%\"}\n",
        "::: {style=\"margin-top: 10px\"}\n",
        "![](images/notabene2.png){height=\"65px\"}\n",
        ":::\n",
        ":::\n",
        "::: {.column width=\"93%\"}\n",
        "Hinweis: Der Faktor in der Varianz lautet hier $\\frac{1}{n-1}$ und nicht $\\frac{1}{n}$. Dies ist die **Besselkorrektur** (s. Vorlesung 08), da wir hier die **Populationsvarianz** auf Basis der Stichprobe schätzen.\n",
        ":::\n",
        "::::\n",
        ":::\n",
        "\n",
        "## Die Varianz von Mittelwertunterschieden\n",
        "\n",
        "Mit einigen mathematischen Tricks lässt sich zeigen, dass die Formel für die Varianz der Differenzwerte auch wie folgt dargestellt werden kann:\n",
        "\n",
        "$$\n",
        "\\hat{\\sigma}^2_\\Delta = \\hat{\\sigma}^2_A + \\hat{\\sigma}^2_B - 2\\,\\hat{Cov}(X_A,X_B) \\quad bzw.\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\hat{\\sigma}_\\Delta = \\sqrt{\\hat{\\sigma}^2_A + \\hat{\\sigma}^2_B - 2\\,\\hat{Cov}(X_A,X_B)}\n",
        "$$\n",
        "\n",
        ":::{.fragment}\n",
        "In dieser Form macht die Formel transparent, was passiert, wenn wir zwei Zufallsvariablen voneinander abziehen:\n",
        ":::\n",
        "\n",
        "- Sind die Zufallsvariablen *nicht korreliert* ($\\hat{Cov}(X_A,X_B)=0$), so ist die Varianz der Differenz einfach der Summe der Einzelvarianzen in den Bedingungen A und B.\n",
        "- Sind die Zufallsvariablen *positiv korreliert* ($\\hat{Cov}(X_A,X_B)>0$), so reduziert sich diese die Summe in Abhängigkeit von der Kovarianz.\n",
        "- Sind die Zufallsvariablen *negativ korreliert* ($\\hat{Cov}(X_A,X_B)<0$), so erhöht sich die Summe in Abhängigkeit von der Kovarianz.<br>(*Subtraktion* der *negativen* Kovarianz resultiert in einer Erhöhung &mdash; \"minus x minus = plus\").\n",
        "\n",
        "## Die Varianz von Mittelwertunterschieden\n",
        "\n",
        "Der Effekt der Kovarianz auf die Varianz der Differenzwerte ist besonders intuitiv bei einer positiven Korrelation. Betrachten wir zwei Variablen $X_A$ und $X_B$ mit unterschiedlichen Kovarianzen und wie sich dabei jeweils die Variabilität des Differenzwertes entwickelt:\n",
        "\n",
        "<div class=\"vspace-medium\"></div>\n",
        "\n",
        "![In allen drei Plots gilt $\\bar{x}_A=6$ und $\\bar{x}_B=5$, d.h. $\\bar{x}_A-\\bar{x}_B=1$.](images/pooled_variance_dependent.png)\n",
        "\n",
        "<div class=\"vspace-medium\"></div>\n",
        "\n",
        "Wir sehen: je höher die Korrelation $\\bar{x}_A$ und $\\bar{x}_B$, desto geringer die Variabilität der Differenz von $\\bar{x}_A-\\bar{x}_B$! Ist die Korrelation perfekt ($r=1$), so ist die Differenz sogar konstant, d.h. ihre Variabilität ist gleich 0.\n"
      ],
      "id": "246f846d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "X = 6+np.random.randn(10)\n",
        "X += (6-X.mean())\n",
        "\n",
        "fontsize = 15\n",
        "\n",
        "# plt.style.use('dark_background')\n",
        "plt.figure(figsize=(10, 2.5))\n",
        "\n",
        "for i in range(3):\n",
        "    plt.subplot(1,3,3-i)\n",
        "    Y_ = X+(0,2.7,6.2)[i]*(np.random.rand(10)-0.5)\n",
        "    Y_ += (5-Y_.mean())\n",
        "    print(f'cov={np.cov(X,Y_)[0, 1]:.3f}; r={pearsonr(X,Y_)[0]:.3f}; deltaX={np.mean(X)-np.mean(Y_):.2f}')\n",
        "    plt.plot(X, 'o-', label='$X_A$')\n",
        "    plt.plot(Y_, 'o-', label='$X_B$')\n",
        "    plt.plot(X-Y_, 'o-', label='$X_A-X_B$')\n",
        "    plt.xticks(range(10), range(1, 11), fontsize=fontsize-2)\n",
        "    plt.yticks(range(-2, 9, 2), fontsize=fontsize-2)\n",
        "    plt.xlabel('Versuchspersonen', fontsize=fontsize)\n",
        "    plt.ylim(-2, 9)\n",
        "    if i == 0:\n",
        "        plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "    plt.title(r'$Cov(X_A,X_B)='+f'{np.cov(X,Y_)[0, 1]:.2f}' + r';\\quad r=' + f'{pearsonr(X,Y_)[0]:.2f}$')\n",
        "# plt.xlim(0, 1)\n",
        "# plt.ylim(0, 1)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('images/pooled_variance_dependent.png', bbox_inches='tight')"
      ],
      "id": "ca4518b2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Die Varianz von Mittelwertunterschieden\n",
        "\n",
        "***Unhängige* Messungen in *zwei* Stichproben**\n",
        "\n",
        "Im Fall zweier unabhängiger Messungen, ist es nicht möglich die Einzelmesswerte $x_{A,i}$ und $x_{B,i}$ auf Versuchspersonenebene voneinander abzuziehen. Es wäre ohnehin völlig unklar, welche Versuchsperson man in Gruppe A mit welcher anderen Versuchsperson in Gruppe B matched.\n",
        "\n",
        ":::{.fragment}\n",
        "[Die Frage lautet hier:]{.underline} wie groß ist die mittlere Varianz beider Gruppen?\n",
        ":::\n",
        "\n",
        ":::{.fragment}\n",
        "Da die Stichprobengrößen $n_A$ und $n_B$ unterschiedlich sein können, berechnen wir den *an den Stichprobengrößen* gewichteten Varianzmittelwert:\n",
        "\n",
        "$$\n",
        "\\hat{\\sigma}^2_\\text{pooled} = \\frac{(n_A-1)\\hat{\\sigma}^2_A + (n_B-1)\\hat{\\sigma}^2_B}{n_A+n_B-2}\\quad\\text{bzw.}\\quad\\hat{\\sigma}_\\text{pooled} = \\sqrt{\\frac{(n_A-1)\\hat{\\sigma}^2_A + (n_B-1)\\hat{\\sigma}^2_B}{n_A+n_B-2}}\n",
        "$$\n",
        ":::\n",
        "\n",
        "- $\\hat{\\sigma}^2_\\text{pooled}$ wird als [**gepoolte Varianz**]{color=\"navy\"} bezeichnet. Die Subtraktion von 1 von den Stichprobengrößen ist erneut Ausdruck der Besselkorrektur.\n",
        "\n",
        ":::{.fragment}\n",
        "**Wir halten fest:** die gepoolte Varianz zweier unabhängiger Stichproben entspricht der \"mittleren Varianz\" beider Gruppen.\n",
        ":::\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## [Herleitung der gepoolten Varianz und Standardabweichung]{color=\"darkred\"}\n",
        "\n",
        "![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=110px}\n",
        "\n",
        "<!-- https://stats.stackexchange.com/questions/1850/difference-between-cohens-d-and-hedges-g-for-effect-size-metrics\n",
        "https://stats.stackexchange.com/questions/66956/whats-the-difference-between-hedges-g-and-cohens-d\n",
        "https://stats.stackexchange.com/questions/1850/difference-between-cohens-d-and-hedges-g-for-effect-size-metrics -->\n",
        "\n",
        ":::{.nonincremental}\n",
        "- Wir starten mit den (nicht bias-korrigierten) **Varianzen** $s^2_A$ und $s^2_B$ der Stichproben A und B.\n",
        "- Die **gepoolte Varianz** ist definiert als der gewichtete Mittelwert der beiden Einzelvarianzen in den beiden Gruppen:\n",
        ":::\n",
        "\n",
        "::: {style=\"margin-top: -25px\"}\n",
        "$$\n",
        "s^2_\\text{pooled} = \\frac{n_A\\cdot s^2_A + n_B\\cdot s^2_B}{n_A+n_B}\n",
        "$$\n",
        ":::\n",
        "\n",
        "\n",
        ":::{.nonincremental}\n",
        "- Da wir von der Stichprobe auf die Population schließen wollen, wird die **Besselkorrektur** verwendet, d.h. $n_A\\rightarrow n_A-1$ und $n_B\\rightarrow n_B-1$ und $s^2 \\rightarrow \\hat{\\sigma}^2$:\n",
        ":::\n",
        "\n",
        "$$\n",
        "\\hat{\\sigma}^2_\\text{pooled} = \\frac{(n_A-1)\\cdot \\hat{\\sigma}^2_A + (n_B-1)\\cdot \\hat{\\sigma}^2_B}{n_A+n_B-2}\n",
        "$$\n",
        "\n",
        "\n",
        ":::{.nonincremental}\n",
        "- Analog gilt:\n",
        ":::\n",
        "\n",
        "$$\n",
        "\\text{bzw.}\\qquad \\hat{\\sigma}_\\text{pooled} = \\sqrt{\\frac{(n_A-1)\\cdot \\hat{\\sigma}^2_A + (n_B-1)\\cdot \\hat{\\sigma}^2_B}{n_A+n_B-2}}\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## [Standardisierte Effektstärken für Mittelwertunterschiede: Einzelmessung]{style=\"font-size:35px\"}\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"63%\"}\n",
        "[**Fall 1:**]{.underline} Es gibt nur eine einzelne Messung an einer Gruppe und die Frage ist, ob der Mittelwert $\\bar{x}$ bedeutsam über einem Referenzwert $\\mu_0$ liegt.\n",
        "\n",
        "<div class=\"vspace-medium\"></div>\n",
        "\n",
        ":::{.fragment}\n",
        "$$\n",
        "\\text{Mittelwertsunterschied} = \\bar{x} - \\mu_0\n",
        "$$\n",
        ":::\n",
        "\n",
        "<div class=\"vspace-medium\"></div>\n",
        "\n",
        ":::{.fragment}\n",
        "$$\n",
        "\\text{Standardisierte Effektstärke:}\\qquad d = \\frac{\\bar{x} - \\mu_0}{\\hat{\\sigma}}\n",
        "$$\n",
        ":::\n",
        "\n",
        ":::\n",
        "::: {.column width=\"37%\"}\n",
        "![Beispiel: Studie zum Wohlbefinden &mdash; ist das Wohlbefinden *in der Gruppe* mit Kontaktsperre noch im positiven Bereich ($\\bar{x}>\\mu_0 \\text{ mit } \\mu_0=0$)?](images/unterschied_referenz.png){height=300px}\n",
        ":::\n",
        "::::\n",
        "\n",
        "::: {style=\"margin-top:-25px\"}\n",
        "- Das Symbol $\\hat{\\sigma}$ statt $\\sigma$ bringt zum Ausdruck, dass wir hier auf Basis der Stichprobe die Varianz in der Population schätzen (d.h. Anwendung der Besselkorrektur mit $n-1$):\n",
        ":::\n",
        "\n",
        ":::{.fragment}\n",
        "$$\n",
        "\\hat{\\sigma} = \\sqrt{\\frac{\\sum\\left(x_i-\\bar{x}\\right)^2}{n\\color{darkgreen}{-1}}}\n",
        "$$\n",
        ":::\n",
        "\n",
        "- Die Bezeichnung $d$ für standardisierte Mittelwertsunterschiede stammt von dem Statistiker Jacob Cohen &mdash; häufig wird daher auch von [**Cohen's d**]{color=\"navy\"} gesprochen.\n",
        "\n",
        "## [Standardisierte Effektstärken für Mittelwertunterschiede: abhängige Messungen]{style=\"font-size:32px\"}\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"68%\"}\n",
        "[**Fall 2:**]{.underline} $A$ und $B$ sind *abhängige* Messungen in derselben Gruppe (d.h. $A$ und $B$ sind zwei Versuchszeitpunkte oder Versuchsbedingungen). \n",
        "\n",
        ":::{.fragment}\n",
        "$$\n",
        "\\text{Mittelwertsunterschied} = \\bar{x}_A - \\bar{x}_B\n",
        "$$\n",
        ":::\n",
        "\n",
        "- Klassischerweise wird für die Berechnung von Cohen's d die Standardabweichung $\\hat{\\sigma}_{\\Delta}$ der Differenz $\\Delta X=X_A-X_B$ gewählt:\n",
        "\n",
        ":::{.fragment}\n",
        "$$\n",
        "\\text{Standardisierte Effektstärke:}\\qquad d = \\frac{\\bar{x}_A - \\bar{x}_B}{\\hat{\\sigma}_{\\Delta}}\n",
        "$$\n",
        ":::\n",
        "\n",
        ":::\n",
        "::: {.column width=\"32%\"}\n",
        "![Beispiel: Unterscheidet sich das Wohlbefinden *in derselben Gruppe* vor und nach einer Kontaktsperre?](images/mittelwertunterschied_within2.png)\n",
        ":::\n",
        "::::\n",
        "\n",
        "\n",
        ":::{.fragment}\n",
        "$$\n",
        "\\text{mit}\\quad \\hat{\\sigma}_{\\Delta} = \\sqrt{\\frac{\\sum\\left(\\Delta x_i-\\Delta\\bar{x}\\right)^2}{n-1}} \\qquad\\text{und}\\quad \\Delta x_i = x^{(A)}_i - x^{(B)}_i\n",
        "$$\n",
        ":::\n",
        "\n",
        "::: {.notabene .fragment}\n",
        ":::: {.columns}\n",
        "::: {.column width=\"7%\"}\n",
        "::: {style=\"margin-top: 10px\"}\n",
        "![](images/notabene2.png){height=65px}\n",
        "\n",
        ":::\n",
        ":::\n",
        "::: {.column width=\"93%\"}\n",
        "Handelt es sich um ein Pre-post-Interventionsdesign (Messung vor und nach einer Intervention an derselben Gruppe), bietet es sich eigentlich an, nur die Standardabweichung des Vortestes für die Standardisierung zu nehmen. Grund: die Variabilität *vor* einer Intervention ist am ehesten zwischen Studien vergleichbar.^[Cumming G (2013) Cohen’s d needs to be readily interpretable: Comment on Shieh (2013). Behav Res 45:968–971.] In der Praxis geschieht dies aber selten.\n",
        ":::\n",
        "\n",
        "\n",
        "::::\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "## [Standardisierte Effektstärken für Mittelwertunterschiede: unabhängige Messungen]{style=\"font-size:31px\"}\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"68%\"}\n",
        "\n",
        "[**Fall 3:**]{.underline} $A$ und $B$ sind **unabhängige Gruppen**, d.h. sie sind aus unterschiedlichen Versuchspersonen zusammengesetzt.\n",
        "\n",
        "- Auch hier gilt: Mittelwertunterschiede werden immer mit der Streuung *innerhalb der Gruppen* standardisiert.\n",
        "- Da es zwei Gruppen gibt, wird berechnet, wie die Datenpunkte beider Gruppen im Mittel *um ihren jeweiligen Mittelwerte* $\\bar{x}_A$ und $\\bar{x}_B$ streuen.\n",
        "- Diese Art von Standardabweichung ist die bereits eingeführte **gepoolte Standardabweichung** $\\hat{\\sigma}_\\text{pooled}$:\n",
        "\n",
        ":::\n",
        "::: {.column width=\"32%\"}\n",
        "![Unterscheidet sich der Mittelwert zweier Gruppen?](images/effectsize_pooledSD.png)\n",
        "\n",
        ":::\n",
        "::::\n",
        "\n",
        ":::{.fragment}\n",
        "$$\n",
        "\\scriptsize{\n",
        "\\hat{\\sigma}_\\text{pooled} = \\sqrt{\\frac{(n_A-1)\\hat{\\sigma}_A^2 + (n_B-1)\\hat{\\sigma}_B^2}{n_A+n_B-2}}\\qquad\\qquad\\text{Falls }n_A=n_B=n:\\;\\; \\hat{\\sigma}_\\text{pooled} = \\sqrt{\\frac{\\hat{\\sigma}_A^2 + \\hat{\\sigma}_B^2}{2\\left(1-\\frac{1}{n}\\right)}}\n",
        "}\n",
        "$$\n",
        ":::\n",
        "\n",
        "<div class=\"vspace-medium\"></div>\n",
        "\n",
        ":::{.fragment}\n",
        "$$\n",
        "\\text{Standardisierte Effektstärke:}\\qquad d = \\frac{\\bar{x}_A - \\bar{x}_B}{\\hat{\\sigma}_\\text{pooled}}\n",
        "$$\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Interpretation von Cohen's d\n",
        "\n",
        "- Die Werte von Cohen's $d$ reichen von $-\\infty$ bis $+\\infty$. Negative Werte sind möglich, da das Vorzeichen davon abhängt, welcher Mittelwert von welchem abgezogen wird.\n",
        "    - Es ist Konvention, $d$ so zu berechnen, dass $d$ positiv ausfällt, falls der Effekt in die hypothesierte Richtung geht.\n",
        "    - Die Interpretation der Effektstärke macht sich aber am absoluten Wert $|d|$ fest: wenn $d=-0{,}3$, dann hat der Effekt eine Stärke von $d=0{,}3$, aber in eine andere Richtung als erwartet.\n",
        "- Durch die Standardisierung mit der Standardabweichung gilt umgekehrt, dass Cohen's d ausdrückt, um wie viel Standardabweichungen ein Effekt von einem Nulleffekt abweicht. Diese Interpretation ist am intuitivsten für den Fall einer *Einzelmessung mit Referenzwert*:\n",
        "\n",
        "\n",
        "<!---  Example --->\n",
        "::: {.example .fragment}\n",
        ":::: {.columns}\n",
        "::: {.column width=\"10%\"}\n",
        "::: {style=\"margin-top: 10px\"}\n",
        "![](images/example.png){height=70px}\n",
        ":::\n",
        ":::\n",
        "::: {.column width=\"90%\"}\n",
        "Eine Studie untersucht, ob die Schlafdauer in einer Gruppe von Psychologiestudierenden in der Bachelorarbeitsphase geringer ist als die durchschnittliche Schlafdauer in Deutschland (7:45 Stunden). Tatsächlich zeigt sich eine verringerte Schlafdauer mit einem Cohen's d von $0{,}3$.\n",
        ":::\n",
        "::::\n",
        ":::\n",
        "\n",
        "- Die Effektstärke von $0{,}3$ sagt aus, dass die Schlafdauer um $0{,}3$ *Standardabweichungen* gegenüber dem Durchschnittswert verringert ist. Die Einheit *Standardabweichung* bezieht sich dabei auf die Standardabweichung $\\hat{\\sigma}$ der Schlafdauer in der untersuchten Gruppe.\n",
        "    - Bei mehreren Bedingungen/Gruppen gilt zwar weiterhin die Interpretation im Sinne von *in Einheiten von Standardabweichungen*, allerdings ist die Definition der Standardabweichungen ($s_{\\Delta}$, $s_\\text{pooled}$) eher kompliziert und damit nicht unbedingt intuitiv.\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Interpretation von Effektstärken\n",
        "\n",
        ":::{.nonincremental}\n",
        "- Um Effektstärken besser einordnen und kommunizieren zu können, hat Jacob Cohen folgende Unterteilung vorgeschlagen:\n",
        ":::\n",
        "\n",
        "\n",
        ":::{style=\"margin-top: -25px\"}\n",
        "<!---  Table --->\n",
        "|d|r|Interpretation|\n",
        "|:-:|:-:|-|\n",
        "| $<0.2$ | $<0.1$ | Trivialer Effekt |\n",
        "| ab $0.2$ | ab $0.1$ | Kleiner Effekt |\n",
        "| ab $0.5$ | ab $0.3$ | Mittlerer Effekt |\n",
        "| ab $0.8$ | ab $0.5$ | Großer Effekt |\n",
        ": {tbl-colwidths=\"[33, 33, 34]\"}\n",
        ":::\n",
        "\n",
        "- Zugleich fügt aber Cohen selbst folgende Qualifizierung an:\n",
        "\n",
        ":::{.fragment}\n",
        "![](images/cohen_effectsizes.png){height=140px}\n",
        ":::\n",
        "\n",
        "- Effektstärken sollten also idealerweise in ihrem jeweiligen Kontext interpretiert werden.\n",
        "- **Beispiel:** Effektstärken bezüglich der Veränderung des Körpergewichts durch Diäten sind erwartbar größer, als Veränderungen bei eher stabilen Merkmalen wie Persönlichkeitsfacetten. &rArr; Ein d-Wert der einer vergleichsweise geringen Veränderung des Körpergewichts entspricht, würde vielleicht in der Persönlichkeitsforschung als starker Effekt gelten.\n",
        "\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Interpretation von Cohen's d\n",
        "\n",
        "- Um zu beurteilen, was als kleine / mittlere / starke Effekte in einem spezifischen Kontext gilt, konsultiert man prinzipiell die entsprechende Fachliteratur nach typischen Referenzeffektstärken.\n",
        "- Problem: es gibt gute Evidenz, dass *publizierte Effekte* die *wahren Effekte*<br>überschätzen (**Publikationsbias**) &rArr; führt zu falschen Maßstäben\n",
        "\n",
        ":::: {.columns .fragment}\n",
        "::: {.column width=\"70%\"}\n",
        "\n",
        "\n",
        "![](images/effectsizes_prereg_schaefer.png){height=330px}\n",
        "\n",
        ":::\n",
        "::: {.column .caption-style width=\"30%\"}\n",
        "Die Abbildung zeigt, dass Effekte, bei denen Hypothesen und Analysen vorab registriert wurden (\"with pre-registration\") deutlich geringere Effektstärken aufweisen, als Effekte \"without pre-registration\". In der Abbildung ist zu beachten, dass die absolute und nicht die relative Häufigkeit aufgetragen ist, wodurch Studien ohne Preregistrierung &mdash; von denen es deutlich mehr gibt &mdash; visuell dominieren.^[Schäfer T, Schwarz MA (2019) The Meaningfulness of Effect Sizes in Psychological Research: Differences Between Sub-Disciplines and the Impact of Potential Biases. Frontiers in Psychology 10 Available at: https://www.frontiersin.org/articles/10.3389/fpsyg.2019.00813.]\n",
        "\n",
        ":::\n",
        "::::\n",
        "\n",
        ":::{.fragment}\n",
        "&rArr; Die Interpretation und Einordnung von Effektstärken ist ein nicht-triviales Problem, das viel \"domain knowledge\" erfordert. Dies gilt für standardisierte wie unstandardisierte Effektstärken.\n",
        ":::\n",
        "\n",
        "- Faustregeln finden sich hier: \n",
        "<a href=\"https://imaging.mrc-cbu.cam.ac.uk/statswiki/FAQ/effectSize\" target=\"_blank\">https://imaging.mrc-cbu.cam.ac.uk/statswiki/FAQ/effectSize</a>\n",
        "\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## [Effektstärken für Mittelwertunterschiede bei mehr als zwei Messungen]{style=\"font-size: 36px\"}\n",
        "\n",
        "- Gibt es mehr als zwei Experimentalbedingungen oder Gruppen (A, B, C, ...), gibt es zwei Möglichkeiten:\n",
        "    1. Von Interesse sind die **paarweisen** Mittelwertsunterschiede (z.B: $A-B$, $A-C$, $B-C$) &xrarr; in diesem Fall kann wie bisher Cohen's d für für jedes Paar angewendet werden.\n",
        "    2. Von Interesse ist, ob sich die Mittelwerte in den Gruppen A, B, C **in ihrer Gesamtheit betrachtet** unterscheiden, d.h. ob die Aufteilung in diese spezifischen Gruppen sinnvoll ist.\n",
        "\n",
        ":::{.fragment}\n",
        "Fall 2 ist unser erster Kontakt mit der **Varianzanalyse**, die in Statistik 2 ausführlich behandelt wird. Man kann die Fragestellung in Fall 2 auch folgendermaßen formulieren:\n",
        ":::\n",
        "\n",
        ":::{.fragment}\n",
        "\n",
        "    Zu welchem Grad wird die Varianz der gepoolten Daten aller Gruppen bereits erklärt durch die Mittelwerte der Gruppen?\n",
        "\n",
        ":::\n",
        "\n",
        "- Auf Basis dieser Formulierung ist nicht mehr überraschend, dass die Effektstärke für Mittlwertunterschiede von mehreren Messungen als *Verhältnis zweier Streuungen* ausgedrückt werden kann:\n",
        "\n",
        "\n",
        "\n",
        ":::: {.columns .fragment}\n",
        "::: {.column width=\"50%\"}\n",
        "$$\n",
        "\\eta^2 = \\frac{QS_\\text{Mittelwerte}}{QS_\\text{Gesamt}}\n",
        "$$\n",
        ":::\n",
        "::: {.column width=\"50%\"}\n",
        "![Die Quadratsumme entspricht dem Zähler in der Formel für die Varianz.](images/quadratsumme.png){height=80px}\n",
        "\n",
        ":::\n",
        "::::\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## [Effektstärken für Mittelwertunterschiede bei mehr als zwei Messungen]{style=\"font-size: 36px\"}\n",
        "\n",
        "![Courtesy of Prof. Thomas Schäfer, Medical School Berlin](images/effectsize_eta_squared.png)\n",
        "\n",
        "- $\\eta^2$ (\"Eta Quadrat\") gibt an, wie viel der Gesamtvarianz durch die Varianz der Mittelwerte aufgeklärt wird.\n",
        "- Es kann zwischen 0 (Mittelwerte erklären keine Varianz) und 1 (Mittelwerte erklären die komplette Varianz) liegen.\n",
        "- Die Berechnung von $QS_\\text{Gesamt}$ umfasst 1) die Varianz zwischen den Bedingungen, 2) die Varianz zwischen zwischen Personen (über Bedingungen hinweg), und 3) wie sehr sich die Varianz der Bedingungen zwischen Personen unterscheidet:\n",
        "\n",
        "\n",
        ":::{.fragment style=\"margin-top: -15px\"}\n",
        "$$\n",
        "QS_\\text{Gesamt} = QS_\\text{Bedingungen} + QS_\\text{Personen} + QS_\\text{Personen x Bedingungen}\n",
        "$$\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## [Effektstärken für Mittelwertunterschiede bei mehr als zwei Messungen]{style=\"font-size: 36px; color: darkred\"}\n",
        "\n",
        "![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=110px}\n",
        "\n",
        "\n",
        ":::{.nonincremental}\n",
        "- Es kann argumentiert werden, dass die Varianz, die lediglich die interindividuellen Unterschiede der Versuchspersonen (Varianzanteil 2 bzw. $QS_\\text{Personen}$) charakterisiert, für die Effektstärke irrelevant ist und nicht zu $QS_\\text{Gesamt}$ gezählt werden sollte, d.h.:\n",
        ":::\n",
        "$$\n",
        "QS_\\text{Gesamt} = QS_\\text{Bedingungen} + QS_\\text{Personen x Bedingungen}\n",
        "$$\n",
        "- Wird die Varianz $QS_\\text{Personen}$ nicht berücksichtigt, spricht man vom [**partiellen**]{color=\"navy\"} $\\color{navy}{\\eta_p^2}$.\n",
        "\n",
        ":::{.nonincremental}\n",
        "- Eine ausführliche Diskussion zum Pro und Kontra von $\\eta^2$ vs. $\\eta_p^2$ findet sich z.B. im Buch von Eid, Gollwitzer und Schmitt im Kapitel zur Varianzanalyse.\n",
        ":::\n",
        "\n",
        "::: {.notabene}\n",
        ":::: {.columns}\n",
        "::: {.column width=\"7%\"}\n",
        "::: {style=\"margin-top: 10px\"}\n",
        "![](images/notabene2.png){height=\"65px\"}\n",
        ":::\n",
        ":::\n",
        "::: {.column width=\"93%\"}\n",
        "Warum werden bei der Berechnung von $\\eta^2$ die Quadratsummen und nicht die Varianzen direkt verwendet? Grund ist, dass die Varianz die *durchschnittliche* (quadrierte) Abweichung vom Mittelwert angibt (daher der Faktor $\\frac{1}{n}$), und beim Vergleich verschiedener Variabilitätskomponenten nicht festgestellt werden kann, wie viel der Datenvariabilität *absolut gesehen* durch eine Variabilitätskomponente erklärt wird.\n",
        "\n",
        ":::\n",
        "::::\n",
        ":::\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "<!-- ## [Typische Effektstärken in der Sozialpsychologie]{color=\"darkred\"}\n",
        "\n",
        "![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=110px}\n",
        "\n",
        "<div class=\"vspace-medium\"></div>\n",
        "![Typische Effektstärke in der sozialpsychologischen Literatur^[Lovakov A, Agadullina ER (2021) Empirically derived guidelines for effect size interpretation in social psychology. Eur J Soc Psychol 51:485–504.].](images/lovakov2021_typical.png){height=550px} -->\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## [Empirische Verteilung von Effektstärken (Sozialpsychologie)]{style=\"font-size: 39px !important; color: darkred\"}\n",
        "\n",
        "![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=110px}\n",
        "\n",
        "<div class=\"vspace-medium\"></div>\n",
        "![Trotz Publikationsbias sind die tatsächlich in der Literatur berichteten Effektstärken geringer als bei der Einteilung nach Cohen angenommen. Auf Basis dieser Studie wären die korrekten Grenzen für Cohen's d 0,15, 0,36, und 0,65. Bild adaptiert von Lovakov & Agadulina (2021)^[Lovakov A, Agadullina ER (2021) Empirically derived guidelines for effect size interpretation in social psychology. Eur J Soc Psychol 51:485–504.].](images/lovakov2021_effectsizes.png){height=550px}\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        ":::{.content-hidden when-format=\"pdf\"}\n",
        "## https://rpsychologist.com/d3/cohend/\n",
        "<iframe width=100% height=100% src=\"https://rpsychologist.com/d3/cohend/\"></iframe>\n",
        ":::\n",
        "\n",
        "\n",
        "## Standardisierte oder unstandardisierte Effektstärken?\n",
        "\n",
        "- Die Frage ob Effektstärken in standardisierter oder unstandardisierter Form berichtet werden sollten wird durchaus kontrovers diskutiert^[https://twitter.com/ceptional/status/1687577019629142017] ^[Baguley T (2009) Standardized or simple effect size: What should be reported? British Journal of Psychology 100:603–617.].\n",
        "- Standardisierte Effektstärken ermöglichen eine bessere Vergleichbarkeit zwischen unterschied-lichen Skalen, gleichzeitig wird die intuitive Bedeutung von *Effektstärke* aber verwässert.\n",
        "\n",
        "<!---  Example --->\n",
        "::: {.example .fragment}\n",
        ":::: {.columns}\n",
        "::: {.column width=\"10%\"}\n",
        "::: {style=\"margin-top: 10px\"}\n",
        "![](images/example.png){height=70px}\n",
        ":::\n",
        ":::\n",
        "::: {.column width=\"90%\"}\n",
        "Es wird berichtet, dass ein Coronoaimpfstoff die Viruslast bei einer Infektion reduziert. Die Effektstärke wird mit $\\text{Cohen's }d=0.4$ angegeben.\n",
        ":::\n",
        "::::\n",
        ":::\n",
        "\n",
        "- Aus diesem Beispiel wird klar, dass die Effektstärke zum einen wenig intuitiv ist (in jedem Fall für Nicht-Wissenschaftler:innen), zum anderen ist nicht ersichtlich, ob die Viruslast nennenswert reduziert wurde oder ob der Rückgang eher klein war, aber die Standardabweichung in der Gruppe so gering, dass dennoch ein hoher $d$-Wert erreicht wurde.\n",
        "- Darüber hinaus hängt die Standardabweichung einer Variable häufig mit eher nebensächlichen Details eines experimentellen Designs (within-subject vs. between-subject) oder einer Stichprobe (nur Psychologiestudierende oder heterogeneres Sample der Allgemeinbevölkerung?) zusammenhängt, die für die Effektstärke wenig relevant sind.\n",
        "- Aus diesen Gründen sollte für **Effekte, die in interpretierbaren Einheiten vorliegen, immer (auch) die unstandardisierte Effektstärke** angegeben werden (z.B. Notenstufen, Einkommen, IQ-Punkte, Größe- Gewichtsangaben, Zeitangaben).\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## [Umrechnung von Cohen's $d$ und Korrelationskoeffizient $r$]{color=\"darkred\"}\n",
        "\n",
        "![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=110px}\n",
        "\n",
        "Fassen Metaanalysen sowohl Studien zusammen, die Effekte als Korrelation berichten (Effektmaß $r$), als auch Studien, die Effekte als Mittelwertsunterschiede zwischen Bedingungen/Gruppen berichten (Effektmaß $d$), entsteht die Notwendigkeit $r$ und $d$ ineinander umzurechnen.\n",
        "\n",
        "**Fall 1: eine der Variablen in der Korrelation ist eine natürliche binäre Variable (z.B. männl./weibl.)**\n",
        "\n",
        "In diesem Fall gilt:\n",
        "\n",
        "$$\n",
        "d=\\frac{2r}{\\sqrt{1-r^2}} \\qquad\\qquad \\hat{se}(d) = \\frac{2}{\\sqrt{(n-1)(1-r^2)}}\n",
        "$$\n",
        "\n",
        "wobei $\\hat{se}(d)$ der Standardfehler der Effektstärke $d$ ist, der zusätzlich angegeben werden sollte.\n",
        "\n",
        "Umgekehrt gilt:\n",
        "\n",
        "$$\n",
        "r = \\frac{d}{\\sqrt{d^2+4}}\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## [Umrechnung von Cohen's $d$ und Korrelationskoeffizient $r$]{color=\"darkred\"}\n",
        "\n",
        "![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=110px}\n",
        "\n",
        "**Fall 2: beide Variablen in der Korrelation sind kontinuierlich, oder eine Variable ist binär, aber enstand durch Dichotomisierung einer kontinuierlichen Variable (advanced!)**\n",
        "\n",
        "In diesem Fall muss eine Variable als unabhängige Variable $X$ definiert werden. Falls eine der Variablen durch Dichotomisierung binär ist, ist diese Variable in jedem Fall die unabhängige Variable.\n",
        "\n",
        "Es gilt:\n",
        "\n",
        ":::{style=\"margin-top: -35px\"}\n",
        "$$\n",
        "d=\\frac{kr}{\\hat{\\sigma}_X\\sqrt{1-r^2}} \\qquad\\qquad \\hat{se}(d) = |d|\\sqrt{\\frac{1}{r^2(n-3)} + \\frac{1}{2(n-1)}}\n",
        "$$\n",
        ":::\n",
        "\n",
        "wobei $\\hat{se}(d)$ der Standardfehler der Effektstärke $d$ ist, der zusätzlich angegeben werden sollte.\n",
        "\n",
        "**Interpretation:** $d$ entspricht der durchschnittlichen Zunahme der standarsierten $Y$-Variable mit jeder Zunahme von $X$ um $k$ (Rohwert)Einheiten &mdash; $k$ muss vom Forscher gewählt werden. \n",
        "\n",
        "Hier wird klar, dass die Formel in Fall 1 implizit $k=2\\hat{\\sigma}_X$ annnimmt. Wählt man dieses $k$ auch in Fall 2, ist die Berechnung von $d$ identisch zu Fall 1 &mdash; der Standardfehler unterscheidet sich allerdings weiterhin! Quelle: ^[Mathur MB, VanderWeele TJ (2020) A Simple, Interpretable Conversion from Pearson’s Correlation to Cohen’s d for Continuous Exposures. Epidemiology 31:e16–e18.]\n",
        "\n",
        "Umgekehrt gilt:\n",
        "\n",
        ":::{style=\"margin-top: -40px\"}\n",
        "$$\n",
        "r = \\frac{d \\hat{\\sigma}_X}{\\sqrt{d^2\\hat{\\sigma}_X^2+k^2}}\n",
        "$$\n",
        ":::\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Absolute Risikoreduktion (ARR)\n",
        "\n",
        "Sind beide Variablen dichotom, sind weder der Korrelationskoeffizient noch Cohen's d intuitive Effektmaße. \n",
        "\n",
        "<!---  Example --->\n",
        "::: {.example .fragment}\n",
        "|||\n",
        "|:-:|-|\n",
        "| ![](images/example.png){height=70px} | Sie untersuchen, ob ein neues Medikament die Heilungsrate (Erfolgsrate) einer Krankheit verbessert. Die Treatmentgruppe erhält das Medikament, die Kontrollgruppe Placebo.\n",
        ": {tbl-colwidths=\"[10, 90]\"}\n",
        ":::\n",
        "\n",
        ":::{.fragment}\n",
        "Eine sinnnvolles Effektmaß ist hier, *um wie viel* die Erfolgsrate in der Treatmentgruppe die Erfolgsrate in der Kontrollgruppe übersteigt. Dies lässt sich einfach aus einer Vierfeldertafel ableiten:\n",
        ":::\n",
        "\n",
        ":::: {.columns .fragment}\n",
        "::: {.column width=\"50%\"}\n",
        "![](images/vierfeldertafel3.png)\n",
        ":::\n",
        "::: {.column width=\"50%\"}\n",
        "![](images/arr.png)\n",
        "\n",
        ":::\n",
        "::::\n",
        "\n",
        "- $ARR$ ist die [**Absolute Risikoreduktion**]{color=\"navy\"}.\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Numbers Needed to Treat (NNT)\n",
        "\n",
        "- Noch gängiger als die Absolute Risikoreduktion ist die inverse Größe, die als [**Numbers Needed to Treat (NNT)**]{color=\"navy\"} bezeichnet wird.\n",
        "\n",
        "::: {.definition .fragment}\n",
        "<!---  Definition--->\n",
        "|||\n",
        "|:-:|-|\n",
        "|||\n",
        "| ![](images/definition.svg){height=70px} | **Number Needed to Treat:** Anzahl der Personen, die behandelt werden müssten, damit eine zusätzliche Person einen Nutzen hat. | \n",
        "|||\n",
        ": {tbl-colwidths=\"[10, 90]\"}\n",
        "\n",
        ":::\n",
        "\n",
        ":::{.fragment}\n",
        "Mathematisch ist $NNT$ das Inverse der $ARR$:\n",
        "\n",
        "$$\n",
        "NNT = \\frac{1}{ARR}\n",
        "$$\n",
        ":::\n",
        "\n",
        "- Da es um Personen geht, wird die NNT immer aufgerundet.\n",
        "\n",
        "<!---  Example --->\n",
        "::: {.example .fragment style=\"border-width: 0 !important\"}\n",
        "||||\n",
        "|:-:|-|-|\n",
        "||||\n",
        "| ![](images/example.png){height=60px} | ![](images/vierfeldertafel_numbers.png) | $ARR = \\frac{90}{90+10} - \\frac{35}{35+35}=0{,}9-0{,}5=0{,}4\\quad\\rightarrow\\quad NRR=\\frac{1}{0{,}4}=2{,}5$ \\\n",
        "&rArr; Drei weitere Personen müssten behandelt werden, damit eine zusätzliche Person einen Nutzen hat (d.h. die andernfalls nicht geheilt würde).|\n",
        "||||\n",
        ": {tbl-colwidths=\"[10, 30, 60]\"}\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Numbers Needed to Treat (NNT)\n",
        "\n",
        ":::{.nonincremental}\n",
        "- Auch wenn das Ziel von $NNT$ eine einfache laienverständliche Kommunikation der Treatmenteffizienz ist, darf angezweifelt werden, ob dies immer der Fall ist, wie durch folgendes Beispiel demonstriert^[Andrade C (2015) The Numbers Needed to Treat and Harm (NNT, NNH) Statistics: What They Tell Us and What They Do Not: (Practical Psychopharmacology). J Clin Psychiatry 76:e330–e333.\n",
        "]:\n",
        ":::\n",
        "\n",
        "![](images/quote_NNT.png)\n",
        "\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Odds Ratio (OR)\n",
        "\n",
        ":::{.nonincremental}\n",
        "- Das [**Odds Ratio**]{color=\"navy\"} ($OR$) vergleicht das *Heilerfolgsverhältnis in der Treatmentgruppe* zum *Heilerfolgsverhältnis in der Kontrollgruppe*:\n",
        ":::\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"50%\"}\n",
        "![](images/vierfeldertafel3.png){height=200px}\n",
        "\n",
        ":::\n",
        "::: {.column width=\"50%\"}\n",
        "$$\n",
        "\\text{OR} = \\frac{\\frac{a}{b}}{\\frac{c}{d}} = \\frac{a\\cdot c}{b\\cdot d}\n",
        "$$\n",
        "\n",
        "[Beachte: Als Heilerfolgsverhältnis wird hier das Verhältnis der Zahl der geheilten Patienten gegenüber der Zahl der nicht geheilten Patienten verstanden.]{style=\"font-size: 20px; line-height: 1.05 !important; display: block; margin-top: 40px; color:#777\"}\n",
        "\n",
        ":::\n",
        "::::\n",
        "\n",
        "- Hat das Treatment keine Auswirkung, so sind die Heilerfolgsverhältnisse in beiden Gruppen gleich, d.h. $OR=1$.\n",
        "- Ist das Treatment erfolgreich, ist das Heilerfolgsverhältnis in der Treatmentgruppen höher als in der Kontrollgruppe, d.h. $OR>1$.\n",
        "- Ist das Treatment sogar nachteilig, ist das Heilerfolgsverhältnis in der Treatmentgruppen *kleiner* als in der Kontrollgruppe, d.h. $OR<1$.\n",
        "\n",
        "::: {.notabene .fragment}\n",
        ":::: {.columns}\n",
        "::: {.column width=\"7%\"}\n",
        "::: {style=\"margin-top: 10px\"}\n",
        "![](images/notabene2.png){height=\"65px\"}\n",
        "\n",
        ":::\n",
        ":::\n",
        "::: {.column width=\"93%\"}\n",
        "Als kleine Übung kann man das Odds Ratio für die beiden hypothetischen Beispiele auf der vorherigen Folie berechnen. Spoiler: das Odds Ratio ist für beide Fälle gleich ($OR=13.5$)!\n",
        "\n",
        ":::\n",
        "::::\n",
        ":::\n",
        "\n",
        "## Übersicht Effektmaße\n",
        "\n",
        "<div class=\"vspace-medium\"></div>\n",
        "\n",
        "![](images/overview_effectsizes.png){height=600px}\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## [Referenz]{color=\"darkred\"}\n",
        "\n",
        "![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=110px}\n",
        "\n",
        "Empfehlungen nach Lakens (2013)^[Lakens D (2013) Calculating and reporting effect sizes to facilitate cumulative science: a practical primer for t-tests and ANOVAs. Frontiers in Psychology 4 Available at: https://www.frontiersin.org/articles/10.3389/fpsyg.2013.00863]:\n",
        "\n",
        "![](images/effectsizes_recommendation_lakens2013.png)\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## [Standardisierte Effektstärken für Mittelwertunterschiede: aktuelle Forschung]{style=\"font-size:33px; color: darkred\"}\n",
        "\n",
        "![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=110px}\n",
        "\n",
        "Ein Problem der vorgestellten Effektmaße für abhängige Messungen, ist, dass sie nicht vergleichbar sind mit Effektmaßen für unabhängige Messungen. Es sind streng genommen **unterschiedliche Skalen**.\n",
        "\n",
        "Eine aktuelle Forschungsarbeit^[Cousineau D (2020) Approximating the distribution of Cohen’s d_p in within-subject designs. TQMP 16:418–421.] bietet dafür eine Lösung mit folgender (komplizierterer) Formel:\n",
        "\n",
        "$$\n",
        "d = \\sqrt{\\frac{2(1-r)}{n}}\\cdot t'_\\nu(\\lambda)\\quad\\text{mit}\\quad \\lambda = \\sqrt{\\frac{n}{2(1-r)}}\\cdot\\frac{\\bar{x}_A - \\bar{x}_B}{\\hat{\\sigma}}\n",
        "$$\n",
        "\n",
        "wobei $r$ die Pearson-Korrelation zwischen den beiden abhängigen Messungen ist und $t'$ die nichtzentrale *t*-Verteilung mit $\\nu = 2(n − 1)/(1 + r^2)$ Freiheitsgraden. Zu beachten ist, dass die Formel nur gilt, falls gleiche Standardabweichungen in den beiden Bedingungen angenommen werden können($\\sigma=\\sigma_A=\\sigma_B$).\n",
        "\n",
        "Laut dem Autor der Forschungsarbeit ist diese Formel sowohl auf abhängige als auch unabhängige Messungen anwendbar.\n",
        "\n",
        "Weiterer nützlicher Link: ^[http://jakewestfall.org/blog/index.php/2016/03/25/five-different-cohens-d-statistics-for-within-subject-designs/]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<!-- ```{python}\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "import seaborn as sns\n",
        "\n",
        "np.random.seed(0)\n",
        "root = '/home/matteo/OneDrive/lehre/Statistik/stats1_lecture/book/'\n",
        "\n",
        "fontsize = 15\n",
        "color = 'k'\n",
        "\n",
        "N = 50\n",
        "\n",
        "df = pd.read_csv(os.path.join(root, 'data', 'paradoxia.csv'))\n",
        "# print(df.head())\n",
        "\n",
        "data_tiktok_control = df[df.group == 1]['hours_tiktok_per_day'].values\n",
        "data_tiktok_paradoxia = df[df.group == 2]['hours_tiktok_per_day'].values\n",
        "data_inflam_control = df[df.group == 1]['inflammation'].values\n",
        "data_inflam_paradoxia = df[df.group == 2]['inflammation'].values\n",
        "\n",
        "d_tiktok = (np.mean(data_tiktok_paradoxia) - np.mean(data_tiktok_control)) / np.sqrt((np.var(data_tiktok_paradoxia)+np.var(data_tiktok_control))/(2*(1-1/N)))\n",
        "d_inflam = (np.mean(data_inflam_paradoxia) - np.mean(data_inflam_control)) / np.sqrt((np.var(data_inflam_paradoxia)+np.var(data_inflam_control))/(2*(1-1/N)))\n",
        "\n",
        "# Formula from https://stats.stackexchange.com/questions/495015/what-is-the-formula-for-the-standard-error-of-cohens-d\n",
        "d_se_tiktok = (8+d_tiktok**2)/(4*N)\n",
        "d_se_inflam = (8+d_inflam**2)/(4*N)\n",
        "\n",
        "plt.style.use('dark_background')\n",
        "plt.figure(figsize=(3, 2.5))\n",
        "plt.gca().set_facecolor('#eee')\n",
        "plt.errorbar([0], [d_tiktok], yerr=[d_se_tiktok], fmt='o', markersize=4, capsize=10, capthick=2, elinewidth=2, ecolor=color, mfc=color, mec=color, zorder=3)\n",
        "plt.errorbar([1], [d_inflam], yerr=[d_se_inflam], fmt='o', markersize=4, capsize=10, capthick=2, elinewidth=2, ecolor=color, mfc=color, mec=color, zorder=3)\n",
        "plt.text(0, 0.07, r'$d=' + f'{d_tiktok:.2f}'.replace('.', '{,}') + '$', ha='center', color='k', fontsize=fontsize-2)\n",
        "plt.text(1, 0.07, r'$d=' + f'{d_inflam:.2f}'.replace('.', '{,}') + '$', ha='center', color='k', fontsize=fontsize-2)\n",
        "\n",
        "plt.xticks([0, 1], ['TikTok', 'Entzündung'], fontsize=fontsize)\n",
        "plt.yticks(fontsize=fontsize-2)\n",
        "plt.ylabel(\"Cohen's $d$\", fontsize=fontsize)\n",
        "plt.xlabel('')\n",
        "plt.xlim(-0.5, 1.5)\n",
        "plt.ylim(0, 1.6)\n",
        "plt.grid(True, color='#e2e2e2')\n",
        "\n",
        "\n",
        "plt.savefig('images/paradoxia_cohensd.png', bbox_inches='tight')\n",
        "\n",
        "``` -->\n",
        "\n",
        "## {.blackslide .center}\n",
        "\n",
        "<div class=\"vspace-medium\"></div>\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"65%\"}\n",
        "Sie berechnen nun Cohen's d für die beiden Gruppenunterschiede hinsichtlich der TikTok-Zeit und Entzündungswerte:\n",
        ":::\n",
        "::: {.column width=\"35%\"}\n",
        "::: {.content-hidden when-format=\"pdf\"}\n",
        "![](images/paradoxia_group_of_scientists.png){.hcenter-image height=200px style=\"margin-top:-100px !important\"}\n",
        "<!-- Source: Midjourney -->\n",
        "\n",
        ":::\n",
        ":::\n",
        "::::\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"70%\"}\n",
        "<div class=\"vspace-large\"></div>\n",
        "![](images/paradoxia_cohensd.png){height=300px}\n",
        ":::\n",
        "::: {.column width=\"30%\"}\n",
        "::: {.caption-style style=\"margin-top:250px !important; margin-left:-180px\"}\n",
        "Hinweis: in der Abbildung wurde nicht nur die Effektstärke selbst aufgetragen, sondern auch ein Streuungsmaß der Effektstärke (Standardfehler der Effektstärke). Dazu kommen wir in Vorlesung 08.\n",
        ":::\n",
        ":::\n",
        "::::\n",
        "\n",
        "Langsam schärft sich das Bild: während die Entzündungswerte höchstens eine mittlere Effektstärke aufweisen ($d=0{,}33$), ist der TikTok-Effekt beeindruckend groß: $\\;d=0{,}93$.\n"
      ],
      "id": "ee3c21f9"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}