{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Vorlesung 05: Zusammenhänge\"\n",
        "---"
      ],
      "id": "b9c5d983"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## {.blackslide .center}\n",
        "\n",
        "::: {.content-hidden when-format=\"pdf\"}\n",
        "![](images/paradoxia_group_of_scientists.png){.hcenter-image height=300px}\n",
        "<!-- Source: Midjourney -->\n",
        "<div class=\"vspace-small\"></div>\n",
        ":::\n",
        "\n",
        "Die bisherige Auswertung der Beobachtungsstudie hat Evidenz sowohl für Hypothese 1 (mehr Zeit auf TikTok) als auch Hypothese 2 (erhöhte Entzündungswerte) erbracht. So einen richtigen Reim können Sie sich noch nicht auf das Ergebnis machen.\n",
        "\n",
        "Ihre Neugier ist aber geweckt und Sie fragen sich: hängen vielleicht Ihre beiden abhängigen Variablen (TikTok-Zeit & Entzündungswerte) selbst miteinander zusammen? Steigen die Entzündungswerte mit zunehmender Online-Zeit auf der Plattform TikTok? \n",
        "\n",
        "<div class=\"vspace-medium\"></div>\n",
        "\n",
        "![](images/paradoxia_zusammenhang.png){height=75px}\n",
        "\n",
        "\n",
        "## Der Forschungsprozess {.hcenter-slide}\n",
        "\n",
        "```yaml { .animate src=\"images/scientific_process.svg\"}\n",
        "setup:\n",
        "    - element: \"#results\"\n",
        "      modifier: function() { this.node.style.fill = 'green'; }\n",
        "    - element: \"#resultsbg\"\n",
        "      modifier: function() { this.node.style.fill = '#d8ffe2';}\n",
        "```\n",
        "\n",
        "## Was sind Zusammenhänge?\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"70%\"}\n",
        "- Ein [**Zusammenhang**]{color=\"navy\"} beschreibt zu welchem Grad zwei Variablen (Merkmale) systematisch miteinander in Verbindung stehen\n",
        "- Zusammenhänge bilden die Essenz der psychologischen Forschung&mdash;durch sie versuchen wir die Mechanik der menschlichen Psyche zu verstehen:\n",
        "    - Fördert **Ausdauersport** das **psychische Wohlbefinden**?\n",
        "    - Helfen **Psychotherapiestunden** bei der Überwindung einer **Depression**?\n",
        "    - Wirkt sich **Bildschirmzeit** nachteilig auf die **Schlafqualität** aus?\n",
        "    - Steigt durch **kindliche Frühförderung** die Wahrscheinlichkeit für einen **akadamischen Bildungsabschluss**?\n",
        "- Fast jede wissenschaftliche Hypothese lässt sich als Zusammenhang formuliern &ndash; selbst Unterschiede!\n",
        "    - [Formulierung als Unterschied]{.underline}: unterscheiden sich Männer und Frauen in ihren verbalen Fähigkeiten?\n",
        "    - [Formulierung als Zusammenhang]{.underline}: steht die kategorische Variable **Geschlecht** in Zusammenhang mit der metrischen Variable **verbale Fähigkeiten**?\n",
        ":::\n",
        "<!-- Begin second column -->\n",
        "::: {.column width=\"30%\"}\n",
        "![](images/relationship.png){width=200px}\n",
        ":::\n",
        "::::\n",
        "\n",
        "## Zusammenhänge im engeren Sinn\n",
        "\n",
        "- Um Unterschiede und Zusammenhänge voneinander abzugrenzen, verstehen wir nachfolgend Zusammenhänge in einem engeren Sinn:\n",
        "\n",
        "<!---  Definition--->\n",
        "::: {.definition}\n",
        "|||\n",
        "|:-:|-|\n",
        "|||\n",
        "| ![](images/definition.svg){height=70px} | Ein [**Zusammenhang**]{color=\"navy\"} (im engeren Sinn) beschreibt zu welchem Grad die **Variation zweier metrischer Variablen** miteinander in Verbindung steht. | \n",
        "|||\n",
        ": {tbl-colwidths=\"[10, 90]\"}\n",
        ":::\n",
        "\n",
        "- Durch die Eingrenzung auf **metrische Variablen** (diskret oder kontinuerlich) stellt etwa die Verbindung von Geschlecht und verbalen Fähigkeiten keinen Zusammenhang im engeren Sinn dar, da Geschlecht eine kategorische Variable ist.\n",
        "- In den meisten Fällen sind Zusammenhänge das \"schärfere statistische Schwert\" als Unterschiede und es lohnt sich oft, Forschungsfragen entsprechend anzupassen:\n",
        "    - Unterscheidet sich die akademische Leistung von Rauchern und Nichtrauchern? &rArr; Zusammenhang **Zahl der Zigaretten pro Tag** und **akademische Leistung**\n",
        "    - Unterscheidet sich der Medienkonsum von Depressiven und Kontrollen? &rArr; Zusammenhang **Depressivität** und **Medienkonsum**\n",
        "    - Unterscheidet sich das Risiko von Alkoholsucht zwischen Nord- und Süddeutschland? &rArr; Zusammenhang **geographischer Breitengrad** und **Alkoholsuchtrisiko**\n",
        "\n",
        "\n",
        "# Kovarianz\n",
        "\n",
        "## Kovarianz\n",
        "\n",
        "- Ziel: mathematische Größe, die zum Ausdruck bringt, wie stark die Variation zweier Variablen miteinander in Zusammenhang steht\n",
        "- Wir haben bereits eine Größe für die Variation *einer* Variable &mdash; die Varianz:\n",
        "\n",
        "$$\n",
        "Var(X) = \\frac{1}{n}\\sum_{i=1}^n\\big(x_i-\\bar{x}\\big)^2 = \\frac{1}{n}\\sum_{i=1}^n(x_i-\\bar{x})\\color{darkred}{(x_i-\\bar{x})}\n",
        "$$\n",
        "\n",
        "\n",
        "- Die Varianz gibt an, wie stark eine Variable $X$ um ihren Mittelwert $\\bar{x}$ schwankt\n",
        "- Analog berechnet die [**Kovarianz**]{color=\"navy\"}, wie stark die *gemeinsame Schwankung zweier Variablen um ihren jeweiligen Mittelwert* ist:\n",
        "$$\n",
        "\\text{Kovarianz:}\\quad Cov(X,Y) = \\frac{1}{n}\\sum_{i=1}^n\\big(x_i-\\bar{x}\\big)^2 = \\frac{1}{n}\\sum_{i=1}^n(x_i-\\bar{x})\\color{darkred}{(y_i-\\bar{y})}\n",
        "$$\n",
        "\n",
        "- Im Zentrum der Kovarianz steht die Erkenntnis, dass das **mathematische Produkt** zweier Abweichungsvariablen &mdash; hier die Abweichungen $(x_i-\\bar{x})$ und $(y_i-\\bar{y})$ vom Mittelwert &mdash; angibt, wie stark die beiden Abweichungen gleichsinnig variieren (ko-variieren).\n",
        "\n",
        "## Kovarianz\n",
        "\n",
        "Intuition:\n",
        "\n",
        "- Sind zwei zusammengehörige Datenpunkte $x_i$ und $y_i$ **größer als der Mittelwert**, sind sowohl $(x_i-\\bar{x})$ als auch $(y_i-\\bar{y})$ **positiv**, und damit auch das Produkt $(x_i-\\bar{x})(y_i-\\bar{y})$ **positiv**.\n",
        "\n",
        "- Sind zwei zusammengehörige Datenpunkte $x_i$ und $y_i$ **geringer als der Mittelwert**, sind sowohl $(x_i-\\bar{x})$ als auch $(y_i-\\bar{y})$ **negativ**, und damit das Produkt $(x_i-\\bar{x})(y_i-\\bar{y})$ wieder **positiv**.\n",
        "\n",
        "<div class=\"vspace-medium\"></div>\n",
        "\n",
        "![](images/covariance-examples.png)\n",
        "\n",
        "\n",
        "## Kovarianz: Größe-Gewicht-Beispiel\n",
        "\n",
        "\n",
        "<div class=\"vspace-small\"></div>\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"34%\"}\n",
        "![](images/covariance_height_weight.png)\n",
        ":::\n",
        "::: {.column width=\"66%\"}\n",
        "\n",
        "$$\n",
        "\\scriptsize{\n",
        "\\begin{aligned}\n",
        "&Cov(X, Y) = \\frac{1}{n}\\sum_{i=1}^n(x_i-\\bar{x})(y_i-\\bar{y}) = \\\\\n",
        "          &= \\frac{1}{3}\\big[(160-170)(60-70)+(170-170)(70-70)+(180-170)(80-70)\\big] = \\\\\n",
        "          &= \\frac{1}{3}\\big[(-10)\\cdot (-10)+0\\cdot 0+10\\cdot 10\\big] = \\\\\n",
        "          &= \\frac{1}{3}\\cdot 200 = 66{,}67\n",
        "\\end{aligned}\n",
        "}\n",
        "$$\n",
        "\n",
        ":::\n",
        "::::\n",
        "\n",
        "- Problem: die Kovarianz hängt von den Einheiten ab!\n",
        "- Wird im Beispiel die Körpergröße $X$ in der Einheit *Meter* angegeben, so lautet die Kovarianz:\n",
        "\n",
        "$$\n",
        "\\scriptsize{\n",
        "\\begin{aligned}\n",
        "Cov(X, Y) &= \\frac{1}{3}\\big[(1{,}60-1{,}70)(60-70)+(1{,}70-1{,}70)(70-70)+(1{,}80-1{,}70)(80-70)\\big] = \\\\\n",
        "          &= \\frac{1}{3}\\big[(-0{,}10)\\cdot (-10)+0\\cdot 0+0{,}10\\cdot 10\\big] = \\frac{1}{3}\\cdot 2 = 0{,}667\n",
        "\\end{aligned}\n",
        "}\n",
        "$$\n",
        "\n",
        "- Kovarianzen sind also **nicht vergleichbar wenn sich Einheiten unterscheiden**, und erst recht nicht, wenn sich die Variablen unterscheiden.\n",
        "\n",
        "\n",
        "# Pearson-Korrelation\n",
        "\n",
        "## Pearson-Korrelation\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"70%\"}\n",
        "- Die [**Pearson-Korrelation**]{color=\"navy\"} schafft Abhilfe für das Problem der mangelnden Vergleichbarkeit\n",
        "- Der Schlüssel: die Kovarianz wird mit der Standardabweichung beider Variablen normalisiert:\n",
        "\n",
        "$$\n",
        "\\small{\n",
        "\\text{Korrelation:}\\quad r = \\frac{Cov(X,Y)}{s_X s_Y} = \\frac{1}{n s_X s_Y}\\sum_{i=1}^n(x_i-\\bar{x})(y_i-\\bar{y})\n",
        "}\n",
        "$$\n",
        "\n",
        "- Durch das Teilen durch die Standardabweichungen $s_X$ und $s_Y$ werden die Einheiten herausgekürzt &mdash; die Korrelation ist also eine **einheitslose Größe**.\n",
        "- Die Korrelation kann Werte zwischen $-1$ (perfekter negativer Zusammenhang) und $+1$ (perfekter positiver Zusammenhang) annehmen.\n",
        "\n",
        ":::\n",
        "<!-- Begin second column -->\n",
        "::: {.column width=\"30%\"}\n",
        "\n",
        "![Der britische Mathematiker Karl Pearson in seinem Büro im Jahr 1910. Neben dem Korrelationskoeffizienten verdanken wir Pearson viele andere statistische Konzepte wie die Hauptkomponentenanalyse oder den p-Wert. Später wurden seine Ansichten zu Eugenik kritisch hinterfragt. Bildnachweis^[http://www.learn-stat.com/life-of-karl-pearson/]](images/karl_pearson.png)\n",
        "\n",
        ":::\n",
        "::::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## [Warum ist die Korrelation auf &minus;1 bis 1 beschränkt?]{color=\"darkred\"}\n",
        "\n",
        "![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=110px}\n",
        "\n",
        "Darstellung der Korrelation nur mit (Ko)Varianzen:\n",
        "\n",
        "$$\n",
        "r_{XY} = \\frac{Cov(X,Y)}{s_X s_Y} = \\frac{Cov(X,Y)}{\\sqrt{Var(X)} \\sqrt{Var(Y)}}\n",
        "$$\n",
        "\n",
        "Die Korrelation sollte maximal ($r=1$) sein, wenn $X$ mit sich selbst korreliert wird ($Y=X$). Zu berücksichtigen ist, dass die Kovarianz *von X mit sich selbst* gleich der Varianz ist:\n",
        "\n",
        "$$\n",
        "r_{XX} = \\frac{Cov(X,X)}{\\sqrt{Var(X)} \\sqrt{Var(X)}} = \\frac{Var(X)}{\\sqrt{Var(X)} \\sqrt{Var(X)}} = \\frac{Var(X)}{Var(X)} = 1\n",
        "$$\n",
        "\n",
        "\n",
        "Umgekehrt sollte die Korrelation maximal negativ sein ($r=-1$), wenn $Y$ genau das Inverse von $X$ ist, also $Y=-X$. Unter Berücksichtigung von $Var(X) = Var(-X)$ gilt:\n",
        "$$\n",
        "r_{X(-X)} = \\frac{Cov(X,-X)}{\\sqrt{Var(X)} \\sqrt{Var(-X)}} = \\frac{-Cov(X,X)}{\\sqrt{Var(X)} \\sqrt{Var(X)}} = \\frac{-Var(X)}{Var(X)} = -1\n",
        "$$\n",
        "\n",
        "\n",
        "<!-- ```{python}\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import pearsonr, linregress\n",
        "\n",
        "np.random.seed(0)\n",
        "data = np.random.multivariate_normal([0, 0], [[1, 0.5], [0.5, 1]], 30) + 3\n",
        "x, y = data[:, 0]/2, data[:, 1]\n",
        "fontsize = 15\n",
        "\n",
        "r, p = pearsonr(x, y)\n",
        "reg = linregress(x, y)\n",
        "xrange = np.array([0.1, 2.7])\n",
        "\n",
        "plt.style.use('dark_background')\n",
        "plt.figure()\n",
        "plt.gca().tick_params(color='white')\n",
        "plt.scatter(x, y)\n",
        "plt.plot(xrange, reg.slope*xrange+reg.intercept, color='#b8ffc3')\n",
        "plt.xlabel('Stunden auf TikTok / 24h', fontsize=fontsize)\n",
        "plt.ylabel('Entzündungswerte', fontsize=fontsize)\n",
        "plt.xticks(fontsize=fontsize-2)\n",
        "plt.yticks(fontsize=fontsize-2)\n",
        "plt.text(1.6, 0.7, fr'$r={r:.3f}$ ($p={p:.4f}$)', color='white', fontsize=fontsize-2)\n",
        "plt.savefig('images/streudiagramm.png', bbox_inches=\"tight\")\n",
        "``` -->\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Das Streudiagramm {.blackslide}\n",
        "\n",
        "- Von einer kleinen Stichprobe im TikTok-Datensatz des CCC sind auch Entzündungswerte bekannt\n",
        "- In der Task Force fragen Sie sich, ob es unter den Paradoxikern einen Zusammenhang zwischen der Zahl der Stunden auf TikTok und den Entzündungswerten gibt\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"45%\"}\n",
        "Sie fassen Ihr Ergebnis in einem [**Streudiagramm**]{color=\"lightblue\"} zusammen.\n",
        "\n",
        "- Das Streudiagramm (engl. *scatter plot*) ist die häufigste Visualisierung eins biavariaten Zusammenhangs\n",
        "- Bei der Korrelation ist es dabei willkürlich, welche Variable auf der X- und Y-Achse liegt\n",
        "- Häufig wird zusätzlich zur \"Punktwolke\" auch eine **Regressionsgerade** angegeben, sowie die Stärke des Zusammenhangs (r=.., p=..)\n",
        ":::\n",
        "::: {.column width=\"55%\"}\n",
        "![](images/streudiagramm.png)\n",
        ":::\n",
        "::::\n",
        "\n",
        "\n",
        "## Pearson-Korrelation: Größe-Gewicht-Beispiel\n",
        "\n",
        "<div class=\"vspace-small\"></div>\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"44%\"}\n",
        "![](images/covariance_height_weight.png)\n",
        ":::\n",
        "::: {.column width=\"56%\"}\n",
        "Wir hatten:\n",
        "\n",
        "$$\n",
        "\\small{\n",
        "\\begin{aligned}\n",
        "&Cov(X, Y) = \\frac{1}{n}\\sum_{i=1}^n(x_i-\\bar{x})(y_i-\\bar{y}) = \\frac{200}{3}\n",
        "\\end{aligned}\n",
        "}\n",
        "$$\n",
        "\n",
        "Und berechnen nun die Korrelation $\\;\\;r = \\frac{Cov(X,Y)}{s_X s_Y}$\n",
        "\n",
        "$\\scriptsize{s_X=\\sqrt{\\frac{1}{n}\\sum_{i=1}^n\\big(x_i-\\bar{x}\\big)^2}=\\sqrt{\\frac{1}{3}[(-10)^2+0^2+10^2]}=\\sqrt{\\frac{200}{3}}}$\n",
        "\n",
        "$\\scriptsize{s_Y=\\sqrt{\\frac{1}{n}\\sum_{i=1}^n\\big(y_i-\\bar{y}\\big)^2}=\\sqrt{\\frac{1}{3}[(-10)^2+0^2+10^2]}=\\sqrt{\\frac{200}{3}}}$\n",
        "\n",
        "$$\n",
        "\\small{\n",
        "r = \\frac{\\frac{200}{3}}{\\sqrt{\\frac{200}{3}}\\cdot\\sqrt{\\frac{200}{3}}}=1\n",
        "}\n",
        "$$\n",
        "\n",
        ":::\n",
        "::::\n",
        "\n",
        "- Wäre die Körpergröße in der Einheit *Meter* angeben, so kürzt sich der Faktor 100 (1m = 100cm) nicht nur im Zähler, sondern auch im Nenner:\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"40%\"}\n",
        "$$\n",
        "\\small{\n",
        "r = \\frac{\\frac{2\\color{darkred}{{,}}00}{3}}{\\sqrt{\\frac{2\\color{darkred}{{,}}00}{3}}\\cdot\\sqrt{\\frac{2\\color{darkred}{{,}}00}{3}}}=1\n",
        "}\n",
        "$$\n",
        ":::\n",
        "::: {.column width=\"60%\"}\n",
        "Die Normalisierung mit der Standardabweichung sorgt somit dafür, dass die willkürliche Einheit keine Rolle spielt.\n",
        ":::\n",
        "::::\n",
        "\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Interpretation der Pearson-Korrelation\n",
        "\n",
        "- Die Pearson-Korrelation zeigt an, **wie linear** der Zusammenhang zweier Variablen ausgeprägt ist\n",
        "- Die Pearson-Korrelation ist dabei [nicht]{.underline} von der Steigung einer gedachten Gerade abhängig.\n",
        "\n",
        "![Korrelationskoeffizienten für verschiedene hypothetische Streudiagramme](images/correlation_examples.png){width=1030px}\n",
        "\n",
        "- Ein Zusammenhang zweier Variablen kann extrem schwach sein (z.B. so, dass eine Verdopplung von X nur einer 0.1%-Steigerung von Y entspricht) und dennoch kann die Korrelation stark sein (= nah an $\\pm 1$), wenn die Punkte exakt auf einer Geraden liegen.\n",
        "- Auf einen Satz gemünzt kann man sagen: \n",
        "\n",
        "::: {style=\"font-size: 26px; margin-top: -10px\"}\n",
        "> Die Pearson-Korrelation misst, wie gut bivariate Daten durch eine Gerade abgebildet werden können.\n",
        ":::\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        ":::{.content-hidden when-format=\"pdf\"}\n",
        "## [https://www.guessthecorrelation.com/]{style=\"font-size: 37px\"}\n",
        "\n",
        "<iframe width=100% height=\"100%\" src=\"https://www.guessthecorrelation.com/\"></iframe>\n",
        ":::\n",
        "\n",
        "## Voraussetzungen für das Berechnen der Pearson-Korrelation\n",
        "\n",
        "- Die Pearson-Korrelation *kann* *immer* berechnet werden, solange beide Variablen aus Zahlenwerten bestehen.\n",
        "- Es gibt jedoch weitere Kriterien, die für die Sinnhaftigkeit und Interpretierbarkeit der Pearson-Korrelation wichtig sind:\n",
        "\n",
        "<!---  Table --->\n",
        "|Kriterium|Falls Kriterium nicht erfüllt? | Beispiel | Mögliche Abhilfe? |\n",
        "|-|-|-|-|\n",
        "| Daten haben mindestens Intervallskalenniveau | ▪&numsp;Keine Aussage über Linearität des untersuchten Zusammenhangs möglich \\\n",
        "▪&numsp;Korrelation nicht interpretierbar | ![](images/example_ordinal.png) | Rangkorrelation |\n",
        "| Keine Ausreißer | Korrelationskoeffizient kann massiv verzerrt sein | ![](images/outlier_example.png) | Ausreißer entfernen oder Rangkorrelation | \n",
        "| Zusammenhang der Daten wird nicht durch *nicht-linearen* Anteil dominiert | ▪&numsp;Pearson-Korrelation falsches Modell \\\n",
        "▪&numsp;Linearität der Daten wird verzerrt wiedergegeben, da die Korrelation vom nicht-linearen Teil beeinflusst wird  | ![](images/nonlinear.png) | Komplexeres Modell, das den nicht-linearen Anteil berücksichtigt |\n",
        "\n",
        ": {tbl-colwidths=\"[24, 36, 20, 20]\"}\n",
        "\n",
        "## Mythen zur Pearson-Korrelation\n",
        "\n",
        "- In vielen Quellen finden sich darüber hinaus **unzutreffende Behauptungen** zur Pearson-Korrelation:\n",
        "\n",
        ":::{style=\"margin-top: 5px\"}\n",
        "<!---  Table --->\n",
        "||Behauptung| Fact |\n",
        "|-|-|-|\n",
        "| **Mythos 1** | Die Variablen müssen kontinuierlich sein | **Pearson-Korrelation ist valide für diskrete Daten**, solange diese mindestens Intervallskalenniveau aufweisen. Tatsächlich gibt es sogar eine Variante der Pearson-Korrelation, bei der beide Variablen binär sind (Phi-Koeffizient). |\n",
        "| **Mythos 2** | Die Variablen müssen einen linearen Zusammenhang aufweisen | Gegenbeispiel: wenn Daten aus zufälligem Rauschen basieren, sind sie mit Sicherheit nicht linear verbunden &mdash; und dennoch gibt der Pearson-Koeffizient korrekterweise an, dass die Korrelation ungefähr 0 ist. Zusammenhänge in der Psychologie sind *sehr selten* eindeutig linear, dennoch kann es sinnvoll sein, die Pearson-Korrelation anzuwenden. Besser ist daher zu sagen (s. vorherige Folie), dass der **Zusammenhang nicht zu stark durch einen nicht-linearen Anteil dominiert** werden sollten. |\n",
        "| **Mythos 3** | Die beiden Variablen müssen normalverteilt sein. | Der **Pearson-Korrelationskoeffizient per se erfordert keine Normalverteilung** der Variablen. Korrekt ist aber, dass die Daten für die **Berechnung eines p-Wertes auf Basis des t-Tests annähernd normalverteilt** (ganz korrekt: *bivariat normalverteilt*) sein sollten. Wenn Normalverteilung nicht gegeben ist, können andere Signifikanztests (Permutation, Bootstrap) verwendet werden.\n",
        "| **Mythos 4** | Die Variablen müssen varianzhomogen sein | Varianzhomogenität (auch Homoskedastizität) meint, dass Y-Werte ähnliche Varianz in verschiedenen Abschnitten der X-Achse haben und umgekehrt. Hier gilt das gleiche wie bei Mythos 3. **Varianzhomogenität ist keine Voraussetzung für die Anwendung der Pearson-Korrelation per se, wohl aber für die Anwendung des T-tests.**\n",
        "\n",
        ": {tbl-colwidths=\"[10, 18, 72]\"}\n",
        ":::\n",
        "\n",
        "\n",
        "<!-- ```{python}\n",
        "from string import ascii_letters\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.set_theme(style=\"white\")\n",
        "fontsize = 36\n",
        "\n",
        "data = [\n",
        "    [1, 0.13, 0.35, 0.23, -0.2],\n",
        "    [0, 1, 0.37, 0.1, -0.4],\n",
        "    [0, 0, 1, 0.01, -0.26],\n",
        "    [0, 0, 0, 1, -0.1],\n",
        "    [0, 0, 0, 0, 1]\n",
        "]\n",
        "\n",
        "annot = [\n",
        "    ['1', '0.13', '0.35', '0.23', '-0.2'],\n",
        "    ['', '1', '0.37', '0.1', '-0.4'],\n",
        "    ['', '', '1', '0.01', '-0.26'],\n",
        "    ['', '', '', '1', '-0.1'],\n",
        "    ['', '', '', '', '1']\n",
        "]\n",
        "\n",
        "columns = ['O', 'C', 'E', 'A', 'n']\n",
        "\n",
        "corr = pd.DataFrame(data, columns=columns, index=pd.Index(columns))\n",
        "\n",
        "# Generate a mask for the upper triangle\n",
        "# mask = np.tril(np.ones_like(corr, dtype=bool))\n",
        "mask = np.zeros_like(corr, dtype=bool)\n",
        "np.fill_diagonal(mask, True)\n",
        "\n",
        "# Set up the matplotlib figure\n",
        "f, ax = plt.subplots(figsize=(11, 9))\n",
        "\n",
        "# Generate a custom diverging colormap\n",
        "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
        "\n",
        "# Draw the heatmap with the mask and correct aspect ratio\n",
        "hm = sns.heatmap(corr, annot=annot, fmt='', mask=mask, cmap=cmap, vmax=.3, center=0,\n",
        "                 square=True, linewidths=.5, cbar_kws=dict(shrink=1, label='Korrelation'), annot_kws=dict(size=fontsize))\n",
        "plt.gca().collections[0].colorbar.ax.tick_params(labelsize=28)\n",
        "hm.figure.axes[-1].set_ylabel('Korrelation', size=fontsize)\n",
        "hm.tick_params(labelsize=fontsize)\n",
        "plt.yticks(rotation=0) \n",
        "hm.patch.set_facecolor('#777')\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'images/corrmatrix.png', bbox_inches=\"tight\")\n",
        "```-->\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Korrelationsmatrix\n",
        "\n",
        "- Eine **Korrelation** bestimmt immer den Zusammenhang zwischen **zwei Variablen**\n",
        "- Gibt es mehr als zwei Variablen (z.B. die \"Big Five\"), bietet sich eine Darstellung aller paarweisen Korrelationen an &ndash; die [**Korrelationsmatrix**]{color=\"navy\"}\n",
        "\n",
        ":::: {.columns .vcenter-column style=\"margin-top:-15px\"}\n",
        "::: {.column width=\"60%\"}\n",
        "![Tabellarische Korrelationsmatrix. Sterne kennzeichnen häufig das Signifikanzniveau.](images/corrmatrix_table.png)\n",
        ":::\n",
        "::: {.column width=\"40%\"}\n",
        "![Korrelationsmatrix als \"Heatmap\" &ndash; die Einfärbung ist ein visuelles Hilfsmittel zur intuitiven und schnellen Erfassung der Korrelationsstruktur eines Variablen-Sets.](images/corrmatrix.png)\n",
        ":::\n",
        "::::\n",
        "- Die [Nebendiagonalelemente]{color=\"darkgreen\"} sind der interessante Teil der Korrelationsmatrix, sie geben die Korrelationen verschiedener Variablen an\n",
        "- Die [Diagonalelemente]{color=\"darkred\"}, also die Korrelationen von Variablen mit sich selbst, sind immer 1\n",
        "\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Kovarianzmatrix\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"75%\"}\n",
        "- Eine analoge Matrix-Darstellung gibt es auch für die **Kovarianz**\n",
        "- Im Unterschied zur Korrelationsmatrix sind die Diagonalelemente der Kovarianzmatrix nicht 1, sondern geben die **Varianz** der Variable an.\n",
        "- Sei $\\mathbf{X}$ (beachte Fettschrift) ein Vektor von $n$ Variablen $X_1 .. X_n$, so ist die zugehörige Kovarianzematrix $\\operatorname{Cov}(\\mathbf{X})$:\n",
        "\n",
        "$$\n",
        "\\small{\n",
        "\\begin{aligned}\n",
        "\\operatorname{Cov}(\\mathbf{X}) & = \n",
        "\\begin{pmatrix}\\operatorname{Var}(X_1) & \\operatorname{Cov}(X_1,X_2) & \\cdots & \\operatorname{Cov}(X_1,X_n) \\\\ \\\\\n",
        " \\operatorname{Cov}(X_2,X_1)  & \\operatorname{Var}(X_2) & \\cdots & \\operatorname{Cov}(X_2,X_n) \\\\ \\\\\n",
        " \\vdots & \\vdots & \\ddots & \\vdots \\\\ \\\\\n",
        "\\operatorname{Cov}(X_n,X_1) & \\operatorname{Cov}(X_n,X_2) & \\cdots & \\operatorname{Var}(X_n)\n",
        "\\end{pmatrix}\n",
        "\\end{aligned}\n",
        "}\n",
        "$$\n",
        "\n",
        ":::\n",
        "::: {.column width=\"25%\"}\n",
        "![](images/covariance_matrix.png)\n",
        ":::\n",
        "::::\n",
        "\n",
        "- Im Gegensatz zur Korrelationsmatrix ist die Kovarianzmatrix selten das \"Endprodukt\" einer Analyse, sondern meist ein Zwischenschritt in fortgeschritteneren statistischen Analysen wie der **Hauptkomponentenanalyse**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## [Punktbiseriale und biseriale Korrelation]{color=\"darkred\"}\n",
        "\n",
        "![](images/kein_klausurstoff.png){.absolute top=40 right=30 height=110px}\n",
        "\n",
        "- Korrelationskoeffizienten können auch berechnet werden, wenn eine<br>der beiden Variablen dichotom ist. Zwei Fälle werden unterschieden.\n",
        "\n",
        "\n",
        "**Fall 1: die binäre Variable liegt natürlicherweise in dichotomer Form vor (z.B. männl./weibl.)**\n",
        "\n",
        "In diesem Fall haben die beiden Werte der binären Variable *keine natürliche Ordnung* und es wird der [**punktbiseriale Korrelationskoeffizient**]{color=\"navy\"} verwendet.\n",
        "\n",
        "Sei $X$ die binäre Variable und $Y$ die kontinuierliche Variable. Wir teilen die Stichprobe in Gruppe $A$ (für die $X$ den einen Wert einnimmt) und Gruppe $B$ (für die $X$ den anderen Wert einnimmt). Es gilt:\n",
        "\n",
        ":::{style=\"margin-top: 0px\"}\n",
        "$$\n",
        "r_\\text{population} = \\frac{\\left(\\bar{y}_A - \\bar{y}_B\\right)}{\\sigma_Y}\\sqrt{p_A p_B} \\qquad\\qquad r_\\text{sample} = \\frac{\\left(\\bar{y}_A - \\bar{y}_B\\right)}{s_Y}\\sqrt{\\frac{n p_A p_B}{n-1}}\n",
        "$$\n",
        ":::\n",
        "\n",
        "wobei $\\bar{y}_{A/B}$ der Mittelwert von $Y$ und $p_{A/B}$ der Anteil (proportion) der Versuchspersonen in Gruppe $A$/$B$ ist. $\\sigma_Y$/$s_Y$ ist die Standardabweichung von $Y$ in der Population/Stichprobe.\n",
        "\n",
        "<div class=\"vspace-medium\"></div>\n",
        "\n",
        "::: {.merke}\n",
        ":::: {.columns}\n",
        "::: {.column width=\"5%\"}\n",
        "::: {style=\"margin-top: 18px\"}\n",
        "![](images/merke.png){height=\"55px\"}\n",
        ":::\n",
        ":::\n",
        "::: {.column width=\"95%\"}\n",
        "**Beachte:** der punktbiserielle Korrelationskoeffizient leitet sich direkt aus dem Pearson-Korrelationskoeffizienten ab (ist äquivalent), d.h. die Pearsonkorrelation einschlägiger Statistiksoftware kann verwendet werden!\n",
        ":::\n",
        "::::\n",
        ":::\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## [Punktbiseriale und biseriale Korrelation]{color=\"darkred\"}\n",
        "\n",
        "![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=110px}\n",
        "\n",
        "**Fall 2: die binäre Variable resultiert aus der Dichotomisierung einer kontinuierlichen Variable**\n",
        "\n",
        "In diesem Fall unterschätzt die punktbiseriale Korrelation den wahren Wert und es sollte der [**biseriale Korrelationskoeffizient**]{color=\"navy\"} verwendet:\n",
        "\n",
        ":::{style=\"margin-left: -30px\"}\n",
        "$$\n",
        "r_\\text{population} = \\frac{\\left(\\bar{y}_A - \\bar{y}_B\\right)}{f(z_p)\\sigma_Y}p_A p_B \\qquad\\qquad r_\\text{sample} = \\frac{\\left(\\bar{y}_A - \\bar{y}_B\\right)}{f(z_p)s_Y}\\frac{n p_A p_B}{n-1}\n",
        "$$\n",
        ":::\n",
        "\n",
        "wobei $f(z_p)$ der Wert der Standardnormalverteilung bei $z_p$ ist und $z_p$ der Wert, bei dem die Fläche rechts unter der Standardnormalverteilung gleich $p$ ist ($P(Z>z_p)=p$).\n",
        "\n",
        "<!-- Antwort auf \n",
        "https://real-statistics.com/correlation/biserial-correlation/comment-page-1/?unapproved=1505005&moderation-hash=fba191d84ae6d8b2252c6b13efb49ba1#comment-1505005\n",
        "checken! -->\n",
        "\n",
        "\n",
        "Quellen: ^[https://real-statistics.com/correlation/biserial-correlation/] ^[https://www.ncss.com/wp-content/themes/ncss/pdf/Procedures/NCSS/Point-Biserial_and_Biserial_Correlations.pdf] ^[Jacobs P, Viechtbauer W (2017) Estimation of the biserial correlation and its sampling variance for use in meta-analysis: Biserial Correlation. Res Syn Meth 8:161–180.]\n",
        "\n",
        "\n",
        "# Rangkorrelationen\n",
        "\n",
        "## Was ist eine Rangkorrelation?\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"72%\"}\n",
        "\n",
        "- [**Rangkorrelationsmaße**]{color=\"navy\"} ermöglichen es, Zusammenhänge von ordinalskalierten und nicht-linearen Variablem zu untersuchen.\n",
        "    - Dies ist mit der Pearson-Korrelation nicht möglich\n",
        "- \"Rang\" bezieht sich auf das Ordinalskalenniveau, d.h. dass die Daten nur als \"Rang\" oder \"Reihenfolge\" interpretiert werden können.\n",
        "- Im Gegensatz zur Pearson-Korrelation bewerten Rangkorrelationen nicht die Linearität eines Zusammenhangs, sondern die **Monotonie des Zusammenhangs**.\n",
        "- Ein weiterer Anwendungsfall sind intervallskalierte Daten, die Ausreißer aufweisen und daher die Pearson-Korrelation verzerren.\n",
        "    - Rangkorrelationen sind **robust gegenüber Ausreißern**\n",
        "    - In diesem Fall werden die Variablen künstlich in Ränge umgewandelt.\n",
        "- Hier behandeln wir zwei Maße für die Rangkorrelation:\n",
        "    - [**Spearman-Korrelation**]{color=\"navy\"}\n",
        "    - [**Kendall'sches Tau**]{color=\"navy\"}\n",
        ":::\n",
        "::: {.column width=\"28%\"}\n",
        "![](images/rankorder_example.png)\n",
        "\n",
        "<div class=\"vspace-medium\"></div>\n",
        "\n",
        "![](images/rankorder_example2.png)\n",
        ":::\n",
        "::::\n",
        "\n",
        "\n",
        "## Berechnung von Rängen\n",
        "\n",
        "- Liegen die Variablen nicht als Ränge vor, müssen sie zunächst in Ränge umgewandelt werden:\n",
        "    1. Werte der Variable sortieren\n",
        "    2. (Unnormierte) Ränge zuordnen\n",
        "    3. Normierung: Gleiche Werte erhalten den Mittelwert ihrer Ränge\n",
        "    4. (Optional) Variablen in ihre ursprüngliche Reihenfolge bringen\n",
        "\n",
        "![](images/rangbildung.png){heigh=375px}\n",
        "\n",
        "- Die Tabelle gibt die Rangberechnung *einer* Variablen an (z.B. X) &ndash; für die andere Variable (Y) muss das analoge Prozedere durchgeführt werden.\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Spearman-Korrelation\n",
        "- Die Spearman-Korrelation $r_s$ ist identisch zur Pearson-Korrelation, wenn die Variablen $X$ und $Y$ als Ränge $R(X)$ und $R(Y)$ vorliegen:\n",
        "\n",
        "$$\n",
        "r_s = \\frac{cov(R(X),R(Y))}{s_{R(X)} s_{R(Y)}}\n",
        "$$\n",
        "&numsp;&numsp;wobei $s_{R(X)}$ und $s_{R(Y)}$ die Standardabweichungen der Ränge von $X$ und $Y$ sind.\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"60%\"}\n",
        "- Wie die Pearson-Korrelation nimmt die Spearman-Korrelation Werte zwischen $-1$ und $+1$ an:\n",
        "    - Ein positiver Wert impliziert eine positiven monotonen Zusammenhang\n",
        "    - Ein negativer Wert impliziert eine negativen monotonen Zusammenhang\n",
        "    - Ein Wert nahe bei 0 impliziert einen schwachen (oder keinen) monotonen Zusammenhang\n",
        ":::\n",
        "::: {.column width=\"40%\"}\n",
        "![](images/monotonie.png)\n",
        ":::\n",
        "::::\n",
        "\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Kendalls Tau\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"65%\"}\n",
        "- Eine Alternative Rangkorrelation zu Spearman ist [**Kendalls Tau**]{color=\"navy\"}\n",
        "- Kendalls Tau vergleicht inwieweit die Rangfolge *aller* Paare $x_i$, $x_j$ mit der Rangfolge *aller* Paare $y_i$, $y_j$ übereinstimmt\n",
        "- Dazu wird die Zahl der konkordanten (übereinstimmenden) und diskordanten (nicht übereinstimmenden) Paare gezählt\n",
        ":::\n",
        "::: {.column width=\"35%\"}\n",
        "<div class=\"vspace-large\"></div>\n",
        "![](images/Kendalls_Tau_Gleichung.png)\n",
        ":::\n",
        "::::\n",
        "\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"30%\"}\n",
        "::: {.greybox}\n",
        "**Beispiel**\n",
        ":::\n",
        "\n",
        "$$\n",
        "\\small{\n",
        "X=\\begin{pmatrix} 9\\\\ 3\\\\ 7\\\\ 5 \\end{pmatrix}\n",
        "Y=\\begin{pmatrix} 18\\\\ 7\\\\ 8\\\\ 21 \\end{pmatrix}\n",
        "}\n",
        "$$\n",
        ":::\n",
        "::: {.column width=\"70%\"}\n",
        "- Die Paare von X sind: $\\small{(9, 3), (9, 7), (9, 5), (3, 7), (3, 5), (7, 5)}$\n",
        "- Die Paare von Y sind: $\\small{(18, 7), (18, 8), (18, 21), (7, 8), (7, 21), (8, 21)}$\n",
        "- Die Paare $(x_1=9, x_3=7)$ und $(y_1=18, y_3=2)$ wären konkordant, da die Rangfolge des X-Paares ($x_1 > x_3$) gleich der Rangfolge des entsprechenden Y-Paares ($y_1 > y_3$) ist\n",
        "- Die Paare$(x_1=9, x_4=5)$ und $(y_1=18, y_4=21)$ wären diskonkordant, da die Rangfolge des X-Paares ($x_1 > x_4$) ungleich der Rangfolge des entsprechenden Y-Paares ($y_1 < y_4$) ist\n",
        ":::\n",
        "::::\n",
        "\n",
        "[Insgesamt gibt es im Beispiel 4 konkordante Paare und 2 diskordante Paare (prüfe nach!), daher gilt:]{style=\"margin-top:-12px; display: block\"}\n",
        "\n",
        "$$\n",
        "\\tau = \\frac{K-D}{K+D} = \\frac{4-2}{3+3} = \\frac{2}{6} = 0.333..\n",
        "$$\n"
      ],
      "id": "86519155"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.stats import pearsonr, spearmanr, linregress\n",
        "np.random.seed(13)\n",
        "fontsize=15\n",
        "\n",
        "data = np.random.multivariate_normal([0, 0], [[1, 0.1], [0.1, 1]], 20) + 3\n",
        "data = np.vstack((data, [5, 12]))\n",
        "x, y = data[:, 0], data[:, 1]\n",
        "\n",
        "reg = linregress(x, y)\n",
        "reg2 = linregress(x[:-1], y[:-1])\n",
        "r, p = pearsonr(x, y)\n",
        "r2, p2 = pearsonr(x[:-1], y[:-1])\n",
        "xrange = np.array([1.1, 5.2])\n",
        "\n",
        "plt.figure(figsize=(11, 4))\n",
        "plt.subplot(121)\n",
        "plt.scatter(x[:-1], y[:-1], c='#888')\n",
        "plt.scatter(x[-1], y[-1], c='#d80000')\n",
        "plt.plot(xrange, reg.slope*xrange+reg.intercept, color='#d80000')\n",
        "plt.plot(xrange, reg2.slope*xrange+reg2.intercept, color='#888')\n",
        "plt.xticks(fontsize=fontsize-2)\n",
        "plt.yticks(fontsize=fontsize-2)\n",
        "plt.xlabel('X', fontsize=fontsize)\n",
        "plt.ylabel('Y', fontsize=fontsize)\n",
        "plt.text(1, 10.25, f'Pearson (mit Ausreißer): $r = {r:.3f}$', fontsize=fontsize-2, color='#d80000')\n",
        "plt.text(1, 11.4, f'Pearson (ohne Ausreißer): $r = {r2:.3f}$', fontsize=fontsize-2, color='#888')\n",
        "plt.text(4.53, 11, 'Ausreißer', fontsize=fontsize-2, color='#d80000')\n",
        "\n",
        "xr, yr = data[:, 0].argsort().argsort()+1, data[:, 1].argsort().argsort()+1\n",
        "print(data[:, 0], data[:, 1])\n",
        "print(xr, yr)\n",
        "rr, pr = spearmanr(xr, yr)\n",
        "rr2, pr2 = spearmanr(xr[:-1], yr[:-1])\n",
        "regr = linregress(xr, yr)\n",
        "regr2 = linregress(xr[:-1], yr[:-1])\n",
        "xrange = np.array([1, 22])\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.scatter(xr[:-1], yr[:-1], c='#888')\n",
        "plt.scatter(xr[-1], yr[-1], c='#d80000')\n",
        "plt.plot(xrange, regr.slope*xrange+regr.intercept, color='#d80000')\n",
        "plt.plot(xrange, regr2.slope*xrange+regr2.intercept, color='#888')\n",
        "plt.xticks(range(0, 21, 5), fontsize=fontsize-2)\n",
        "plt.yticks(fontsize=fontsize-2)\n",
        "plt.xlabel('Rang(X)', fontsize=fontsize)\n",
        "plt.ylabel('Rang(Y)', fontsize=fontsize)\n",
        "plt.text(0.5, 23.5, fr'Spearman (mit Ausreißer): $r_s = {rr:.3f}$', fontsize=fontsize-2, color='#d80000')\n",
        "plt.text(0.5, 26, fr'Spearman (ohne Ausreißer): $r_s = {rr2:.3f}$', fontsize=fontsize-2, color='#888')\n",
        "plt.ylim(0, 29)\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.savefig('images/pearson_outlier.png', bbox_inches=\"tight\")"
      ],
      "id": "22bb5095",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Ausreißer: Der Storch bringt die Babys zur Welt(p = 0.008)\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"50%\"}\n",
        "![](images/geburtenrate_stoerche.png)\n",
        ":::\n",
        "::: {.column width=\"50%\"}\n",
        "![](images/geburtenrate_stoerche_tabelle.png)\n",
        ":::\n",
        "::::\n",
        "\n",
        "http://www3.math.uni-paderborn.de/~agbiehler/sis/sisonline/struktur/jahrgang21-2001/heft2/Langfassungen/2001-2_Matth.pdf\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Rangkorrelationen: Robust gegen Ausreißer\n",
        "\n",
        "- Beispiel Pearson vs. Spearman:\n",
        "\n",
        "![](images/pearson_outlier.png)\n",
        "\n",
        "- Ein einziger Ausreißer verändert die Pearson-Korrelation im Beispiel von $r=-0.046$ nach $r=0.410$\n",
        "- Demgegnüber ist die Spearman-Korrelation \"robuster\" gegenüber dem Ausreißer &ndash; sie verändert sich \"lediglich\" von $\\rho=-0.030$ nach $\\rho=0.110$.\n",
        "- Intution: während der *Wert* es Ausreißers deutlich über dem zweithöchsten Y-Wert liegt, ist der *Rang* nur um 1 höher.\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## [Wann Spearman und wann Kendall?]{color=\"darkred\"}\n",
        "\n",
        "![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=130px}\n",
        "\n",
        "- Beide Rangkorrelationskoeffizienten bestimmen die Monotonie eines Zusammenhangs\n",
        "- **Kendall ist robuster bei kleinen Stichproben** und ist in diesen Fällen bevorzugt\n",
        "- **Spearman ist etwas weniger sensitiv gegenüber Rangbindungen** (also wenn zwei Werte den gleichen Rang haben) und ist daher bevorzugt, wenn es viele Rangbindungen gibt^[Puth M-T, Neuhäuser M, Ruxton GD (2015) Effective use of Spearman’s and Kendall’s correlation coefficients for association between two measured traits. Animal Behaviour 102:77–84.  ]\n",
        "    - Beachte: auch bei den Kendall'schen Paaren gibt es Rangbindungen, und zwar dann, wenn die verglichenen *Paare* zwischen $X$ und $Y$ genau identisch sind\n",
        "    - Diese Paare sind weder konkordant noch diskordant und es gibt verschiedene Algorithmen diese Fälle zu berücksichtigen (hier nicht behandelt)\n",
        "- **In Abwesenheit von Rangbindungen liefert Kendall präzisere Schätzungen** und ist Kendall zu bevorzugen.^[Puth M-T, Neuhäuser M, Ruxton GD (2015) Effective use of Spearman’s and Kendall’s correlation coefficients for association between two measured traits. Animal Behaviour 102:77–84.]\n",
        "- In der Statistik wird Kendall häufig als \"Default\"-Rangkorrelation empfohlen^[DC Howell (2012). Statistical Methods for Psychology. Wadsworth.]:\n",
        "    - idR präzisere Schätzung des Populationsparameters\n",
        "    - Standardfehler ist bekannt (für Spearman gibt es lediglich Approximationen^[https://stats.stackexchange.com/questions/18887/how-to-calculate-a-confidence-interval-for-spearmans-rank-correlation])\n",
        "- Faktisch ist aber Spearman der weitaus verbreitetere Korrelationskoeffizient &ndash;<br> womöglich weil er idR größer als der Kendall-Koeffizient ist &#128521;\n",
        "\n",
        "<!-- https://www.researchgate.net/post/Does-Spearmans-rho-have-any-advantage-over-Kendalls-tau     -->\n",
        "\n",
        "\n",
        "## Der Phi-Koeffizient\n",
        "\n",
        "- Spezialfall: **beide Variablen haben nur zwei Ausprägungen**\n",
        "- Darstellbar in der [**Vierfeldertafel**]{color=\"navy\"}:\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"40%\"}\n",
        "![Bildnachweis^[https://learnattack.de/mathematik/baumdiagramm-und-vierfeldertafel]](images/vierfeldertafel.png)\n",
        ":::\n",
        "::: {.column width=\"50%\"}\n",
        "- In die vier Felder werden die Häufigkeiten der jeweiligen Variablen-Kombination eingetragen (im Beispiel blaugefärbt)\n",
        "- Optional: In der letzten Zeile/Spalte die Summe\n",
        ":::\n",
        "::::\n",
        "\n",
        "::: {style=\"margin-top: -29px\"}\n",
        "- Wie alle Korrelationskoeffizienten beantwortet der [**Phi-Koeffizient**]{color=\"navy\"} die Frage, ob zwei Variablen miteinander zusammenhängen\n",
        "    - Im Beispiel: hängt das gewählte Fach vom Geschlecht ab?\n",
        ":::\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"65%\"}\n",
        "$$\n",
        "\\small{\n",
        "\\text{Formel:}\\quad Phi = \\frac{ad-bc}{\\sqrt{(a+b)(c+d)(a+c)(b+d)}}\n",
        "}\n",
        "$$\n",
        "\n",
        "- Auch der Phi-Koeffizient hat einen Wertebereich von $[-1; 1]$\n",
        ":::\n",
        "::: {.column width=\"35%\"}\n",
        "\n",
        "::: { style=\"margin: -50px 0 0 -50px !important\"}\n",
        "![](images/vierfeldertafel2.png){height=165px}\n",
        ":::\n",
        "\n",
        ":::\n",
        "::::\n",
        "\n",
        "::: {style=\"margin-top: -19px\"}\n",
        "- NB: der Phi-Koeffizient ist identisch mit der Pearson-Korrelation und der Spearman-Korrelation, wenn beide dichotomen Variablen mit 0 und 1 kodiert werden.\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Phi-Koeffizient: Beispiel\n",
        "\n",
        "<div class=\"vspace-medium\"></div>\n",
        "\n",
        "![](images/vierfeldertafel_beispiel.png){height=220px}\n",
        "\n",
        "\\begin{align}\n",
        "Phi &= \\frac{ad-bc}{\\sqrt{(a+b)(c+d)(a+c)(b+d)}} = \\\\\n",
        "    &= \\frac{2\\cdot11-8\\cdot12}{\\sqrt{(2+8)(12+11)(2+12)(8+11)}} = \\\\\n",
        "    &= \\frac{22-96}{\\sqrt{10\\cdot23\\cdot14\\cdot19}} = \\frac{-74}{\\sqrt{61180}} = -0.299\n",
        "\\end{align}\n",
        "\n",
        "\n",
        "# Interpretation von Korrelationen\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Korrelation und Kausalität {.blackslide}\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"59%\"}\n",
        "Die Task Force ist immer noch einigermaßen perblex, ob des Zusammenhangs von TikTok-Onlinezeit und Entzündungswerten.\n",
        "\n",
        "- Als erfahrenen Statistiker:innen kennen Sie die **erste Regel der Korrelation**:\n",
        "\n",
        "::: {style=\"color:lightblue; margin: -5px 0 0 5px; font-family: monospace; border: 2px solid lightblue; outline: 2px solid lightblue; outline-offset:-7px; padding-left: 14px\"}\n",
        "**Korrelation ist nicht gleich Kausalität**\n",
        ":::\n",
        "::: {style=\"text-align: left\"}\n",
        "(Oder falls Sie den Lateiner heraushängen lassen wollen: *Cum hoc ergo propter hoc*)\n",
        ":::\n",
        ":::\n",
        "::: {.column width=\"41%\"}\n",
        "![](images/streudiagramm.png)\n",
        ":::\n",
        "::::\n",
        "\n",
        "- Es scheint unmöglich, dass virtuelle TikTok-Zeit einen [**kausalen Einfluss**]{color=\"lightblue\"} auf biologische Entzündungswerte hat.\n",
        "- Sie wissen, dass ein häufiger alternativer Grund für eine Korrelation eine dritte Variable ist, die wiederum Einfluss auf beide Variablen der Korrelation hat&mdash; eine [**Störvariable**]{color=\"lightblue\"}.\n",
        "- In diesem Fall vermuten Sie, dass die Störvariable eine vorhandene Paradoxie-Erkrankung selbst ist: die Erkrankung führt einerseits zu höheren Entzündungswerten und andererseits zu vermehrter TikTok-Zeit (um Trost bei Leidensgenossen zu erfahren?)\n",
        "\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Korrelation und Kausalität\n",
        "\n",
        "- Rein rechnerisch bedeutet eine Korrelation einen *Zusammenhang* zweier Variablen, sogar, dass man die *eine Variable aus der anderen zu einem gewissen Grad vorhersagen kann*\n",
        "- Dies **bedeutet jedoch nicht, dass sich die Variablen auch kausal bedingen**\n",
        "- Einerseits **können Korrelationen zufällig zustande kommen** (die Wahrscheinlichkeit von solchen irrtümlichen Befunden untersuchen wir noch genauer beim Thema Signifikanztestung).\n",
        "- .. andererseits können Korrelationen durch dritte Variablen (**Störvariablen**) verursacht sein.\n",
        "- Umgekehrt können Störvariablen auch tatsächlich vorhandene Zusammenhänge unterdrücken &mdash; man spricht dann von **Suppression**; der Korrelationskoeffizient unterschätzt in diesem Fall die tatsächliche Stärke des Zusammenhangs.\n",
        "- Trotz aller Fallstricke bei der Interpretation gilt: eine Korrelation KANN ein **Indiz für Kausalität** sein (wo Kausalität da auch Korrelation, sofern diese nicht durch Störvariablen unterdrückt ist).\n",
        "<div class=\"vspace-medium\"></div>\n",
        "\n",
        "![](images/correlation_confounder.png)\n",
        "![Bildnachweis^[https://www.patheos.com/blogs/tippling/2017/10/31/spooky-punkins-and-statistical-correlation/]](images/Inferring-Causation-from-Correlation.jpg)\n",
        "\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Korrelation und Kausalität\n",
        "\n",
        "<div class=\"vspace-xlarge\">&nbsp;</div>\n",
        "\n",
        "![](images/correlation_nicolascage.png)\n",
        "\n",
        "![](images/tylergiven.png){.absolute bottom=0 left=0 height=150px}\n",
        "\n",
        "\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Korrelation und Kausalität\n",
        "\n",
        "<div class=\"vspace-xlarge\"></div>\n",
        "\n",
        "![](images/correlation_confounder_sharks.png)\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## Wann ist ein Korrelationskoeffizient groß oder klein?\n",
        "- Pauschal schwer zu beantworten\n",
        "- In der psychologischen Literatur hat sich folgende Nomenklatur nach Jacob Cohen^[Cohen J. (1988). Statistical Power Analysis for the Behavioral Sciences. New York, NY: Routledge Academic] eingebürgert:\n",
        "\n",
        "<!---  Table --->\n",
        "| Korrelation (r) | Nomenklatur |\n",
        "|-|-|\n",
        "| 0.1 bis 0.3  | \"kleiner\" Effekt |\n",
        "| 0.3 bis 0.5 | \"mittlerer\" Effekt |\n",
        "| > 0.5 | \"großer\" Effekt |\n",
        "\n",
        ": {tbl-colwidths=\"[20, 20]\"}\n",
        "\n",
        "- Allerdings fügt Cohen im gleichen Artikel hinzu:\n",
        "\n",
        "> These proposed conventions were set forth throughout with much diffidence [Zurückhaltung], qualifications [Bedingungen], and invitations **not to employ** them if possible.\n",
        "\n",
        "- Bei der Beurteilung sollte der Korrelationskoeffizient, wie jede Effektgröße, immer in Relation zu typischen Werten im jeweiligen Forschungsfeld gesetzt werden.\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "## [Wann ist ein Korrelationskoeffizient groß oder klein?]{color=\"darkred\"}\n",
        "\n",
        "![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=120px}\n",
        "\n",
        "- In einer kürzlichen Metaanalyse von Lovakov Agadullina (2021)^[Lovakov A, Agadullina ER (2021) Empirically derived guidelines for effect size interpretation in social psychology. Eur J Soc Psychol 51:485–504.] wurden typische Effektstärken in der Sozialpsychologie untersucht:\n",
        "\n",
        "![](images/lovakov_2021.png){height=400px}\n",
        "\n",
        "- Erkenntnis: \"mittlere\" und \"starke\" Korrelationen (definiert als das 50%- und 75%- Quantil)<br> sind in der Realität kleiner als von Cohen angenommen\n",
        "\n",
        "<!----------------->\n",
        "<!--- New slide --->\n",
        "<!----------------->\n",
        "##\n",
        ":::: {.columns}\n",
        "::: {.column width=\"9%\"}\n",
        "::: {style=\"margin-top:-15px\"}\n",
        "![](images/summary.png)\n",
        ":::\n",
        ":::\n",
        "::: {.column width=\"91%\"}\n",
        "::: {.summary}\n",
        "- Zusammenhänge werden mit **Kovarianz** und **Korrelation** untersucht\n",
        "- Die **Kovarianz** ist die Basis der Pearson-Korrelation &ndash; aber sie ist abhängig von den gewählten Einheiten\n",
        "- Die **Pearson-Korrelation** misst die Linearität eines Zusammenhangs und gilt für intervallskalierte Daten\n",
        "- Für ordinalskalierte Variablen eignen sich **Rangkorrelationen**: **Spearmans Rho** und **Kendalls Tau** &ndash; sie messen die Monotonie eines Zusammenhangs\n",
        "- Sind beide Variablen dichotom, greift der **Phi-Koeffizient**\n",
        "- Correlation does not imply causation, Correlation does not imply causation, Correlation does not imply causation, Correlation does not\n",
        ":::\n",
        ":::\n",
        "::::\n",
        "\n",
        "\n",
        " <!-- ```{python}\n",
        "\n",
        "```   -->\n",
        "\n",
        " <!-- ```{python}\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from scipy.stats import linregress, pearsonr\n",
        "\n",
        "np.random.seed(0)\n",
        "root = '/home/matteo/OneDrive/lehre/Statistik/stats1_lecture/book/'\n",
        "df = pd.read_csv(os.path.join(root, 'data', 'paradoxia.csv'))\n",
        "data_tiktok_paradoxia = df[df.group == 2]['hours_tiktok_per_day'].values\n",
        "data_inflam_paradoxia = df[df.group == 2]['inflammation'].values\n",
        "\n",
        "linrg = linregress(data_tiktok_paradoxia, data_inflam_paradoxia)\n",
        "r, p = pearsonr(data_tiktok_paradoxia, data_inflam_paradoxia)\n",
        "print(linrg)\n",
        "\n",
        "fontsize = 15\n",
        "\n",
        "plt.style.use('dark_background')\n",
        "plt.figure(figsize=(3, 2.5))\n",
        "plt.xticks(fontsize=fontsize-2)\n",
        "plt.yticks(fontsize=fontsize-2)\n",
        "plt.xlabel('Stunden TikTok / 24h', fontsize=fontsize)\n",
        "plt.ylabel('Entzündungswerte', fontsize=fontsize)\n",
        "plt.scatter(data_tiktok_paradoxia, data_inflam_paradoxia)\n",
        "plt.plot([0.1, 3.1], linrg.intercept + linrg.slope * np.array([0.1, 3.1]), color='#ff00ff', lw=2)\n",
        "plt.text(0.2, 0.3, r'$\\bf{r=' + f'{r:.3f}' + r'}$', color='#ff00ff', fontsize=fontsize-2)\n",
        "plt.xlim(0, 3.2)\n",
        "plt.ylim(0, 0.34)\n",
        "# plt.legend()\n",
        "plt.savefig('images/paradoxia_histogram_correlation_paradoxiker.png', bbox_inches='tight')\n",
        "```  -->\n",
        "\n",
        "## {.blackslide .center}\n",
        "\n",
        "<div class=\"vspace-medium\"></div>\n",
        "\n",
        ":::: {.columns}\n",
        "::: {.column width=\"65%\"}\n",
        "Zurück zum Zusammenhang zwischen TikTok-Online-Zeit und Entzündungswerten. Beides sind kontinuierliche intervallskalierte Variablen, wie können also den Pearson-Korrelationskoeffizienten anwenden.\n",
        ":::\n",
        "::: {.column width=\"35%\"}\n",
        "::: {.content-hidden when-format=\"pdf\"}\n",
        "![](images/paradoxia_group_of_scientists.png){.hcenter-image height=200px style=\"margin-top:-100px !important\"}\n",
        "<!-- Source: Midjourney -->\n",
        ":::\n",
        ":::\n",
        "::::\n",
        "\n",
        "<div class=\"vspace-large\"></div>\n",
        "![](images/paradoxia_histogram_correlation_paradoxiker.png){height=300px}\n",
        "\n",
        "Faszinierend. Es gibt tatsächlich einen Zusammenhang beider Variablen. Kann das Ergebnis so interpretiert werden, dass TikTok sich auf physiologische Entzündungswerte auswirkt?\n"
      ],
      "id": "1cf90e98"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}