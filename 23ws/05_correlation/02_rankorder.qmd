# Rangkorrelationen

## Was ist eine Rangkorrelation?

:::: {.columns}
::: {.column width="72%"}

- [**Rangkorrelationsmaße**]{color="navy"} ermöglichen es, Zusammenhänge von ordinalskalierten und nicht-linearen Variablem zu untersuchen.
    - Dies ist mit der Pearson-Korrelation nicht möglich
- "Rang" bezieht sich auf das Ordinalskalenniveau, d.h. dass die Daten nur als "Rang" oder "Reihenfolge" interpretiert werden können.
- Im Gegensatz zur Pearson-Korrelation bewerten Rangkorrelationen nicht die Linearität eines Zusammenhangs, sondern die **Monotonie des Zusammenhangs**.
- Ein weiterer Anwendungsfall sind intervallskalierte Daten, die Ausreißer aufweisen und daher die Pearson-Korrelation verzerren.
    - Rangkorrelationen sind **robust gegenüber Ausreißern**
    - In diesem Fall werden die Variablen künstlich in Ränge umgewandelt.
- Hier behandeln wir zwei Maße für die Rangkorrelation:
    - [**Spearman-Korrelation**]{color="navy"}
    - [**Kendall'sches Tau**]{color="navy"}
:::
::: {.column width="28%"}
![](images/rankorder_example.png)

<div class="vspace-medium"></div>

![](images/rankorder_example2.png)
:::
::::


## Berechnung von Rängen

- Liegen die Variablen nicht als Ränge vor, müssen sie zunächst in Ränge umgewandelt werden:
    1. Werte der Variable sortieren
    2. (Unnormierte) Ränge zuordnen
    3. Normierung: Gleiche Werte erhalten den Mittelwert ihrer Ränge
    4. (Optional) Variablen in ihre ursprüngliche Reihenfolge bringen

:::{.fragment}
![](images/rangbildung.png){height=375px}
:::

- Die Tabelle gibt die Rangberechnung *einer* Variablen an (z.B. X) &mdash; für die andere Variable (Y) muss das analoge Prozedere durchgeführt werden.


<!----------------->
<!--- New slide --->
<!----------------->
## Spearman-Korrelation
- Die Spearman-Korrelation $r_s$ ist identisch zur Pearson-Korrelation, wenn die Variablen $X$ und $Y$ als Ränge $R(X)$ und $R(Y)$ vorliegen:

:::{.fragment}
$$
r_s = \frac{cov(R(X),R(Y))}{s_{R(X)} s_{R(Y)}}
$$
&numsp;&numsp;wobei $s_{R(X)}$ und $s_{R(Y)}$ die Standardabweichungen der Ränge von $X$ und $Y$ sind.
:::

:::: {.columns}
::: {.column width="60%"}
- Wie die Pearson-Korrelation nimmt die Spearman-Korrelation Werte zwischen $-1$ und $+1$ an:
    - Ein positiver Wert impliziert eine positiven monotonen Zusammenhang
    - Ein negativer Wert impliziert eine negativen monotonen Zusammenhang
    - Ein Wert nahe bei 0 impliziert einen schwachen (oder keinen) monotonen Zusammenhang
:::
::: {.column width="40%"}
:::{.fragment}
![](images/monotonie.png)
:::
:::
::::



<!----------------->
<!--- New slide --->
<!----------------->
## Kendalls Tau

:::: {.columns}
::: {.column width="69%"}
- Eine Alternative Rangkorrelation zu Spearman ist [**Kendalls Tau**]{color="navy"}
- Kendalls Tau vergleicht inwieweit die Rangfolge *aller* Paare ($x_i$, $x_j$) mit der Rangfolge *aller* Paare ($y_i$, $y_j$) übereinstimmt
- Dazu wird die Zahl der konkordanten (übereinstimmenden) und diskordanten (nicht übereinstimmenden) Paare gezählt
:::
::: {.column width="31%"}
<div class="vspace-large"></div>
:::{.fragment}
![](images/Kendalls_Tau_Gleichung.png)
:::
:::
::::


:::: {.columns}
::: {.column width="30%"}

:::{.fragment}
::: {.greybox}
**Beispiel**
:::


$$
\small{
X=\begin{pmatrix} 9\\ 3\\ 7\\ 5 \end{pmatrix}
Y=\begin{pmatrix} 18\\ 7\\ 8\\ 21 \end{pmatrix}
}
$$
:::
:::
::: {.column width="70%"}
- Die Paare von X sind: $\small{(9, 3), (9, 7), (9, 5), (3, 7), (3, 5), (7, 5)}$
- Die Paare von Y sind: $\small{(18, 7), (18, 8), (18, 21), (7, 8), (7, 21), (8, 21)}$
- Die Paare $(x_1=9, x_3=7)$ und $(y_1=18, y_3=8)$ wären **konkordant**, da die Rangfolge des X-Paares ($x_1 > x_3$) gleich der Rangfolge des entsprechenden Y-Paares ($y_1 > y_3$) ist
- Die Paare$(x_1=9, x_4=5)$ und $(y_1=18, y_4=21)$ wären **diskonkordant**, da die Rangfolge des X-Paares ($x_1 > x_4$) ungleich der Rangfolge des entsprechenden Y-Paares ($y_1 < y_4$) ist
:::
::::

:::{.fragment}
[Insgesamt gibt es im Beispiel 4 konkordante Paare und 2 diskordante Paare (prüfe nach!), daher gilt:]{style="margin-top:-12px; display: block"}
:::

:::{.fragment}
$$
\tau = \frac{K-D}{K+D} = \frac{4-2}{4+2} = \frac{2}{6} = 0.333..
$$
:::



<!-- ```{python}
import matplotlib.pyplot as plt
import numpy as np
from scipy.stats import pearsonr, spearmanr, linregress
np.random.seed(13)
fontsize=15

data = np.random.multivariate_normal([0, 0], [[1, 0.1], [0.1, 1]], 20) + 3
data = np.vstack((data, [5, 12]))
x, y = data[:, 0], data[:, 1]

reg = linregress(x, y)
reg2 = linregress(x[:-1], y[:-1])
r, p = pearsonr(x, y)
r2, p2 = pearsonr(x[:-1], y[:-1])
xrange = np.array([1.1, 5.2])

plt.figure(figsize=(11, 4))
plt.subplot(121)
plt.scatter(x[:-1], y[:-1], c='#888')
plt.scatter(x[-1], y[-1], c='#d80000')
plt.plot(xrange, reg.slope*xrange+reg.intercept, color='#d80000')
plt.plot(xrange, reg2.slope*xrange+reg2.intercept, color='#888')
plt.xticks(fontsize=fontsize-2)
plt.yticks(fontsize=fontsize-2)
plt.xlabel('X', fontsize=fontsize)
plt.ylabel('Y', fontsize=fontsize)
plt.text(1, 10.25, f'Pearson (mit Ausreißer): $r = {r:.3f}$', fontsize=fontsize-2, color='#d80000')
plt.text(1, 11.4, f'Pearson (ohne Ausreißer): $r = {r2:.3f}$', fontsize=fontsize-2, color='#888')
plt.text(4.53, 11, 'Ausreißer', fontsize=fontsize-2, color='#d80000')

xr, yr = data[:, 0].argsort().argsort()+1, data[:, 1].argsort().argsort()+1
print(data[:, 0], data[:, 1])
print(xr, yr)
rr, pr = spearmanr(xr, yr)
rr2, pr2 = spearmanr(xr[:-1], yr[:-1])
regr = linregress(xr, yr)
regr2 = linregress(xr[:-1], yr[:-1])
xrange = np.array([1, 22])

plt.subplot(122)
plt.scatter(xr[:-1], yr[:-1], c='#888')
plt.scatter(xr[-1], yr[-1], c='#d80000')
plt.plot(xrange, regr.slope*xrange+regr.intercept, color='#d80000')
plt.plot(xrange, regr2.slope*xrange+regr2.intercept, color='#888')
plt.xticks(range(0, 21, 5), fontsize=fontsize-2)
plt.yticks(fontsize=fontsize-2)
plt.xlabel('Rang(X)', fontsize=fontsize)
plt.ylabel('Rang(Y)', fontsize=fontsize)
plt.text(0.5, 23.5, fr'Spearman (mit Ausreißer): $r_s = {rr:.3f}$', fontsize=fontsize-2, color='#d80000')
plt.text(0.5, 26, fr'Spearman (ohne Ausreißer): $r_s = {rr2:.3f}$', fontsize=fontsize-2, color='#888')
plt.ylim(0, 29)

plt.tight_layout()

plt.savefig('images/pearson_outlier.png', bbox_inches="tight")
``` -->




<!----------------->
<!--- New slide --->
<!----------------->
## Ausreißer: Der Storch bringt die Babys zur Welt(p = 0.008)

:::: {.columns}
::: {.column width="50%"}
![](images/geburtenrate_stoerche.png)
:::
::: {.column width="50%"}
![](images/geburtenrate_stoerche_tabelle.png)
:::
::::

http://www3.math.uni-paderborn.de/~agbiehler/sis/sisonline/struktur/jahrgang21-2001/heft2/Langfassungen/2001-2_Matth.pdf


- Im gezeigten Beispiel wird die Korrelation fast ausschließlich durch zwei Ausreißer (Türkei und Polen) bestimmt. Der Zusammenhang wird dadurch  überschätzt.

<!----------------->
<!--- New slide --->
<!----------------->
## Rangkorrelationen: Robust gegen Ausreißer

- Beispiel Pearson vs. Spearman:

:::{.fragment}
![](images/pearson_outlier.png)
:::

- Ein einziger Ausreißer verändert die Pearson-Korrelation im Beispiel von $r=-0{,}046$ nach $r=0{,}410$
- Demgegnüber ist die Spearman-Korrelation "robuster" gegenüber dem Ausreißer &mdash; sie verändert sich "lediglich" von $r_s=-0{,}030$ nach $r_s=0{,}110$.
- Intution: während der *Wert* es Ausreißers deutlich über dem zweithöchsten Y-Wert liegt, ist der *Rang* nur um 1 höher.

<!----------------->
<!--- New slide --->
<!----------------->
## [Wann Spearman und wann Kendall?]{color="darkred"}

![](images/kein_klausurstoff.png){.absolute bottom=0 right=0 height=130px}

- Beide Rangkorrelationskoeffizienten bestimmen die Monotonie eines Zusammenhangs.
- **Kendall ist robuster bei kleinen Stichproben** und ist in diesen Fällen bevorzugt.
- **Spearman ist etwas weniger sensitiv gegenüber Rangbindungen** (also wenn zwei Werte den gleichen Rang haben) und ist daher bevorzugt, wenn es viele Rangbindungen gibt^[Puth M-T, Neuhäuser M, Ruxton GD (2015) Effective use of Spearman’s and Kendall’s correlation coefficients for association between two measured traits. Animal Behaviour 102:77–84.].
    - Beachte: auch bei den Kendall'schen Paaren gibt es Rangbindungen, und zwar dann, wenn die verglichenen *Paare* zwischen $X$ und $Y$ genau identisch sind.
    - Diese Paare sind weder konkordant noch diskordant und es gibt verschiedene Algorithmen diese Fälle zu berücksichtigen (hier nicht behandelt).
- **In Abwesenheit von Rangbindungen liefert Kendall präzisere Schätzungen** und ist in diesem Fall zu bevorzugen.^[Puth M-T, Neuhäuser M, Ruxton GD (2015) Effective use of Spearman’s and Kendall’s correlation coefficients for association between two measured traits. Animal Behaviour 102:77–84.].
- In der Statistik wird Kendall häufig als "Default"-Rangkorrelation empfohlen^[DC Howell (2012). Statistical Methods for Psychology. Wadsworth.]:
    - idR präzisere Schätzung des Populationsparameters
    - Standardfehler ist bekannt (für Spearman gibt es lediglich Approximationen^[https://stats.stackexchange.com/questions/18887/how-to-calculate-a-confidence-interval-for-spearmans-rank-correlation])
- In der Praxis ist aber Spearman der weitaus verbreitetere Korrelationskoeffizient &mdash;<br> womöglich weil er idR größer als der Kendall-Koeffizient ist &#128521;.

<!-- https://www.researchgate.net/post/Does-Spearmans-rho-have-any-advantage-over-Kendalls-tau     -->


## Der Phi-Koeffizient

- Spezialfall: **beide Variablen haben nur zwei Ausprägungen** (sind also *dichotom*).
- Darstellbar in der [**Vierfeldertafel**]{color="navy"}:

:::: {.columns}
::: {.column width="40%"}
:::{.fragment}
![](images/vierfeldertafel.png)
:::
:::
::: {.column width="50%"}
- In die vier Felder werden die Häufigkeiten der jeweiligen Variablen-Kombination eingetragen.
- Optional: In der letzten Zeile/Spalte die Summe.
- $a+b+c+d$ muss sich zur Stichprobengröße $n$ addieren.
:::
::::

- Frage: hängen Raucherstatus und Geschlecht zusammen? Die Antwort liefert der [**Phi-Koeffizient**]{color="navy"}:

:::{.fragment}
$$
\small{
\text{Phi-Koeffizient:}\quad \phi = \frac{ad-bc}{\sqrt{(a+b)(c+d)(a+c)(b+d)}}
}
$$
:::

- Wichtig: das Vorzeichen hängt davon ab, in welcher Reihenfolge die beiden Variablen in die Vierfeldertafel eingetragen werden.
    - Übung für zu Hause: das Vorzeichen von $\phi$ dreht sich um, wenn die Spalten male/female vertauscht werden, und ebenso, wenn die Zeilen smoker/nonsmoker vertauscht werden. Warum? 
- Wie alle Korrelationskoeffizienten hat auch der Phi-Koeffizient einen Wertebereich von $[-1; 1]$.

## Der Phi-Koeffizient

- Der Phi-Koeffizient ist identisch mit der Pearson-Korrelation und der Spearman-Korrelation, wenn beide dichotomen Variablen mit 0 und 1 kodiert werden.

:::{.fragment}
$$
\phi = \frac{Cov(X,Y)}{s_X s_Y}\qquad\text{mit}\quad X=\{0, 1\}, Y=\{0, 1\}
$$
:::

- Hier ist für das Vorzeichen entscheidend, welche Ausprägung als 0 und welche als 1 definiert wird (analog der Eintrage-Reihenfolge in die Vierfeldertafel).
- In der Praxis findet der Phi-Koeffizient wenig Anwendung, da der Zusammenhang zumeist intuitiver in Form von Häufigkeiten berichtet wird (z.B. Raucherhäufigkeit bei Männern versus Frauen).
- Zwei Vorteile hat der Phi-Koeffizient jedoch:
    - Es muss keine Festlegung erfolgen, ob die Raucherhäufigkeit zwischen den Geschlechtern, oder die Geschlechterhäufigkeit zwischen Rauchern und Nichtrauchern berichtet wird.
    - Der Phi-Koeffizient kann in Metaanalysen mit anderen Studien verglichen werden, die eine ähnliche Fragestellung mit einer linearen Pearson-Korrelation bemessen haben.
- Zudem macht der Phi-Koeffizient in konzeptioneller Hinsicht den Punkt zu Beginn der Vorlesung deutlich, dass jeder Unterschied (z.B. Raucherhäufigkeit bei Männern versus Frauen) auch als Zusammenhang (Zusammenhang von Geschlecht und Raucherstatus) formuliert werden kann.


<!----------------->
<!--- New slide --->
<!----------------->
## Phi-Koeffizient: Beispiel

<div class="vspace-medium"></div>

![](images/vierfeldertafel_beispiel.png){height=220px}

\begin{align}
\phi &= \frac{ad-bc}{\sqrt{(a+b)(c+d)(a+c)(b+d)}} = \\
    &= \frac{2\cdot11-8\cdot12}{\sqrt{(2+8)(12+11)(2+12)(8+11)}} = \\
    &= \frac{22-96}{\sqrt{10\cdot23\cdot14\cdot19}} = \frac{-74}{\sqrt{61180}} = -0.299
\end{align}

<div class="vspace-medium"></div>

::: {.notabene}
:::: {.columns}
::: {.column width="7%"}
::: {style="margin-top: 10px"}
![](images/notabene2.png){height="65px"}
:::
:::
::: {.column width="93%"}
**Achtung:** Der Phi-Koeffizient beschreibt einen *Zusammenhang im weiteren Sinne* und kann somit auch als Unterschied konzeptionalisiert werden (Beispiel: *unterscheidet* sich die relative Häufigkeit des Haustierbesitzes zwischen Männern und Frauen?).
:::
::::
:::